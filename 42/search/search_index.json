{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"SEKOIA.IO Documentations Get familiar with SEKOIA.IO and explore products features kind: homepage What are you curious about? Explore by Category Get Started Operation Center Intelligence Center APIs Documentation What's New?","title":"Home"},{"location":"getting_started/","text":"Welcome to SEKOIA.IO SEKOIA.IO is a Cybersecurity Platform as a Service , based on our ability to leverage threat intelligence to dynamically integrate it into an innovative approach of the cyberdefense. SEKOIA.IO architecture couples the generation and operation of Threat Intelligence dynamic databases to a set of functions for analysis, guidance and treatment. This technology brings together automation, sharing of indicators and implementation of playbooks to treat, on a large scale and in real time, the flows exchanged and data from other tools already deployed on the networks (internal security logs). There are two main parts in SEKOIA.IO: The Intelligence Center , a Threat Intelligence knowledge base constantly updated by SEKOIA analysts The Operation Center ,a SIEM application that can trigger alerts from the security events received, based on two principles: CTI rules based on dedicated CTI indicator feeds generated by SEKOIA. Correlation rules between events. In addition to a web interface, SEKOIA.IO provides REST/API for external apps for almost all of its features. In order to test SEKOIA.IO, you just have to create an account and send your logs to the platform.","title":"Overview"},{"location":"getting_started/#welcome-to-sekoiaio","text":"SEKOIA.IO is a Cybersecurity Platform as a Service , based on our ability to leverage threat intelligence to dynamically integrate it into an innovative approach of the cyberdefense. SEKOIA.IO architecture couples the generation and operation of Threat Intelligence dynamic databases to a set of functions for analysis, guidance and treatment. This technology brings together automation, sharing of indicators and implementation of playbooks to treat, on a large scale and in real time, the flows exchanged and data from other tools already deployed on the networks (internal security logs). There are two main parts in SEKOIA.IO: The Intelligence Center , a Threat Intelligence knowledge base constantly updated by SEKOIA analysts The Operation Center ,a SIEM application that can trigger alerts from the security events received, based on two principles: CTI rules based on dedicated CTI indicator feeds generated by SEKOIA. Correlation rules between events. In addition to a web interface, SEKOIA.IO provides REST/API for external apps for almost all of its features. In order to test SEKOIA.IO, you just have to create an account and send your logs to the platform.","title":"Welcome to SEKOIA.IO"},{"location":"getting_started/2fa/","text":"Securing your SEKOIA account with two-factor authentication Two-factor authentication adds additional security to your SEKOIA account by requiring a second step to sign in. It requires you to give a 6-digit verification code generated from your phone in addition to your username and password login. When two-factor authentication is enabled, you will need your password and a verification code from your phone whenever you sign in on SEKOIA.IO platform. How do I enable two-factor authentication? Log in to SEKOIA.IO platform Click on your profile picture and select settings to access the User center Under User > Security, click on the button Enable Two-Factor Authentication Follow the steps to complete the process Enter your password Set up your authenticator app (see \u2018Get the code through an authenticator app\u2019 below for more information) Enter your 6-digit code Generate and save your backup codes Get the code through an authenticator app A time-based one-time password (TOTP) application automatically generates an authentication code that changes after a certain period of time. Here are a few we suggest: Google Authenticator Authy LastPass authenticator 1Password To use one of these apps: While enabling, you\u2019ll see a modal with a QR code you will use to register your SEKOIA account with your authenticator app. Open your authenticator and follow the instructions given to you and scan the QR code when asked by the app. Once your app is configured, enter the security code generated by your authenticator app to complete the two-factor authentication process. Generate backup codes If you lose your mobile device or cannot use your authenticator app, you can use backup codes provided by SEKOIA to access your account. Ten backup codes are generated. Each code can be used only one time . When enabling two-factor authentication, backup codes are generated automatically and you can either copy them or download them as a text file. You can also generate new backup codes but keep in mind that your old codes will not work anymore. We recommend you print off and store your codes in a safe location. Log in with backup codes To log in with your backup codes, you will need to: Locate your backup codes Sign into SEKOIA.IO Enter your username and password When asked for your verification code, enter the backup code and select verify How to disable two-factor authentication To disable two-factor authentication on your SEKOIA account: Log in to your SEKOIA account Click on your profile picture and select settings to access the User center Under User > Security, click on the button Disable Two-Factor Authentication Enter your password and select disable","title":"2-Factors Authentication"},{"location":"getting_started/2fa/#securing-your-sekoia-account-with-two-factor-authentication","text":"Two-factor authentication adds additional security to your SEKOIA account by requiring a second step to sign in. It requires you to give a 6-digit verification code generated from your phone in addition to your username and password login. When two-factor authentication is enabled, you will need your password and a verification code from your phone whenever you sign in on SEKOIA.IO platform.","title":"Securing your SEKOIA account with two-factor authentication"},{"location":"getting_started/2fa/#how-do-i-enable-two-factor-authentication","text":"Log in to SEKOIA.IO platform Click on your profile picture and select settings to access the User center Under User > Security, click on the button Enable Two-Factor Authentication Follow the steps to complete the process Enter your password Set up your authenticator app (see \u2018Get the code through an authenticator app\u2019 below for more information) Enter your 6-digit code Generate and save your backup codes","title":"How do I enable two-factor authentication?"},{"location":"getting_started/2fa/#get-the-code-through-an-authenticator-app","text":"A time-based one-time password (TOTP) application automatically generates an authentication code that changes after a certain period of time. Here are a few we suggest: Google Authenticator Authy LastPass authenticator 1Password To use one of these apps: While enabling, you\u2019ll see a modal with a QR code you will use to register your SEKOIA account with your authenticator app. Open your authenticator and follow the instructions given to you and scan the QR code when asked by the app. Once your app is configured, enter the security code generated by your authenticator app to complete the two-factor authentication process.","title":"Get the code through an authenticator app"},{"location":"getting_started/2fa/#generate-backup-codes","text":"If you lose your mobile device or cannot use your authenticator app, you can use backup codes provided by SEKOIA to access your account. Ten backup codes are generated. Each code can be used only one time . When enabling two-factor authentication, backup codes are generated automatically and you can either copy them or download them as a text file. You can also generate new backup codes but keep in mind that your old codes will not work anymore. We recommend you print off and store your codes in a safe location.","title":"Generate backup codes"},{"location":"getting_started/2fa/#log-in-with-backup-codes","text":"To log in with your backup codes, you will need to: Locate your backup codes Sign into SEKOIA.IO Enter your username and password When asked for your verification code, enter the backup code and select verify","title":"Log in with backup codes"},{"location":"getting_started/2fa/#how-to-disable-two-factor-authentication","text":"To disable two-factor authentication on your SEKOIA account: Log in to your SEKOIA account Click on your profile picture and select settings to access the User center Under User > Security, click on the button Disable Two-Factor Authentication Enter your password and select disable","title":"How to disable two-factor authentication"},{"location":"getting_started/first_steps/","text":"Getting started If you received an invitation to join a community and you do not already have an account on SEKOIA.IO, you will have to create one. When opening the invitation by clicking on 'OPEN INVITATION' button, you will arrive on the account creation page. Fill-out the form while keeping in mind that you won\u2019t be able to change your username afterwards . Check \u201cI agree with the terms of service\u201d and create your account. You will then have to accept the invitation to join the community. Note Your access will depend on the permissions you are granted in the community you joined. You can access the platform from any browser and on any device. How to navigate the platform Once you are logged in into SEKOIA.IO, you can navigate through the platform using two menus: A collapsed navigation sidebar on the left that gives you access to all the work areas available on the platform. These areas are divided into subcategories: analyze, detect, investigate, remediate and configure for Operation Center, Collection for Intelligence Center. A contextual menu accessible through your profile picture in the top right that gives you access to your Settings and Communities. Note Depending on the permissions granted to you, navigation between the Intelligence Center and the Operation Center is done by clicking on the name at the top of the sidebar. Set up your account User preferences In the \u201csettings\u201d page, accessible by clicking on your avatar picture, you can edit your profile information like your name, company\u2019s name and avatar. You can define your picture profile by either uploading a PNG file, asks to use your Gravatar or use your initials for your profile picture. You can also enable 2-Factor Authentication for your account or control your privacy by activating or deactivating an opt-out cookie. All of these preferences are available through the contextual menu by clicking on \u201cSettings\u201d. Communities When you first create an account, your personal community is created along with it and you can manage it as you please. A \u201cCommunity\u201d allows you to share events, alerts, rules and information with some people. You can manage the rights of each member. You can have access to more than one community and depending on the permissions you are granted, you can have different roles in each of them. When it comes to a community you manage, you can: Edit its name and description. Add new members and assign specific roles to them to enable them to access certain features. Determine which permissions you want to give them. Manage your API keys and configure delegations.","title":"First steps"},{"location":"getting_started/first_steps/#getting-started","text":"If you received an invitation to join a community and you do not already have an account on SEKOIA.IO, you will have to create one. When opening the invitation by clicking on 'OPEN INVITATION' button, you will arrive on the account creation page. Fill-out the form while keeping in mind that you won\u2019t be able to change your username afterwards . Check \u201cI agree with the terms of service\u201d and create your account. You will then have to accept the invitation to join the community. Note Your access will depend on the permissions you are granted in the community you joined. You can access the platform from any browser and on any device.","title":"Getting started"},{"location":"getting_started/first_steps/#how-to-navigate-the-platform","text":"Once you are logged in into SEKOIA.IO, you can navigate through the platform using two menus: A collapsed navigation sidebar on the left that gives you access to all the work areas available on the platform. These areas are divided into subcategories: analyze, detect, investigate, remediate and configure for Operation Center, Collection for Intelligence Center. A contextual menu accessible through your profile picture in the top right that gives you access to your Settings and Communities. Note Depending on the permissions granted to you, navigation between the Intelligence Center and the Operation Center is done by clicking on the name at the top of the sidebar.","title":"How to navigate the platform"},{"location":"getting_started/first_steps/#set-up-your-account","text":"","title":"Set up your account"},{"location":"getting_started/first_steps/#user-preferences","text":"In the \u201csettings\u201d page, accessible by clicking on your avatar picture, you can edit your profile information like your name, company\u2019s name and avatar. You can define your picture profile by either uploading a PNG file, asks to use your Gravatar or use your initials for your profile picture. You can also enable 2-Factor Authentication for your account or control your privacy by activating or deactivating an opt-out cookie. All of these preferences are available through the contextual menu by clicking on \u201cSettings\u201d.","title":"User preferences"},{"location":"getting_started/first_steps/#communities","text":"When you first create an account, your personal community is created along with it and you can manage it as you please. A \u201cCommunity\u201d allows you to share events, alerts, rules and information with some people. You can manage the rights of each member. You can have access to more than one community and depending on the permissions you are granted, you can have different roles in each of them. When it comes to a community you manage, you can: Edit its name and description. Add new members and assign specific roles to them to enable them to access certain features. Determine which permissions you want to give them. Manage your API keys and configure delegations.","title":"Communities"},{"location":"getting_started/inviting_users_to_join_your_community/","text":"Inviting users to join your community You can invite anyone to become a member of your community using their email address. Note You can invite as many users as you need in your community. In the top right corner of SEKOIA.IO, click your profile photo, then click on Settings . On the left side of your account page, click on \"Communities\" and then on the community where you want to invite someone. On the \"Members\" tag, click \"Invite\" In the invitation panel, type the email address of your invitee, assign a role to its future account and personalize the invitation with an optional note. Click \"Send\" invitation. The invited person will receive an email to join the community. They will need to accept the invitation before becoming a member of your community.","title":"Inviting users to join your community"},{"location":"getting_started/inviting_users_to_join_your_community/#inviting-users-to-join-your-community","text":"You can invite anyone to become a member of your community using their email address. Note You can invite as many users as you need in your community. In the top right corner of SEKOIA.IO, click your profile photo, then click on Settings . On the left side of your account page, click on \"Communities\" and then on the community where you want to invite someone. On the \"Members\" tag, click \"Invite\" In the invitation panel, type the email address of your invitee, assign a role to its future account and personalize the invitation with an optional note. Click \"Send\" invitation. The invited person will receive an email to join the community. They will need to accept the invitation before becoming a member of your community.","title":"Inviting users to join your community"},{"location":"integrations/","text":"Integrations In order to protect your business, you need to know what happens. The monitoring of your network and your devices is a prerequisite to their security. SEKOIA.IO rely on your log to identify threats and malicious activities. In this chapter, you will learn how to configure your log system to make it forward your events to SEKOIA.IO. SEKOIA.IO is able to collect logs through various mechanisms, configuration on your side should be easy! Here is an overview on how integration could be done with SEKOIA.IO. SEKOIA.IO supports the following log collectors: Syslog over TLS ( intake.sekoia.io:10514 ): you can forward your events by using the Syslog protocol specified in RFC 5424. HTTPS ( https://intake.sekoia.io ): you can POST your JSON events. Cloud hosting polling: you can configure SEKOIA.IO to regularly retrieve your logs. If these solutions do not meet your needs, we can also configure a dedicated secured network through a VPN and retrieve your logs directly (please contact us for more information). Syslog integration We are providing documentation and example configurations on how to configure your log system for Rsyslog, but it should be easy to configure other log collectors to forward their events to SEKOIA.IO. HTTPS integration To push your events through our HTTP log collector, you have to POST your logs in the JSON or MessagePack format. To send us events, you should set Content-Type HTTP header: application/javascript for JSON messages. application/msgpack for MessagePack message. Cloud & SaaS integration SEKOIA.IO is also able to retrieve logs and data from cloud platforms, such as Microsoft Azure, Amazon Web Services or Google Cloud. Log formats Cloud and SaaS AWS CloudTrail AWS Flow Logs Microsoft Azure Active Directory Microsoft Azure MySQL Microsoft Azure Linux machines Microsoft Azure Network Watcher Microsoft Azure Windows machines Microsoft Office 365 CISCO Umbrella Dns Logs CISCO Umbrella Ip Logs CISCO Umbrella Proxy Logs Operating Systems Linux Windows / NXLog Windows / Log Insight Applications Alsid Apache BIND Checkpoint Cisco F5 BigIP Fortigate HAProxy ISC DHCP NetFilter Nginx OpenSSH PaloAlto Postfix Sophos SpamAssassin Squid Suricata Unbound Zeek Generic Common Event Format","title":"Overview"},{"location":"integrations/#integrations","text":"In order to protect your business, you need to know what happens. The monitoring of your network and your devices is a prerequisite to their security. SEKOIA.IO rely on your log to identify threats and malicious activities. In this chapter, you will learn how to configure your log system to make it forward your events to SEKOIA.IO. SEKOIA.IO is able to collect logs through various mechanisms, configuration on your side should be easy! Here is an overview on how integration could be done with SEKOIA.IO. SEKOIA.IO supports the following log collectors: Syslog over TLS ( intake.sekoia.io:10514 ): you can forward your events by using the Syslog protocol specified in RFC 5424. HTTPS ( https://intake.sekoia.io ): you can POST your JSON events. Cloud hosting polling: you can configure SEKOIA.IO to regularly retrieve your logs. If these solutions do not meet your needs, we can also configure a dedicated secured network through a VPN and retrieve your logs directly (please contact us for more information).","title":"Integrations"},{"location":"integrations/#syslog-integration","text":"We are providing documentation and example configurations on how to configure your log system for Rsyslog, but it should be easy to configure other log collectors to forward their events to SEKOIA.IO.","title":"Syslog integration"},{"location":"integrations/#https-integration","text":"To push your events through our HTTP log collector, you have to POST your logs in the JSON or MessagePack format. To send us events, you should set Content-Type HTTP header: application/javascript for JSON messages. application/msgpack for MessagePack message.","title":"HTTPS integration"},{"location":"integrations/#cloud-saas-integration","text":"SEKOIA.IO is also able to retrieve logs and data from cloud platforms, such as Microsoft Azure, Amazon Web Services or Google Cloud.","title":"Cloud &amp; SaaS integration"},{"location":"integrations/#log-formats","text":"","title":"Log formats"},{"location":"integrations/#cloud-and-saas","text":"AWS CloudTrail AWS Flow Logs Microsoft Azure Active Directory Microsoft Azure MySQL Microsoft Azure Linux machines Microsoft Azure Network Watcher Microsoft Azure Windows machines Microsoft Office 365 CISCO Umbrella Dns Logs CISCO Umbrella Ip Logs CISCO Umbrella Proxy Logs","title":"Cloud and SaaS"},{"location":"integrations/#operating-systems","text":"Linux Windows / NXLog Windows / Log Insight","title":"Operating Systems"},{"location":"integrations/#applications","text":"Alsid Apache BIND Checkpoint Cisco F5 BigIP Fortigate HAProxy ISC DHCP NetFilter Nginx OpenSSH PaloAlto Postfix Sophos SpamAssassin Squid Suricata Unbound Zeek","title":"Applications"},{"location":"integrations/#generic","text":"Common Event Format","title":"Generic"},{"location":"integrations/alsid/","text":"Overview Alsid is an automated security solution that monitors the components of Active Directory infrastructures by detecting attacks in real time, identifying existing weaknesses and vulnerabilities. Setup This setup guide will show you how to forward logs produced by Alsid to SEKOIA.IO by means of a rsyslog transport channel. On most linux servers, two packages need to be installed: rsyslog and rsyslog-gnutls. 1. Download the certificate In order to allow the connection of your rsyslog server to the SEKOIA.IO intake, please download the SEKOIA.IO intake certificate: 1 $ wget -O /etc/rsyslog.d/SEKOIA-IO-intake.pem https://app.sekoia.io/assets/files/SEKOIA-IO-intake.pem 2. Configure the Rsyslog server Open or create a new Alsid configuration file for rsyslog: 1 sudo vim /etc/rsyslog.d/58-alsid.conf Paste the following rsyslog configuration to trigger the emission of Alsid logs by your rsyslog server to SEKOIA.IO: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Define the SEKIOA-IO intake certificate $DefaultNetstreamDriverCAFile /etc/rsyslog.d/SEKOIA-IO-intake.pem # Configure up the network ssl connection $ActionSendStreamDriver gtls # use gtls netstream driver $ActionSendStreamDriverMode 1 # require TLS for the connection $ActionSendStreamDriverAuthMode x509/name # server is authenticated # Template definition [RFC5424](https://tools.ietf.org/html/rfc5424#section-7.2.2) # IMPORTANT: don't forget to set your intake key in the template template ( name = \"SEKOIAIOAlsidTemplate\" type = \"string\" string = \"<%pri%>1 %timestamp:::date-rfc3339% %hostname% %app-name% %procid% LOG [SEKOIA@53288 intake_key=\\\"YOUR_INTAKE_KEY\\\"] %msg%\\n\" ) # Send your events to SEKOIA.IO intake servers under SEKOIAIOAlsidTemplate template if $hostname == \"YOUR_ALSID_HOSTNAME\" then @@ ( o ) intake.sekoia.io:10514 ; SEKOIAIOAlsidTemplate In the above template instruction, please replace YOUR_INTAKE_KEY variable with your intake key. 3. Restart rsyslog 1 $ sudo service rsyslog restart 4. Enjoy your events Go to the events page to watch your incoming events. Related files SEKOIA-IO-intake.pem : SEKOIA.IO TLS Server Certificate (1674b)","title":"Alsid"},{"location":"integrations/alsid/#overview","text":"Alsid is an automated security solution that monitors the components of Active Directory infrastructures by detecting attacks in real time, identifying existing weaknesses and vulnerabilities.","title":"Overview"},{"location":"integrations/alsid/#setup","text":"This setup guide will show you how to forward logs produced by Alsid to SEKOIA.IO by means of a rsyslog transport channel. On most linux servers, two packages need to be installed: rsyslog and rsyslog-gnutls.","title":"Setup"},{"location":"integrations/alsid/#1-download-the-certificate","text":"In order to allow the connection of your rsyslog server to the SEKOIA.IO intake, please download the SEKOIA.IO intake certificate: 1 $ wget -O /etc/rsyslog.d/SEKOIA-IO-intake.pem https://app.sekoia.io/assets/files/SEKOIA-IO-intake.pem","title":"1. Download the certificate"},{"location":"integrations/alsid/#2-configure-the-rsyslog-server","text":"Open or create a new Alsid configuration file for rsyslog: 1 sudo vim /etc/rsyslog.d/58-alsid.conf Paste the following rsyslog configuration to trigger the emission of Alsid logs by your rsyslog server to SEKOIA.IO: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Define the SEKIOA-IO intake certificate $DefaultNetstreamDriverCAFile /etc/rsyslog.d/SEKOIA-IO-intake.pem # Configure up the network ssl connection $ActionSendStreamDriver gtls # use gtls netstream driver $ActionSendStreamDriverMode 1 # require TLS for the connection $ActionSendStreamDriverAuthMode x509/name # server is authenticated # Template definition [RFC5424](https://tools.ietf.org/html/rfc5424#section-7.2.2) # IMPORTANT: don't forget to set your intake key in the template template ( name = \"SEKOIAIOAlsidTemplate\" type = \"string\" string = \"<%pri%>1 %timestamp:::date-rfc3339% %hostname% %app-name% %procid% LOG [SEKOIA@53288 intake_key=\\\"YOUR_INTAKE_KEY\\\"] %msg%\\n\" ) # Send your events to SEKOIA.IO intake servers under SEKOIAIOAlsidTemplate template if $hostname == \"YOUR_ALSID_HOSTNAME\" then @@ ( o ) intake.sekoia.io:10514 ; SEKOIAIOAlsidTemplate In the above template instruction, please replace YOUR_INTAKE_KEY variable with your intake key.","title":"2. Configure the Rsyslog server"},{"location":"integrations/alsid/#3-restart-rsyslog","text":"1 $ sudo service rsyslog restart","title":"3. Restart rsyslog"},{"location":"integrations/alsid/#4-enjoy-your-events","text":"Go to the events page to watch your incoming events.","title":"4. Enjoy your events"},{"location":"integrations/alsid/#related-files","text":"SEKOIA-IO-intake.pem : SEKOIA.IO TLS Server Certificate (1674b)","title":"Related files"},{"location":"integrations/apache/","text":"Overview The Apache HTTP Server, colloquially called Apache, is free and open-source cross-platform web server software, released under the terms of Apache License 2.0. Apache is developed and maintained by an open community of developers under the auspices of the Apache Software Foundation. Setup This setup guide will show you how to forward both your access and error logs to SEKOIA.IO by means of an rsyslog transport channel. On most linux servers, two packages need to be installed: rsyslog and rsyslog-gnutls. 1. Download the certificate In order to allow the connection of your rsyslog server to the SEKOIA.IO intake, please download the SEKOIA.IO intake certificate: 1 $ wget -O /etc/rsyslog.d/SEKOIA-IO-intake.pem https://app.sekoia.io/assets/files/SEKOIA-IO-intake.pem 2. Configure the Rsyslog server We can configure rsyslog to parse the access_log and error_log and report its entries to SEKOIA.IO. Open or create a new Apache configuration file for rsyslog: 1 sudo vim /etc/rsyslog.d/45-apache.conf At the beginning of the configuration file, paste the following instruction to order the rsyslog server to load the module imfile : 1 $ModLoad imfile Then paste the following configuration to leverage this module to monitor apache httpd access and error output files (please note that the path to the log file may change depending on the OS and your configuration): 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 # Define the SEKIOA-IO intake certificate $DefaultNetstreamDriverCAFile /etc/rsyslog.d/SEKOIA-IO-intake.pem # Configure up the network ssl connection $ActionSendStreamDriver gtls # use gtls netstream driver $ActionSendStreamDriverMode 1 # require TLS for the connection $ActionSendStreamDriverAuthMode x509/name # server is authenticated # error log $InputFileName /var/log/apache2/error.log $InputFileTag apache: $InputFileStateFile stat-apache-error $InputFileSeverity error $InputFileFacility local5 $InputFilePollInterval 1 $InputRunFileMonitor # access log $InputFileName /var/log/apache2/access.log $InputFileTag apache: $InputFileStateFile stat-apache-access $InputFileSeverity notice $InputFileFacility local5 $InputFilePollInterval 1 $InputRunFileMonitor # Template definition [RFC5424](https://tools.ietf.org/html/rfc5424#section-7.2.2) # IMPORTANT: don't forget to set your intake key in the template template ( name = \"SEKOIAIOApacheTemplate\" type = \"string\" string = \"<%pri%>1 %timestamp:::date-rfc3339% %hostname% %app-name% %procid% LOG [SEKOIA@53288 intake_key=\\\"YOUR_INTAKE_KEY\\\"] %msg%\\n\" ) # Send your events to SEKOIA.IO intake servers under SEKOIAIOApacheTemplate template if $programname startswith 'apache' then @@ ( o ) intake.sekoia.io:10514 ; SEKOIAIOApacheTemplate In the above template instruction, please replace YOUR_INTAKE_KEY variable with your intake key. 3. Restart rsyslog 1 $ sudo service rsyslog restart 4. Enjoy your events Go to the events page to watch your incoming events. Related files SEKOIA-IO-intake.pem : SEKOIA.IO TLS Server Certificate (1674b) Further Reading Apache documentation Rsyslog IMFile module","title":"Apache"},{"location":"integrations/apache/#overview","text":"The Apache HTTP Server, colloquially called Apache, is free and open-source cross-platform web server software, released under the terms of Apache License 2.0. Apache is developed and maintained by an open community of developers under the auspices of the Apache Software Foundation.","title":"Overview"},{"location":"integrations/apache/#setup","text":"This setup guide will show you how to forward both your access and error logs to SEKOIA.IO by means of an rsyslog transport channel. On most linux servers, two packages need to be installed: rsyslog and rsyslog-gnutls.","title":"Setup"},{"location":"integrations/apache/#1-download-the-certificate","text":"In order to allow the connection of your rsyslog server to the SEKOIA.IO intake, please download the SEKOIA.IO intake certificate: 1 $ wget -O /etc/rsyslog.d/SEKOIA-IO-intake.pem https://app.sekoia.io/assets/files/SEKOIA-IO-intake.pem","title":"1. Download the certificate"},{"location":"integrations/apache/#2-configure-the-rsyslog-server","text":"We can configure rsyslog to parse the access_log and error_log and report its entries to SEKOIA.IO. Open or create a new Apache configuration file for rsyslog: 1 sudo vim /etc/rsyslog.d/45-apache.conf At the beginning of the configuration file, paste the following instruction to order the rsyslog server to load the module imfile : 1 $ModLoad imfile Then paste the following configuration to leverage this module to monitor apache httpd access and error output files (please note that the path to the log file may change depending on the OS and your configuration): 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 # Define the SEKIOA-IO intake certificate $DefaultNetstreamDriverCAFile /etc/rsyslog.d/SEKOIA-IO-intake.pem # Configure up the network ssl connection $ActionSendStreamDriver gtls # use gtls netstream driver $ActionSendStreamDriverMode 1 # require TLS for the connection $ActionSendStreamDriverAuthMode x509/name # server is authenticated # error log $InputFileName /var/log/apache2/error.log $InputFileTag apache: $InputFileStateFile stat-apache-error $InputFileSeverity error $InputFileFacility local5 $InputFilePollInterval 1 $InputRunFileMonitor # access log $InputFileName /var/log/apache2/access.log $InputFileTag apache: $InputFileStateFile stat-apache-access $InputFileSeverity notice $InputFileFacility local5 $InputFilePollInterval 1 $InputRunFileMonitor # Template definition [RFC5424](https://tools.ietf.org/html/rfc5424#section-7.2.2) # IMPORTANT: don't forget to set your intake key in the template template ( name = \"SEKOIAIOApacheTemplate\" type = \"string\" string = \"<%pri%>1 %timestamp:::date-rfc3339% %hostname% %app-name% %procid% LOG [SEKOIA@53288 intake_key=\\\"YOUR_INTAKE_KEY\\\"] %msg%\\n\" ) # Send your events to SEKOIA.IO intake servers under SEKOIAIOApacheTemplate template if $programname startswith 'apache' then @@ ( o ) intake.sekoia.io:10514 ; SEKOIAIOApacheTemplate In the above template instruction, please replace YOUR_INTAKE_KEY variable with your intake key.","title":"2. Configure the Rsyslog server"},{"location":"integrations/apache/#3-restart-rsyslog","text":"1 $ sudo service rsyslog restart","title":"3. Restart rsyslog"},{"location":"integrations/apache/#4-enjoy-your-events","text":"Go to the events page to watch your incoming events.","title":"4. Enjoy your events"},{"location":"integrations/apache/#related-files","text":"SEKOIA-IO-intake.pem : SEKOIA.IO TLS Server Certificate (1674b)","title":"Related files"},{"location":"integrations/apache/#further-reading","text":"Apache documentation Rsyslog IMFile module","title":"Further Reading"},{"location":"integrations/aws_cloudtrail/","text":"Overview AWS CloudTrail is a service that enables governance, compliance, operational auditing, and risk auditing of your AWS account. With CloudTrail, you can log, continuously monitor, and retain account activity related to actions across your AWS infrastructure. CloudTrail provides event history of your AWS account activity, including actions taken through the AWS Management Console, AWS SDKs, command line tools, and other AWS services ( source: AWS CloudTrail Overview ). Setup Please contact us to discuss about the AWS services in your organization in order to find the appropriate solution to forward CloudTrail events to SEKOIA.IO. 1. CloudTrail trail As a prerequisite you need an existing CloudTrail trail and configure it to record activities from services that you want to monitor. In the AWS console, navigate to: Services > CloudTrail > Trails . From there, enable the events that you want to record: Management events: provide visibility into management operations that are performed on resources in your AWS account. Insights events: help AWS users identify and respond to unusual activity associated with write API calls by continuously analyzing CloudTrail management events. Insights events are logged when CloudTrail detects unusual write management API activity in your account. Data events: provide visibility into the resource operations performed on or within a resource. Activate the logging on the trail through the switch button (On/Off) located on the top right hand corner of the trail page. 2. Log forwarding configuration This part should be discuss with SEKOIA people to find an appropriate solution to forward CloudTrail events to SEKOIA.IO. Further Readings AWS CloudTrail Overview AWS CloudTrail Documentation","title":"CloudTrail"},{"location":"integrations/aws_cloudtrail/#overview","text":"AWS CloudTrail is a service that enables governance, compliance, operational auditing, and risk auditing of your AWS account. With CloudTrail, you can log, continuously monitor, and retain account activity related to actions across your AWS infrastructure. CloudTrail provides event history of your AWS account activity, including actions taken through the AWS Management Console, AWS SDKs, command line tools, and other AWS services ( source: AWS CloudTrail Overview ).","title":"Overview"},{"location":"integrations/aws_cloudtrail/#setup","text":"Please contact us to discuss about the AWS services in your organization in order to find the appropriate solution to forward CloudTrail events to SEKOIA.IO.","title":"Setup"},{"location":"integrations/aws_cloudtrail/#1-cloudtrail-trail","text":"As a prerequisite you need an existing CloudTrail trail and configure it to record activities from services that you want to monitor. In the AWS console, navigate to: Services > CloudTrail > Trails . From there, enable the events that you want to record: Management events: provide visibility into management operations that are performed on resources in your AWS account. Insights events: help AWS users identify and respond to unusual activity associated with write API calls by continuously analyzing CloudTrail management events. Insights events are logged when CloudTrail detects unusual write management API activity in your account. Data events: provide visibility into the resource operations performed on or within a resource. Activate the logging on the trail through the switch button (On/Off) located on the top right hand corner of the trail page.","title":"1. CloudTrail trail"},{"location":"integrations/aws_cloudtrail/#2-log-forwarding-configuration","text":"This part should be discuss with SEKOIA people to find an appropriate solution to forward CloudTrail events to SEKOIA.IO.","title":"2. Log forwarding configuration"},{"location":"integrations/aws_cloudtrail/#further-readings","text":"AWS CloudTrail Overview AWS CloudTrail Documentation","title":"Further Readings"},{"location":"integrations/aws_flow_logs/","text":"Overview Amazon VPC Flow Logs is a feature that provides the ability to capture information about IP network traffic as it enters or exits from network interface in your Amazon VPC (Amazon Virtual Private Cloud). VPC Flow Logs can help you with a number of tasks, such as: Diagnosing overly restrictive security group rules. Monitoring the traffic that is reaching your instance. Determining the direction of the traffic to and from the network interfaces. Setup Please contact us to discuss about the AWS services in your organization in order to find the appropriate solution to forward VPC Flow Logs to SEKOIA.IO. 1. VPC Flow Logs As a prerequisite you need an existing VPC, subnet or network interface (Elastic Load Balancing, Amazon RDS, Amazon ElastiCache, Amazon Redshift, Amazon WorkSpaces, NAT gateways, Transit gateways) to create a flow log. If you create a flow log for a subnet or VPC, each network interface in that subnet or VPC is monitored. In the AWS console, navigate to: Services > VPC . From there, select the resource for which you want to capture information. The flow logs are available on the following resources: VPC, subnet, or network interfaces. For VPC and subnet: Select the specific resource to monitor Go to the tab Flow logs Click on Create flow log Set up the flow log: we recommend to capture all traffic (accepted and rejected). 2. Log forwarding configuration This part should be discussed with SEKOIA.IO people to find an appropriate solution to forward your flow logs to SEKOIA.IO. The following default record format is integrated to the Operation Center: 1 <version> <account-id> <interface-id> <srcaddr> <dstaddr> <srcport> <dstport> <protocol> <packets> <bytes> <start> <end> <action> <log-status> Again, you should discuss with SEKOIA.IO people if your flow logs records are captured with a custom format. Further Readings AWS VPC Overview AWS Flow Logs Documentation","title":"Flow Logs"},{"location":"integrations/aws_flow_logs/#overview","text":"Amazon VPC Flow Logs is a feature that provides the ability to capture information about IP network traffic as it enters or exits from network interface in your Amazon VPC (Amazon Virtual Private Cloud). VPC Flow Logs can help you with a number of tasks, such as: Diagnosing overly restrictive security group rules. Monitoring the traffic that is reaching your instance. Determining the direction of the traffic to and from the network interfaces.","title":"Overview"},{"location":"integrations/aws_flow_logs/#setup","text":"Please contact us to discuss about the AWS services in your organization in order to find the appropriate solution to forward VPC Flow Logs to SEKOIA.IO.","title":"Setup"},{"location":"integrations/aws_flow_logs/#1-vpc-flow-logs","text":"As a prerequisite you need an existing VPC, subnet or network interface (Elastic Load Balancing, Amazon RDS, Amazon ElastiCache, Amazon Redshift, Amazon WorkSpaces, NAT gateways, Transit gateways) to create a flow log. If you create a flow log for a subnet or VPC, each network interface in that subnet or VPC is monitored. In the AWS console, navigate to: Services > VPC . From there, select the resource for which you want to capture information. The flow logs are available on the following resources: VPC, subnet, or network interfaces. For VPC and subnet: Select the specific resource to monitor Go to the tab Flow logs Click on Create flow log Set up the flow log: we recommend to capture all traffic (accepted and rejected).","title":"1. VPC Flow Logs"},{"location":"integrations/aws_flow_logs/#2-log-forwarding-configuration","text":"This part should be discussed with SEKOIA.IO people to find an appropriate solution to forward your flow logs to SEKOIA.IO. The following default record format is integrated to the Operation Center: 1 <version> <account-id> <interface-id> <srcaddr> <dstaddr> <srcport> <dstport> <protocol> <packets> <bytes> <start> <end> <action> <log-status> Again, you should discuss with SEKOIA.IO people if your flow logs records are captured with a custom format.","title":"2. Log forwarding configuration"},{"location":"integrations/aws_flow_logs/#further-readings","text":"AWS VPC Overview AWS Flow Logs Documentation","title":"Further Readings"},{"location":"integrations/azure_ad/","text":"Overview Azure Active Directory is a cloud-based Identity and Rights management service. The service is developed and managed by Microsoft Corp. Setup This setup guide will show you how to forward events produced by Azure Active Directory service to SEKOIA.IO. Theses changes have to be made from the Azure web portal (https://portal.azure.com). 1. Event hubs As a prerequisite you need an Event Hubs (e.g. company-eventhub) and to choose an existing resourceGroup or create a new one (e.g. company-resource-group). You also need your Subscription ID if you don't have a default one. Navigate to: Home > Cost Management + Billing > Subscriptions . From there, copy the relevant Subscription ID that will be used in the command line (e.g. uuid) Then you use Azure powershell (within Cloud Shell interface for example): you will a create a global Event Hubs , then specific Event Hub (e.g. active-directory-event). 1 2 3 PS Azure : \\> az eventhubs namespace create - -name company-eventhub - -resource-group company-resource-group - -enable-kafka true - -subscription uuid PS Azure : \\> az eventhubs eventhub create - -resource-group company-resource-group - -namespace-name company-eventhub - -name active-directory-event - -message-retention 3 - -partition-count 4 - -subscription uuid Navigate to: Home > Event Hubs > company-eventhub - Shared access policies . From there, you can create a policy (e.g. RootManageSharedAccessKey) with the claims Manage , Send and Listen , and note the Primary Key that will be used as the SharedAccessKey . Navigate to: Home > Event Hubs > company-eventhub > active-directory-event - Shared access policies . From there, you can create a policy (e.g. sekoiaio-nifi) with the claims Listen . Once created, click on the policy and save the Connection string-primary key , to be sent to SEKOIA.IO. Navigate to: Home > Event Hubs > company-eventhub > active-directory-event - Consumer groups . From there, you can create a consumer group (e.g. sekoiaio-nifi). 2. Azure Active Directory You need to activate and configure the Azure Active Directory diagnostic settings (e.g. company-ad). Navigate to: Home > Azure Active Directory (e.g. company-ad) > Monitoring > Diagnostic settings : Add a new diagnostic setting, and select Stream to an event hub and click on configure. Select the previously created Event hubs , Event Hub and SharedAccessKey . In the log section, select AuditLogs and SignInLogs . Choose a name for this configuration and click on Save . 3. Enjoy your events You can send to Sekoia the Connection string-primary key previously mentioned. Once the configuration has been done on Sekoia side, you can go to the events page to watch your incoming events. Further Readings Microsoft Github diagnostic Active Directory documentation","title":"Azure Active Directory"},{"location":"integrations/azure_ad/#overview","text":"Azure Active Directory is a cloud-based Identity and Rights management service. The service is developed and managed by Microsoft Corp.","title":"Overview"},{"location":"integrations/azure_ad/#setup","text":"This setup guide will show you how to forward events produced by Azure Active Directory service to SEKOIA.IO. Theses changes have to be made from the Azure web portal (https://portal.azure.com).","title":"Setup"},{"location":"integrations/azure_ad/#1-event-hubs","text":"As a prerequisite you need an Event Hubs (e.g. company-eventhub) and to choose an existing resourceGroup or create a new one (e.g. company-resource-group). You also need your Subscription ID if you don't have a default one. Navigate to: Home > Cost Management + Billing > Subscriptions . From there, copy the relevant Subscription ID that will be used in the command line (e.g. uuid) Then you use Azure powershell (within Cloud Shell interface for example): you will a create a global Event Hubs , then specific Event Hub (e.g. active-directory-event). 1 2 3 PS Azure : \\> az eventhubs namespace create - -name company-eventhub - -resource-group company-resource-group - -enable-kafka true - -subscription uuid PS Azure : \\> az eventhubs eventhub create - -resource-group company-resource-group - -namespace-name company-eventhub - -name active-directory-event - -message-retention 3 - -partition-count 4 - -subscription uuid Navigate to: Home > Event Hubs > company-eventhub - Shared access policies . From there, you can create a policy (e.g. RootManageSharedAccessKey) with the claims Manage , Send and Listen , and note the Primary Key that will be used as the SharedAccessKey . Navigate to: Home > Event Hubs > company-eventhub > active-directory-event - Shared access policies . From there, you can create a policy (e.g. sekoiaio-nifi) with the claims Listen . Once created, click on the policy and save the Connection string-primary key , to be sent to SEKOIA.IO. Navigate to: Home > Event Hubs > company-eventhub > active-directory-event - Consumer groups . From there, you can create a consumer group (e.g. sekoiaio-nifi).","title":"1. Event hubs"},{"location":"integrations/azure_ad/#2-azure-active-directory","text":"You need to activate and configure the Azure Active Directory diagnostic settings (e.g. company-ad). Navigate to: Home > Azure Active Directory (e.g. company-ad) > Monitoring > Diagnostic settings : Add a new diagnostic setting, and select Stream to an event hub and click on configure. Select the previously created Event hubs , Event Hub and SharedAccessKey . In the log section, select AuditLogs and SignInLogs . Choose a name for this configuration and click on Save .","title":"2. Azure Active Directory"},{"location":"integrations/azure_ad/#3-enjoy-your-events","text":"You can send to Sekoia the Connection string-primary key previously mentioned. Once the configuration has been done on Sekoia side, you can go to the events page to watch your incoming events.","title":"3. Enjoy your events"},{"location":"integrations/azure_ad/#further-readings","text":"Microsoft Github diagnostic Active Directory documentation","title":"Further Readings"},{"location":"integrations/azure_linux/","text":"Overview Azure Virtual Machines service is developed and managed by Microsoft Corp. Setup This setup guide will show you how to forward events produced by a Linux Virtual Machine hosted on Azure platform to SEKOIA.IO. 1. Event hubs These explanations are made from the Azure web portal (https://portal.azure.com). As a prerequisite you need an Event Hubs (e.g. company-eventhub) and to choose an existing resourceGroup or create a new one (e.g. company-resource-group). You also need your Subscription ID if you don't have a default one. Navigate to: Home > Cost Management + Billing > Subscriptions . From there, copy the relevant Subscription ID that will be used in the command line (e.g. uuid) Then you use Azure powershell (within Cloud Shell interface for example): you will a create a global Event Hubs , then specific Event Hub (e.g. linux-event). 1 2 3 PS Azure : \\> az eventhubs namespace create - -name company-eventhub - -resource-group company-resource-group - -enable-kafka true - -subscription uuid PS Azure : \\> az eventhubs eventhub create - -resource-group company-resource-group - -namespace-name company-eventhub - -name linux-event - -message-retention 3 - -partition-count 4 - -subscription uuid Navigate to: Home > Event Hubs > company-eventhub - Shared access policies . From there, you can create a policy (e.g. RootManageSharedAccessKey) with the claims Manage , Send and Listen , and note the Primary Key that will be used as the SharedAccessKey . Navigate to: Home > Event Hubs > company-eventhub > linux-event - Shared access policies . From there, you can create a policy (e.g. sekoiaio-nifi) with the claims Listen . Once created, click on the policy and save the Connection string-primary key , to be sent to SEKOIA.IO. Navigate to: Home > Event Hubs > company-eventhub > linux-event - Consumer groups . From there, you can create a consumer group (e.g. sekoiaio-nifi). 2. Linux Virtual Machine You need to activate and configure the diagnostic extension LinuxDiagnostic . Navigate to: Home > Virtual machines > virtual machine name (e.g. company-linux) > Settings > Extensions . Install it and note the new StorageAccount name created (e.g. company-storage-account). Navigate to: Home > Storage accounts > company-storage-account - Access keys . From there you can note the key value later used as the storageAccountKey . Navigate to: Home > Storage accounts > company-storage-account - Shared access signature . From there set the expiration date with caution, then click on Generate SAS and connection string . You should note the SAS token value later used (starting with sv?=). Navigate to: Home > All resources . From there you can note the resourceId associated to your linux virtual machine. You need to create two configuration files public_settings.json and protected_settings.json . Once again you need Azure powershell to do it using your favorite text editor: 1 PS Azure : \\> vim public_settings . json Adapt the public settings configuration file with the value of theses variables: StorageAccount , resourceId and sinks and the syslog configuration. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 { \"StorageAccount\" : \"company-storage-account\" , \"ladCfg\" : { \"diagnosticMonitorConfiguration\" : { \"eventVolume\" : \"Medium\" , \"metrics\" : { \"metricAggregation\" : [ { \"scheduledTransferPeriod\" : \"PT1H\" }, { \"scheduledTransferPeriod\" : \"PT1M\" } ], \"resourceId\" : \"/subscriptions/128ed5ce-4f50-4b5f-a3b0-08233b5a86b6/resourceGroups/company-resource-group/providers/Microsoft.Compute/virtualMachines/company-linux\" }, \"performanceCounters\" : { \"performanceCounterConfiguration\" : [] }, \"syslogEvents\" : { \"sinks\" : \"linux-event\" , \"syslogEventConfiguration\" : { \"LOG_AUTH\" : \"LOG_INFO\" , \"LOG_AUTHPRIV\" : \"LOG_INFO\" , \"LOG_CRON\" : \"LOG_INFO\" , \"LOG_DAEMON\" : \"LOG_INFO\" , \"LOG_FTP\" : \"LOG_INFO\" , \"LOG_KERN\" : \"LOG_INFO\" , \"LOG_LOCAL0\" : \"LOG_INFO\" , \"LOG_LOCAL1\" : \"LOG_INFO\" , \"LOG_LOCAL2\" : \"LOG_INFO\" , \"LOG_LOCAL3\" : \"LOG_INFO\" , \"LOG_LOCAL4\" : \"LOG_INFO\" , \"LOG_LOCAL5\" : \"LOG_INFO\" , \"LOG_LOCAL6\" : \"LOG_INFO\" , \"LOG_LOCAL7\" : \"LOG_INFO\" , \"LOG_LPR\" : \"LOG_INFO\" , \"LOG_MAIL\" : \"LOG_INFO\" , \"LOG_NEWS\" : \"LOG_INFO\" , \"LOG_SYSLOG\" : \"LOG_INFO\" , \"LOG_USER\" : \"LOG_INFO\" , \"LOG_UUCP\" : \"LOG_INFO\" } } }, \"sampleRateInSeconds\" : 15 } } You need to generate an authentication token for the access to the linux-event hub. First we'll convert the expiration date we set before into a unix timestamp. Extract the se= value from storageAccountSasTokenv and use it as a parameter to this command: 1 2 PS Azure : \\> date -d '2021-07-09T23:09:19' + % s 1625872159 Then you could create this python script: 1 PS Azure : \\> vim get_token . py Adapt theses variables: sb_name , eh_name , Url , sas_name , sas_value , and expiry : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 from urllib.parse import quote_plus , quote import hmac import hashlib import base64 def get_auth_token ( sb_name , eh_name , sas_name , sas_value , expiry ): \"\"\" Returns an authorization token dictionary for making calls to Event Hubs REST API. \"\"\" uri = quote_plus ( \"https:// {} .servicebus.windows.net/ {} \" \\ . format ( sb_name , eh_name )) sas = sas_value . encode ( 'utf-8' ) string_to_sign = ( uri + ' \\n ' + expiry ) . encode ( 'utf-8' ) signed_hmac_sha256 = hmac . HMAC ( sas , string_to_sign , hashlib . sha256 ) signature = quote ( base64 . b64encode ( signed_hmac_sha256 . digest ())) return { \"sb_name\" : sb_name , \"eh_name\" : eh_name , \"token\" : 'SharedAccessSignature sr= {} &sig= {} &se= {} &skn= {} ' \\ . format ( uri , signature , expiry , sas_name ) } print ( get_auth_token ( sb_name = \"company-eventhub\" , eh_name = \"linux-event\" , sas_name = \"RootManageSharedAccessKey\" , sas_value = \"base64string\" , expiry = \"unix_timestamp\" )) Execute this python script and note the token variable value only from the sr= . 1 2 PS Azure : \\> python get_token . py { 'token' : 'SharedAccessSignature sr=https%3A%2F%2Fcompany-eventhub.servicebus.windows.net%2Flinux-event&sig=9%2BOwFlfqBVEcVg2c5G1wztIjG22GtsMZN5g4NYEu6p0%3D&se=1561569146&skn=RootManageSharedAccessKey' , 'eh_name' : 'linux-event' , 'sb_name' : 'company-eventhub' } Then edit the protected settings configuration file: 1 PS Azure : \\> vim protected_settings . json Adapt the public protected settings configuration file with the value of theses variables: storageAccountName , storageAccountSasToken (starting with sv= and previously refered as SAS token ), sasURL (replace the different values, company-eventhub, linux-event, sr=, and RootManageSharedAccessKey), and SharedAccessKeyName : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 { \"storageAccountName\" : \"company-storage-account\" , \"storageAccountSasToken\" : \"sv=2018-03-28&ss=bfqt&srt=sco&sp=rwdlacup&se=2019-06-21T15:52:44Z&st=2019-06-21T07:52:44Z&spr=https&sig=Dewc7mP63E4xrwqttVcOrChgDIpm6Trp%2FR4dfvSo4vg%3D\" , \"sinksConfig\" : { \"sink\" : [ { \"name\" : \"SyslogJsonBlob\" , \"type\" : \"JsonBlob\" }, { \"name\" : \"linux-event\" , \"type\" : \"EventHub\" , \"sasURL\" : \"https://company-eventhub.servicebus.windows.net/linux-event?sr=https%3A%2F%2Fcompany-eventhub.servicebus.windows.net%2Flinux-event&sig=W86ldfWlPKW0sutGWM7shYGlg%2BbwnbtyVJ7eMsBs840%3D&se=1561137701&skn=RootManageSharedAccessKey\" } ] } } Finally you could push the change of the diagnostic extension configuration (adapt the parameters resource-group, vm-name): 1 PS Azure : \\> az vm extension set - -publisher Microsoft . Azure . Diagnostics - -name LinuxDiagnostic - -version 3 . 0 - -resource-group company-resource-group - -vm-name company-linux - -protected-settings protected_settings . json - -settings public_settings . json - -subscription uuid 3. Enjoy your events You can send to Sekoia the Connection string-primary key previously mentioned. Once the configuration has been done on Sekoia side, you can go to the events page to watch your incoming events. Further Readings Microsoft Github linux diagnostic extension documentation Linkedin post","title":"Azure Linux machines"},{"location":"integrations/azure_linux/#overview","text":"Azure Virtual Machines service is developed and managed by Microsoft Corp.","title":"Overview"},{"location":"integrations/azure_linux/#setup","text":"This setup guide will show you how to forward events produced by a Linux Virtual Machine hosted on Azure platform to SEKOIA.IO.","title":"Setup"},{"location":"integrations/azure_linux/#1-event-hubs","text":"These explanations are made from the Azure web portal (https://portal.azure.com). As a prerequisite you need an Event Hubs (e.g. company-eventhub) and to choose an existing resourceGroup or create a new one (e.g. company-resource-group). You also need your Subscription ID if you don't have a default one. Navigate to: Home > Cost Management + Billing > Subscriptions . From there, copy the relevant Subscription ID that will be used in the command line (e.g. uuid) Then you use Azure powershell (within Cloud Shell interface for example): you will a create a global Event Hubs , then specific Event Hub (e.g. linux-event). 1 2 3 PS Azure : \\> az eventhubs namespace create - -name company-eventhub - -resource-group company-resource-group - -enable-kafka true - -subscription uuid PS Azure : \\> az eventhubs eventhub create - -resource-group company-resource-group - -namespace-name company-eventhub - -name linux-event - -message-retention 3 - -partition-count 4 - -subscription uuid Navigate to: Home > Event Hubs > company-eventhub - Shared access policies . From there, you can create a policy (e.g. RootManageSharedAccessKey) with the claims Manage , Send and Listen , and note the Primary Key that will be used as the SharedAccessKey . Navigate to: Home > Event Hubs > company-eventhub > linux-event - Shared access policies . From there, you can create a policy (e.g. sekoiaio-nifi) with the claims Listen . Once created, click on the policy and save the Connection string-primary key , to be sent to SEKOIA.IO. Navigate to: Home > Event Hubs > company-eventhub > linux-event - Consumer groups . From there, you can create a consumer group (e.g. sekoiaio-nifi).","title":"1. Event hubs"},{"location":"integrations/azure_linux/#2-linux-virtual-machine","text":"You need to activate and configure the diagnostic extension LinuxDiagnostic . Navigate to: Home > Virtual machines > virtual machine name (e.g. company-linux) > Settings > Extensions . Install it and note the new StorageAccount name created (e.g. company-storage-account). Navigate to: Home > Storage accounts > company-storage-account - Access keys . From there you can note the key value later used as the storageAccountKey . Navigate to: Home > Storage accounts > company-storage-account - Shared access signature . From there set the expiration date with caution, then click on Generate SAS and connection string . You should note the SAS token value later used (starting with sv?=). Navigate to: Home > All resources . From there you can note the resourceId associated to your linux virtual machine. You need to create two configuration files public_settings.json and protected_settings.json . Once again you need Azure powershell to do it using your favorite text editor: 1 PS Azure : \\> vim public_settings . json Adapt the public settings configuration file with the value of theses variables: StorageAccount , resourceId and sinks and the syslog configuration. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 { \"StorageAccount\" : \"company-storage-account\" , \"ladCfg\" : { \"diagnosticMonitorConfiguration\" : { \"eventVolume\" : \"Medium\" , \"metrics\" : { \"metricAggregation\" : [ { \"scheduledTransferPeriod\" : \"PT1H\" }, { \"scheduledTransferPeriod\" : \"PT1M\" } ], \"resourceId\" : \"/subscriptions/128ed5ce-4f50-4b5f-a3b0-08233b5a86b6/resourceGroups/company-resource-group/providers/Microsoft.Compute/virtualMachines/company-linux\" }, \"performanceCounters\" : { \"performanceCounterConfiguration\" : [] }, \"syslogEvents\" : { \"sinks\" : \"linux-event\" , \"syslogEventConfiguration\" : { \"LOG_AUTH\" : \"LOG_INFO\" , \"LOG_AUTHPRIV\" : \"LOG_INFO\" , \"LOG_CRON\" : \"LOG_INFO\" , \"LOG_DAEMON\" : \"LOG_INFO\" , \"LOG_FTP\" : \"LOG_INFO\" , \"LOG_KERN\" : \"LOG_INFO\" , \"LOG_LOCAL0\" : \"LOG_INFO\" , \"LOG_LOCAL1\" : \"LOG_INFO\" , \"LOG_LOCAL2\" : \"LOG_INFO\" , \"LOG_LOCAL3\" : \"LOG_INFO\" , \"LOG_LOCAL4\" : \"LOG_INFO\" , \"LOG_LOCAL5\" : \"LOG_INFO\" , \"LOG_LOCAL6\" : \"LOG_INFO\" , \"LOG_LOCAL7\" : \"LOG_INFO\" , \"LOG_LPR\" : \"LOG_INFO\" , \"LOG_MAIL\" : \"LOG_INFO\" , \"LOG_NEWS\" : \"LOG_INFO\" , \"LOG_SYSLOG\" : \"LOG_INFO\" , \"LOG_USER\" : \"LOG_INFO\" , \"LOG_UUCP\" : \"LOG_INFO\" } } }, \"sampleRateInSeconds\" : 15 } } You need to generate an authentication token for the access to the linux-event hub. First we'll convert the expiration date we set before into a unix timestamp. Extract the se= value from storageAccountSasTokenv and use it as a parameter to this command: 1 2 PS Azure : \\> date -d '2021-07-09T23:09:19' + % s 1625872159 Then you could create this python script: 1 PS Azure : \\> vim get_token . py Adapt theses variables: sb_name , eh_name , Url , sas_name , sas_value , and expiry : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 from urllib.parse import quote_plus , quote import hmac import hashlib import base64 def get_auth_token ( sb_name , eh_name , sas_name , sas_value , expiry ): \"\"\" Returns an authorization token dictionary for making calls to Event Hubs REST API. \"\"\" uri = quote_plus ( \"https:// {} .servicebus.windows.net/ {} \" \\ . format ( sb_name , eh_name )) sas = sas_value . encode ( 'utf-8' ) string_to_sign = ( uri + ' \\n ' + expiry ) . encode ( 'utf-8' ) signed_hmac_sha256 = hmac . HMAC ( sas , string_to_sign , hashlib . sha256 ) signature = quote ( base64 . b64encode ( signed_hmac_sha256 . digest ())) return { \"sb_name\" : sb_name , \"eh_name\" : eh_name , \"token\" : 'SharedAccessSignature sr= {} &sig= {} &se= {} &skn= {} ' \\ . format ( uri , signature , expiry , sas_name ) } print ( get_auth_token ( sb_name = \"company-eventhub\" , eh_name = \"linux-event\" , sas_name = \"RootManageSharedAccessKey\" , sas_value = \"base64string\" , expiry = \"unix_timestamp\" )) Execute this python script and note the token variable value only from the sr= . 1 2 PS Azure : \\> python get_token . py { 'token' : 'SharedAccessSignature sr=https%3A%2F%2Fcompany-eventhub.servicebus.windows.net%2Flinux-event&sig=9%2BOwFlfqBVEcVg2c5G1wztIjG22GtsMZN5g4NYEu6p0%3D&se=1561569146&skn=RootManageSharedAccessKey' , 'eh_name' : 'linux-event' , 'sb_name' : 'company-eventhub' } Then edit the protected settings configuration file: 1 PS Azure : \\> vim protected_settings . json Adapt the public protected settings configuration file with the value of theses variables: storageAccountName , storageAccountSasToken (starting with sv= and previously refered as SAS token ), sasURL (replace the different values, company-eventhub, linux-event, sr=, and RootManageSharedAccessKey), and SharedAccessKeyName : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 { \"storageAccountName\" : \"company-storage-account\" , \"storageAccountSasToken\" : \"sv=2018-03-28&ss=bfqt&srt=sco&sp=rwdlacup&se=2019-06-21T15:52:44Z&st=2019-06-21T07:52:44Z&spr=https&sig=Dewc7mP63E4xrwqttVcOrChgDIpm6Trp%2FR4dfvSo4vg%3D\" , \"sinksConfig\" : { \"sink\" : [ { \"name\" : \"SyslogJsonBlob\" , \"type\" : \"JsonBlob\" }, { \"name\" : \"linux-event\" , \"type\" : \"EventHub\" , \"sasURL\" : \"https://company-eventhub.servicebus.windows.net/linux-event?sr=https%3A%2F%2Fcompany-eventhub.servicebus.windows.net%2Flinux-event&sig=W86ldfWlPKW0sutGWM7shYGlg%2BbwnbtyVJ7eMsBs840%3D&se=1561137701&skn=RootManageSharedAccessKey\" } ] } } Finally you could push the change of the diagnostic extension configuration (adapt the parameters resource-group, vm-name): 1 PS Azure : \\> az vm extension set - -publisher Microsoft . Azure . Diagnostics - -name LinuxDiagnostic - -version 3 . 0 - -resource-group company-resource-group - -vm-name company-linux - -protected-settings protected_settings . json - -settings public_settings . json - -subscription uuid","title":"2. Linux Virtual Machine"},{"location":"integrations/azure_linux/#3-enjoy-your-events","text":"You can send to Sekoia the Connection string-primary key previously mentioned. Once the configuration has been done on Sekoia side, you can go to the events page to watch your incoming events.","title":"3. Enjoy your events"},{"location":"integrations/azure_linux/#further-readings","text":"Microsoft Github linux diagnostic extension documentation Linkedin post","title":"Further Readings"},{"location":"integrations/azure_mysql/","text":"Overview Azure Database for MySQL provides fully managed, enterprise-ready community MySQL database as a service. The service is developed and managed by Microsoft Corp. Setup This setup guide will show you how to forward events produced by Azure MySQL service to SEKOIA.IO. Theses changes have to be made from the Azure web portal (https://portal.azure.com). 1. Event hubs As a prerequisite you need an Event Hubs (e.g. company-eventhub) and to choose an existing resourceGroup or create a new one (e.g. company-resource-group). You also need your Subscription ID if you don't have a default one. Navigate to: Home > Cost Management + Billing > Subscriptions . From there, copy the relevant Subscription ID that will be used in the command line (e.g. uuid) Then you use Azure powershell (within Cloud Shell interface for example): you will a create a global Event Hubs , then specific Event Hub (e.g. mysql-event). 1 2 3 PS Azure : \\> az eventhubs namespace create - -name company-eventhub - -resource-group company-resource-group - -enable-kafka true - -subscription uuid PS Azure : \\> az eventhubs eventhub create - -resource-group company-resource-group - -namespace-name company-eventhub - -name mysql-event - -message-retention 3 - -partition-count 4 - -subscription uuid Navigate to: Home > Event Hubs > company-eventhub - Shared access policies . From there, you can create a policy (e.g. RootManageSharedAccessKey) with the claims Manage , Send and Listen , and note the Primary Key that will be used as the SharedAccessKey . Navigate to: Home > Event Hubs > company-eventhub > mysql-event - Shared access policies . From there, you can create a policy (e.g. sekoiaio-nifi) with the claims Listen . Once created, click on the policy and save the Connection string-primary key , to be sent to SEKOIA.IO. Navigate to: Home > Event Hubs > company-eventhub > mysql-event - Consumer groups . From there, you can create a consumer group (e.g. sekoiaio-nifi). 2. Azure MySQL You need to activate and configure the Azure MySQL diagnostic settings (e.g. company-mysql). Navigate to: Home > SQL databases (e.g. company-mysql) > Monitoring > Diagnostic settings : Add a new diagnostic setting, and select Stream to an event hub and click on configure. Select the previously created Event hubs , Event Hub and SharedAccessKey . In the log section, select MySqlAuditLogs and MySqlSlowLogs . Choose a name for this configuration and click on Save . 3. Enjoy your events You can send to Sekoia the Connection string-primary key previously mentioned. Once the configuration has been done on Sekoia side, you can go to the events page to watch your incoming events.","title":"Azure Mysql"},{"location":"integrations/azure_mysql/#overview","text":"Azure Database for MySQL provides fully managed, enterprise-ready community MySQL database as a service. The service is developed and managed by Microsoft Corp.","title":"Overview"},{"location":"integrations/azure_mysql/#setup","text":"This setup guide will show you how to forward events produced by Azure MySQL service to SEKOIA.IO. Theses changes have to be made from the Azure web portal (https://portal.azure.com).","title":"Setup"},{"location":"integrations/azure_mysql/#1-event-hubs","text":"As a prerequisite you need an Event Hubs (e.g. company-eventhub) and to choose an existing resourceGroup or create a new one (e.g. company-resource-group). You also need your Subscription ID if you don't have a default one. Navigate to: Home > Cost Management + Billing > Subscriptions . From there, copy the relevant Subscription ID that will be used in the command line (e.g. uuid) Then you use Azure powershell (within Cloud Shell interface for example): you will a create a global Event Hubs , then specific Event Hub (e.g. mysql-event). 1 2 3 PS Azure : \\> az eventhubs namespace create - -name company-eventhub - -resource-group company-resource-group - -enable-kafka true - -subscription uuid PS Azure : \\> az eventhubs eventhub create - -resource-group company-resource-group - -namespace-name company-eventhub - -name mysql-event - -message-retention 3 - -partition-count 4 - -subscription uuid Navigate to: Home > Event Hubs > company-eventhub - Shared access policies . From there, you can create a policy (e.g. RootManageSharedAccessKey) with the claims Manage , Send and Listen , and note the Primary Key that will be used as the SharedAccessKey . Navigate to: Home > Event Hubs > company-eventhub > mysql-event - Shared access policies . From there, you can create a policy (e.g. sekoiaio-nifi) with the claims Listen . Once created, click on the policy and save the Connection string-primary key , to be sent to SEKOIA.IO. Navigate to: Home > Event Hubs > company-eventhub > mysql-event - Consumer groups . From there, you can create a consumer group (e.g. sekoiaio-nifi).","title":"1. Event hubs"},{"location":"integrations/azure_mysql/#2-azure-mysql","text":"You need to activate and configure the Azure MySQL diagnostic settings (e.g. company-mysql). Navigate to: Home > SQL databases (e.g. company-mysql) > Monitoring > Diagnostic settings : Add a new diagnostic setting, and select Stream to an event hub and click on configure. Select the previously created Event hubs , Event Hub and SharedAccessKey . In the log section, select MySqlAuditLogs and MySqlSlowLogs . Choose a name for this configuration and click on Save .","title":"2. Azure MySQL"},{"location":"integrations/azure_mysql/#3-enjoy-your-events","text":"You can send to Sekoia the Connection string-primary key previously mentioned. Once the configuration has been done on Sekoia side, you can go to the events page to watch your incoming events.","title":"3. Enjoy your events"},{"location":"integrations/azure_network_watcher/","text":"Overview Azure Network Watcher provides tools to monitor, diagnose, view metrics, and enable or disable logs for resources in an Azure virtual network. It also allows to log information about IP traffic flowing through a network security group: NSG flow logs. Setup Please contact us to discuss about the network security group to monitor in your Azure infrastructure in order to find the appropriate solution to forward your logs to SEKOIA.IO. This setup guide will show you a method to enable and give us access to NSG flow logs produced by Azure Network Watcher service to SEKOIA.IO. 1. Enable NSG flow logs The following instructions are provided for the Azure web portal (https://portal.azure.com). As a prerequisite you need at least one virtual machine with a network security group, to enable Network Watcher and to register the Microsoft.Insights provider. Navigate to the Network Watcher service, and select NSG flow logs under LOGS . From the list of NSGs, select your VM(s), and under Flow logs settings , select On to enable the NSG flow logs. Please, select the Version 2 NSG flow log format sample which is integrated to the Operation Center. These instructions are illustrated and more detailled here . 2. Share access to logs This part should be discussed with SEKOIA.IO people to find an appropriate solution to forward your flow logs to SEKOIA.IO. A possible solution consists to share us: - An access key for the Azure Blob Storage - A storage token associated with the resources to share - The name of the container where the NSG flow logs are stored From this information, we will be able to retrieve each PT1h.json blob which contains the flow logs. Further Readings Azure Network Watcher overview Azure Network Watcher NSG flow logging overview","title":"Azure Network Watcher"},{"location":"integrations/azure_network_watcher/#overview","text":"Azure Network Watcher provides tools to monitor, diagnose, view metrics, and enable or disable logs for resources in an Azure virtual network. It also allows to log information about IP traffic flowing through a network security group: NSG flow logs.","title":"Overview"},{"location":"integrations/azure_network_watcher/#setup","text":"Please contact us to discuss about the network security group to monitor in your Azure infrastructure in order to find the appropriate solution to forward your logs to SEKOIA.IO. This setup guide will show you a method to enable and give us access to NSG flow logs produced by Azure Network Watcher service to SEKOIA.IO.","title":"Setup"},{"location":"integrations/azure_network_watcher/#1-enable-nsg-flow-logs","text":"The following instructions are provided for the Azure web portal (https://portal.azure.com). As a prerequisite you need at least one virtual machine with a network security group, to enable Network Watcher and to register the Microsoft.Insights provider. Navigate to the Network Watcher service, and select NSG flow logs under LOGS . From the list of NSGs, select your VM(s), and under Flow logs settings , select On to enable the NSG flow logs. Please, select the Version 2 NSG flow log format sample which is integrated to the Operation Center. These instructions are illustrated and more detailled here .","title":"1. Enable NSG flow logs"},{"location":"integrations/azure_network_watcher/#2-share-access-to-logs","text":"This part should be discussed with SEKOIA.IO people to find an appropriate solution to forward your flow logs to SEKOIA.IO. A possible solution consists to share us: - An access key for the Azure Blob Storage - A storage token associated with the resources to share - The name of the container where the NSG flow logs are stored From this information, we will be able to retrieve each PT1h.json blob which contains the flow logs.","title":"2. Share access to logs"},{"location":"integrations/azure_network_watcher/#further-readings","text":"Azure Network Watcher overview Azure Network Watcher NSG flow logging overview","title":"Further Readings"},{"location":"integrations/azure_windows/","text":"Overview Azure Virtual Machines service is developed and managed by Microsoft Corp. Setup This setup guide will show you how to forward events produced by a Windows Virtual Machine hosted on Azure platform to SEKOIA.IO. Theses changes have to be made from the Azure web portal (https://portal.azure.com). 1. Event hubs As a prerequisite you need an Event Hubs (e.g. company-eventhub) and to choose an existing resourceGroup or create a new one (e.g. company-resource-group). You also need your Subscription ID if you don't have a default one. Navigate to: Home > Cost Management + Billing > Subscriptions . From there, copy the relevant Subscription ID that will be used in the command line (e.g. uuid) Then you use Azure powershell (within Cloud Shell interface for example): you will a create a global Event Hubs , then specific Event Hub (e.g. windows-event). 1 2 3 PS Azure : \\> az eventhubs namespace create - -name company-eventhub - -resource-group company-resource-group - -enable-kafka true - -subscription uuid PS Azure : \\> az eventhubs eventhub create - -resource-group company-resource-group - -namespace-name company-eventhub - -name windows-event - -message-retention 3 - -partition-count 4 - -subscription uuid Navigate to: Home > Event Hubs > company-eventhub - Shared access policies . From there, you can create a policy (e.g. RootManageSharedAccessKey) with the claims Manage , Send and Listen , and note the Primary Key that will be used as the SharedAccessKey . Navigate to: Home > Event Hubs > company-eventhub > windows-event - Shared access policies . From there, you can create a policy (e.g. sekoiaio-nifi) with the claims Listen . Once created, click on the policy and save the Connection string-primary key , to be sent to SEKOIA.IO. Navigate to: Home > Event Hubs > company-eventhub > windows-event - Consumer groups . From there, you can create a consumer group (e.g. sekoiaio-nifi). 2. Windows Virtual Machine You need to activate and configure the diagnostic extension Microsoft.Insights.VMDiagnosticsSettings . Navigate to: Home > Virtual machines > virtual machine name (e.g. company-windows) > Settings > Extensions . Install it and note the new StorageAccount name created (e.g. company-storage-account). Navigate to: Home > Storage accounts > company-storage-account - Access keys . From there you can note the key value later used as the storageAccountKey . You need to create two configuration files public_settings.json and protected_settings.json . Once again you need Azure powershell to do it using your favorite text editor: 1 PS Azure : \\> vim public_settings . json Adapt the public settings configuration file with the value oh theses variables: Url , SharedAccessKeyName , StorageAccount . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 { \"WadCfg\" : { \"DiagnosticMonitorConfiguration\" : { \"overallQuotaInMB\" : 4096 , \"sinks\" : \"applicationInsights.errors\" , \"DiagnosticInfrastructureLogs\" : { \"scheduledTransferLogLevelFilter\" : \"Error\" }, \"WindowsEventLog\" : { \"scheduledTransferPeriod\" : \"PT1M\" , \"DataSource\" : [ { \"name\" : \"Application!*\" }, { \"name\" : \"System!*\" }, { \"name\" : \"Security!*\" } ], \"sinks\" : \"HotPath\" }, \"Logs\" : { \"scheduledTransferPeriod\" : \"PT1M\" , \"scheduledTransferLogLevelFilter\" : \"Error\" , \"sinks\" : \"HotPath\" } }, \"SinksConfig\" : { \"Sink\" : [ { \"name\" : \"HotPath\" , \"type\" : \"JsonBlob\" , \"EventHub\" : { \"Url\" : \"https://company-eventhub.servicebus.windows.net/windows-event\" , \"SharedAccessKeyName\" : \"RootManageSharedAccessKey\" } }, { \"name\" : \"applicationInsights\" , \"ApplicationInsights\" : \"\" , \"Channels\" : { \"Channel\" : [ { \"logLevel\" : \"Error\" , \"name\" : \"errors\" } ] } } ] } }, \"StorageAccount\" : \"company-storage-account\" } A more specific windows event log can be added by specifying the event log filename (e.g for Sysmon: \"name\": \"Microsoft-Windows-Sysmon/Operational!*\" ). Then edit the protected settings configuration file: 1 PS Azure : \\> vim protected_settings . json Adapt the public protected settings configuration file with the value of theses variables: storageAccountName , storageAccountKey , Url , SharedAccessKeyName , SharedAccessKey : 1 2 3 4 5 6 7 8 9 10 { \"storageAccountName\" : \"company-storage-account\" , \"storageAccountKey\" : \"base64-string\" , \"storageAccountEndPoint\" : \"https://core.windows.net\" , \"EventHub\" : { \"Url\" : \"https://company-eventhub.servicebus.windows.net/windows-event\" , \"SharedAccessKeyName\" : \"RootManageSharedAccessKey\" , \"SharedAccessKey\" : \"base64-string\" } } Finally you could push the change of the diagnostic extension configuration (adapt the parameters resource-group, vm-name): 1 PS Azure : \\> az vm extension set - -publisher Microsoft . Azure . Diagnostics - -name IaaSDiagnostics - -version 1 . 5 - -resource-group company-resource-group - -vm-name company-windows - -protected-settings protected_settings . json - -settings public_settings . json - -subscription uuid 3. Sysmon Sysmon tool from Microsoft could improve the detection on Windows computers. You could download the tool on Microsoft website . If you do not know how to use and configure it, please check SwiftOnSecurity github . 4. Enjoy your events You can send to Sekoia the Connection string-primary key previously mentioned. Once the configuration has been done on Sekoia side, you can go to the events page to watch your incoming events. Further Readings Microsoft Github windows diagnostic extension documentation","title":"Azure Windows machines"},{"location":"integrations/azure_windows/#overview","text":"Azure Virtual Machines service is developed and managed by Microsoft Corp.","title":"Overview"},{"location":"integrations/azure_windows/#setup","text":"This setup guide will show you how to forward events produced by a Windows Virtual Machine hosted on Azure platform to SEKOIA.IO. Theses changes have to be made from the Azure web portal (https://portal.azure.com).","title":"Setup"},{"location":"integrations/azure_windows/#1-event-hubs","text":"As a prerequisite you need an Event Hubs (e.g. company-eventhub) and to choose an existing resourceGroup or create a new one (e.g. company-resource-group). You also need your Subscription ID if you don't have a default one. Navigate to: Home > Cost Management + Billing > Subscriptions . From there, copy the relevant Subscription ID that will be used in the command line (e.g. uuid) Then you use Azure powershell (within Cloud Shell interface for example): you will a create a global Event Hubs , then specific Event Hub (e.g. windows-event). 1 2 3 PS Azure : \\> az eventhubs namespace create - -name company-eventhub - -resource-group company-resource-group - -enable-kafka true - -subscription uuid PS Azure : \\> az eventhubs eventhub create - -resource-group company-resource-group - -namespace-name company-eventhub - -name windows-event - -message-retention 3 - -partition-count 4 - -subscription uuid Navigate to: Home > Event Hubs > company-eventhub - Shared access policies . From there, you can create a policy (e.g. RootManageSharedAccessKey) with the claims Manage , Send and Listen , and note the Primary Key that will be used as the SharedAccessKey . Navigate to: Home > Event Hubs > company-eventhub > windows-event - Shared access policies . From there, you can create a policy (e.g. sekoiaio-nifi) with the claims Listen . Once created, click on the policy and save the Connection string-primary key , to be sent to SEKOIA.IO. Navigate to: Home > Event Hubs > company-eventhub > windows-event - Consumer groups . From there, you can create a consumer group (e.g. sekoiaio-nifi).","title":"1. Event hubs"},{"location":"integrations/azure_windows/#2-windows-virtual-machine","text":"You need to activate and configure the diagnostic extension Microsoft.Insights.VMDiagnosticsSettings . Navigate to: Home > Virtual machines > virtual machine name (e.g. company-windows) > Settings > Extensions . Install it and note the new StorageAccount name created (e.g. company-storage-account). Navigate to: Home > Storage accounts > company-storage-account - Access keys . From there you can note the key value later used as the storageAccountKey . You need to create two configuration files public_settings.json and protected_settings.json . Once again you need Azure powershell to do it using your favorite text editor: 1 PS Azure : \\> vim public_settings . json Adapt the public settings configuration file with the value oh theses variables: Url , SharedAccessKeyName , StorageAccount . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 { \"WadCfg\" : { \"DiagnosticMonitorConfiguration\" : { \"overallQuotaInMB\" : 4096 , \"sinks\" : \"applicationInsights.errors\" , \"DiagnosticInfrastructureLogs\" : { \"scheduledTransferLogLevelFilter\" : \"Error\" }, \"WindowsEventLog\" : { \"scheduledTransferPeriod\" : \"PT1M\" , \"DataSource\" : [ { \"name\" : \"Application!*\" }, { \"name\" : \"System!*\" }, { \"name\" : \"Security!*\" } ], \"sinks\" : \"HotPath\" }, \"Logs\" : { \"scheduledTransferPeriod\" : \"PT1M\" , \"scheduledTransferLogLevelFilter\" : \"Error\" , \"sinks\" : \"HotPath\" } }, \"SinksConfig\" : { \"Sink\" : [ { \"name\" : \"HotPath\" , \"type\" : \"JsonBlob\" , \"EventHub\" : { \"Url\" : \"https://company-eventhub.servicebus.windows.net/windows-event\" , \"SharedAccessKeyName\" : \"RootManageSharedAccessKey\" } }, { \"name\" : \"applicationInsights\" , \"ApplicationInsights\" : \"\" , \"Channels\" : { \"Channel\" : [ { \"logLevel\" : \"Error\" , \"name\" : \"errors\" } ] } } ] } }, \"StorageAccount\" : \"company-storage-account\" } A more specific windows event log can be added by specifying the event log filename (e.g for Sysmon: \"name\": \"Microsoft-Windows-Sysmon/Operational!*\" ). Then edit the protected settings configuration file: 1 PS Azure : \\> vim protected_settings . json Adapt the public protected settings configuration file with the value of theses variables: storageAccountName , storageAccountKey , Url , SharedAccessKeyName , SharedAccessKey : 1 2 3 4 5 6 7 8 9 10 { \"storageAccountName\" : \"company-storage-account\" , \"storageAccountKey\" : \"base64-string\" , \"storageAccountEndPoint\" : \"https://core.windows.net\" , \"EventHub\" : { \"Url\" : \"https://company-eventhub.servicebus.windows.net/windows-event\" , \"SharedAccessKeyName\" : \"RootManageSharedAccessKey\" , \"SharedAccessKey\" : \"base64-string\" } } Finally you could push the change of the diagnostic extension configuration (adapt the parameters resource-group, vm-name): 1 PS Azure : \\> az vm extension set - -publisher Microsoft . Azure . Diagnostics - -name IaaSDiagnostics - -version 1 . 5 - -resource-group company-resource-group - -vm-name company-windows - -protected-settings protected_settings . json - -settings public_settings . json - -subscription uuid","title":"2. Windows Virtual Machine"},{"location":"integrations/azure_windows/#3-sysmon","text":"Sysmon tool from Microsoft could improve the detection on Windows computers. You could download the tool on Microsoft website . If you do not know how to use and configure it, please check SwiftOnSecurity github .","title":"3. Sysmon"},{"location":"integrations/azure_windows/#4-enjoy-your-events","text":"You can send to Sekoia the Connection string-primary key previously mentioned. Once the configuration has been done on Sekoia side, you can go to the events page to watch your incoming events.","title":"4. Enjoy your events"},{"location":"integrations/azure_windows/#further-readings","text":"Microsoft Github windows diagnostic extension documentation","title":"Further Readings"},{"location":"integrations/bind/","text":"Overview BIND is an implementation of the Domain Name System (DNS) of the Internet. It performs both of the main DNS server roles, acting as an authoritative name server for domains, and acting as a recursive resolver in the network. Setup This setup guide will show you how to forward logs produced by your BIND server to SEKOIA.IO by means of an rsyslog transport channel. On most GNU/Linux servers, two packages need to be installed: rsyslog and rsyslog-gnutls . 1. Download the certificate In order to allow the connection of your rsyslog server to the SEKOIA.IO intake, please download the SEKOIA.IO intake certificate: 1 $ wget -O /etc/rsyslog.d/SEKOIA-IO-intake.pem https://app.sekoia.io/assets/files/SEKOIA-IO-intake.pem 2. Configure BIND to log queries First, you need to configure your BIND daemon to log queries and forward them to your rsyslog instance. If rsyslog and BIND are installed on the same box, you can simply add the following statement in your BIND\u2019s main configuration file: 1 2 3 4 5 6 7 8 9 10 logging { channel syslog_chan { syslog daemon; severity dynamic; }; category default { syslog_chan; }; category queries { syslog_chan; }; category config { syslog_chan; }; category security { syslog_chan; }; }; You can find more informations on how to configure your BIND instance on its official website . 3. Configure the rsyslog server Open or create a new BIND configuration file for rsyslog: 1 sudo vim /etc/rsyslog.d/46-bind.conf Paste the following rsyslog configuration to trigger the emission of BIND logs by your rsyslog server to SEKOIA.IO: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Define the SEKIOA-IO intake certificate $DefaultNetstreamDriverCAFile /etc/rsyslog.d/SEKOIA-IO-intake.pem # Configure up the network ssl connection $ActionSendStreamDriver gtls # use gtls netstream driver $ActionSendStreamDriverMode 1 # require TLS for the connection $ActionSendStreamDriverAuthMode x509/name # server is authenticated # Template definition [RFC5424](https://tools.ietf.org/html/rfc5424#section-7.2.2) # IMPORTANT: don't forget to set your intake key in the template template ( name = \"SEKOIAIOBINDTemplate\" type = \"string\" string = \"<%pri%>1 %timestamp:::date-rfc3339% %hostname% %app-name% %procid% LOG [SEKOIA@53288 intake_key=\\\"YOUR_INTAKE_KEY\\\"] %msg%\\n\" ) # Send your events to SEKOIA.IO intake servers under SEKOIAIOBINDTemplate template if $programname startswith 'named' then @@ ( o ) intake.sekoia.io:10514 ; SEKOIAIOBINDTemplate In the above template instruction, please replace YOUR_INTAKE_KEY variable with your intake key. 4. Restart rsyslog 1 $ sudo service rsyslog restart 5. Enjoy your events Go to the events page to watch your incoming events. Related files SEKOIA-IO-intake.pem : SEKOIA.IO TLS Server Certificate (1674b)","title":"BIND"},{"location":"integrations/bind/#overview","text":"BIND is an implementation of the Domain Name System (DNS) of the Internet. It performs both of the main DNS server roles, acting as an authoritative name server for domains, and acting as a recursive resolver in the network.","title":"Overview"},{"location":"integrations/bind/#setup","text":"This setup guide will show you how to forward logs produced by your BIND server to SEKOIA.IO by means of an rsyslog transport channel. On most GNU/Linux servers, two packages need to be installed: rsyslog and rsyslog-gnutls .","title":"Setup"},{"location":"integrations/bind/#1-download-the-certificate","text":"In order to allow the connection of your rsyslog server to the SEKOIA.IO intake, please download the SEKOIA.IO intake certificate: 1 $ wget -O /etc/rsyslog.d/SEKOIA-IO-intake.pem https://app.sekoia.io/assets/files/SEKOIA-IO-intake.pem","title":"1. Download the certificate"},{"location":"integrations/bind/#2-configure-bind-to-log-queries","text":"First, you need to configure your BIND daemon to log queries and forward them to your rsyslog instance. If rsyslog and BIND are installed on the same box, you can simply add the following statement in your BIND\u2019s main configuration file: 1 2 3 4 5 6 7 8 9 10 logging { channel syslog_chan { syslog daemon; severity dynamic; }; category default { syslog_chan; }; category queries { syslog_chan; }; category config { syslog_chan; }; category security { syslog_chan; }; }; You can find more informations on how to configure your BIND instance on its official website .","title":"2. Configure BIND to log queries"},{"location":"integrations/bind/#3-configure-the-rsyslog-server","text":"Open or create a new BIND configuration file for rsyslog: 1 sudo vim /etc/rsyslog.d/46-bind.conf Paste the following rsyslog configuration to trigger the emission of BIND logs by your rsyslog server to SEKOIA.IO: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Define the SEKIOA-IO intake certificate $DefaultNetstreamDriverCAFile /etc/rsyslog.d/SEKOIA-IO-intake.pem # Configure up the network ssl connection $ActionSendStreamDriver gtls # use gtls netstream driver $ActionSendStreamDriverMode 1 # require TLS for the connection $ActionSendStreamDriverAuthMode x509/name # server is authenticated # Template definition [RFC5424](https://tools.ietf.org/html/rfc5424#section-7.2.2) # IMPORTANT: don't forget to set your intake key in the template template ( name = \"SEKOIAIOBINDTemplate\" type = \"string\" string = \"<%pri%>1 %timestamp:::date-rfc3339% %hostname% %app-name% %procid% LOG [SEKOIA@53288 intake_key=\\\"YOUR_INTAKE_KEY\\\"] %msg%\\n\" ) # Send your events to SEKOIA.IO intake servers under SEKOIAIOBINDTemplate template if $programname startswith 'named' then @@ ( o ) intake.sekoia.io:10514 ; SEKOIAIOBINDTemplate In the above template instruction, please replace YOUR_INTAKE_KEY variable with your intake key.","title":"3. Configure the rsyslog server"},{"location":"integrations/bind/#4-restart-rsyslog","text":"1 $ sudo service rsyslog restart","title":"4. Restart rsyslog"},{"location":"integrations/bind/#5-enjoy-your-events","text":"Go to the events page to watch your incoming events.","title":"5. Enjoy your events"},{"location":"integrations/bind/#related-files","text":"SEKOIA-IO-intake.pem : SEKOIA.IO TLS Server Certificate (1674b)","title":"Related files"},{"location":"integrations/cef/","text":"Overview ArcSight's Common Event Format (CEF) is an open log management standard. If one of your applications or devices is not covered by one of the other intakes we support but can produce logs in CEF you can use this intake. Still we recommend using an intake tailored to your specific application or device, even with CEF, in order to ensure you get the most out of your logs. If an intake is missing, please contact us . Setup This setup guide will show you how to forward your CEF logs to SEKOIA.IO by means of an rsyslog transport channel. On most linux servers, two packages need to be installed: rsyslog and rsyslog-gnutls. 1. Download the certificate In order to allow the connection of your rsyslog server to the SEKOIA.IO intake, please download the SEKOIA.IO intake certificate: 1 $ wget -O /etc/rsyslog.d/SEKOIA-IO-intake.pem https://app.sekoia.io/assets/files/SEKOIA-IO-intake.pem 2. Configure the Rsyslog server Open or create a new configuration file for rsyslog: 1 sudo vim /etc/rsyslog.d/xx-yyyyy.conf Customize the following rsyslog configuration to trigger the emission of logs by your rsyslog server to SEKOIA.IO. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # Define the SEKIOA-IO intake certificate $DefaultNetstreamDriverCAFile /etc/rsyslog.d/SEKOIA-IO-intake.pem # Configure up the network ssl connection $ActionSendStreamDriver gtls # use gtls netstream driver $ActionSendStreamDriverMode 1 # require TLS for the connection $ActionSendStreamDriverAuthMode x509/name # server is authenticated # Collects logs out of the dedicated socket, uncomment if needed # $AddUnixListenSocket ... # Template definition [RFC5424](https://tools.ietf.org/html/rfc5424#section-7.2.2) # IMPORTANT: don't forget to set your intake key in the template template ( name = \"SEKOIAIOCefTemplate\" type = \"string\" string = \"<%pri%>1 %timestamp:::date-rfc3339% %hostname% %app-name% %procid% LOG [SEKOIA@53288 intake_key=\\\"YOUR_INTAKE_KEY\\\"] %msg%\\n\" ) # Send your events to SEKOIA.IO intake servers under SEKOIAIOCefTemplate template @@ ( o ) intake.sekoia.io:10514 ; SEKOIAIOCefTemplate In the above template instruction, please replace YOUR_INTAKE_KEY variable with your intake key. 3. Restart rsyslog 1 $ sudo service rsyslog restart 4. Enjoy your events Go to the events page to watch your incoming events. Related files SEKOIA-IO-intake.pem : SEKOIA.IO TLS Server Certificate (1674b) Further Reading CEF specification","title":"Common Event Format"},{"location":"integrations/cef/#overview","text":"ArcSight's Common Event Format (CEF) is an open log management standard. If one of your applications or devices is not covered by one of the other intakes we support but can produce logs in CEF you can use this intake. Still we recommend using an intake tailored to your specific application or device, even with CEF, in order to ensure you get the most out of your logs. If an intake is missing, please contact us .","title":"Overview"},{"location":"integrations/cef/#setup","text":"This setup guide will show you how to forward your CEF logs to SEKOIA.IO by means of an rsyslog transport channel. On most linux servers, two packages need to be installed: rsyslog and rsyslog-gnutls.","title":"Setup"},{"location":"integrations/cef/#1-download-the-certificate","text":"In order to allow the connection of your rsyslog server to the SEKOIA.IO intake, please download the SEKOIA.IO intake certificate: 1 $ wget -O /etc/rsyslog.d/SEKOIA-IO-intake.pem https://app.sekoia.io/assets/files/SEKOIA-IO-intake.pem","title":"1. Download the certificate"},{"location":"integrations/cef/#2-configure-the-rsyslog-server","text":"Open or create a new configuration file for rsyslog: 1 sudo vim /etc/rsyslog.d/xx-yyyyy.conf Customize the following rsyslog configuration to trigger the emission of logs by your rsyslog server to SEKOIA.IO. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # Define the SEKIOA-IO intake certificate $DefaultNetstreamDriverCAFile /etc/rsyslog.d/SEKOIA-IO-intake.pem # Configure up the network ssl connection $ActionSendStreamDriver gtls # use gtls netstream driver $ActionSendStreamDriverMode 1 # require TLS for the connection $ActionSendStreamDriverAuthMode x509/name # server is authenticated # Collects logs out of the dedicated socket, uncomment if needed # $AddUnixListenSocket ... # Template definition [RFC5424](https://tools.ietf.org/html/rfc5424#section-7.2.2) # IMPORTANT: don't forget to set your intake key in the template template ( name = \"SEKOIAIOCefTemplate\" type = \"string\" string = \"<%pri%>1 %timestamp:::date-rfc3339% %hostname% %app-name% %procid% LOG [SEKOIA@53288 intake_key=\\\"YOUR_INTAKE_KEY\\\"] %msg%\\n\" ) # Send your events to SEKOIA.IO intake servers under SEKOIAIOCefTemplate template @@ ( o ) intake.sekoia.io:10514 ; SEKOIAIOCefTemplate In the above template instruction, please replace YOUR_INTAKE_KEY variable with your intake key.","title":"2. Configure the Rsyslog server"},{"location":"integrations/cef/#3-restart-rsyslog","text":"1 $ sudo service rsyslog restart","title":"3. Restart rsyslog"},{"location":"integrations/cef/#4-enjoy-your-events","text":"Go to the events page to watch your incoming events.","title":"4. Enjoy your events"},{"location":"integrations/cef/#related-files","text":"SEKOIA-IO-intake.pem : SEKOIA.IO TLS Server Certificate (1674b)","title":"Related files"},{"location":"integrations/cef/#further-reading","text":"CEF specification","title":"Further Reading"},{"location":"integrations/checkpoint/","text":"Overview Check Point\u2019s Next Generation Firewalls (NGFW\u2019s) are trusted by customers for their highest security effectiveness and their ability to keep organizations protected from sophisticated fifth generation cyber-attacks. Check Point\u2019s NGFW includes 23 Firewall models optimized for running all threat prevention technologies simultaneously, including full SSL traffic inspection, without compromising on security or performance. Setup This setup guide will show you how to forward your Checkpoint firewall logs to SEKOIA.IO by means of an Rsyslog transport channel. On most linux servers, two packages need to be installed: rsyslog and rsyslog-gnutls. We are currently supporting the following firewall versions: R77.30, R80.10, R80.20, R80.30. 1. Download the certificate In order to allow the connection of your rsyslog server to the SEKOIA.IO intake, please download the SEKOIA.IO intake certificate: 1 $ wget -O /etc/rsyslog.d/SEKOIA-IO-intake.pem https://app.sekoia.io/assets/files/SEKOIA-IO-intake.pem 2. Configure Checkpoint The first step is to configure Checkpoint to log the awaited traffic. This could be done differently depending on your current setup, one solution is to export logs with the Log Exporter . 3. Configure the Rsyslog server You can configure your Rsyslog server to forward your checkpoint logs to SEKOIA.IO. Open or create a new Checkpoint configuration file for rsyslog: 1 sudo vim /etc/rsyslog.d/52-checkpoint.conf Then paste the following configuration: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Define the SEKIOA-IO intake certificate $DefaultNetstreamDriverCAFile /etc/rsyslog.d/SEKOIA-IO-intake.pem # Configure up the network ssl connection $ActionSendStreamDriver gtls # use gtls netstream driver $ActionSendStreamDriverMode 1 # require TLS for the connection $ActionSendStreamDriverAuthMode x509/name # server is authenticated # Template definition [RFC5424](https://tools.ietf.org/html/rfc5424#section-7.2.2) # IMPORTANT: don't forget to set your intake key in the template template ( name = \"SEKOIAIOCheckpointTemplate\" type = \"string\" string = \"<%pri%>1 %timestamp:::date-rfc3339% %hostname% %app-name% %procid% LOG [SEKOIA@53288 intake_key=\\\"YOUR_INTAKE_KEY\\\"] CEF:%msg%\\n\" ) # Send your Checkpoint events to SEKOIA.IO intake servers under SEKOIAIOCheckpointTemplate template if $hostname == \"YOUR_CHECKPOINT_HOSTNAME\" then @@ ( o ) intake.sekoia.io:10514 ; SEKOIAIOCheckpointTemplate In the above template instruction, change the YOUR_CHECKPOINT_HOSTNAME variable with the correct value, and please replace YOUR_INTAKE_KEY variable with your intake key. 4. Restart rsyslog 1 $ sudo service rsyslog restart Related files SEKOIA-IO-intake.pem : SEKOIA.IO TLS Server Certificate (1674b) 5. Enjoy your events Go to the events page to watch your incoming events.","title":"Checkpoint"},{"location":"integrations/checkpoint/#overview","text":"Check Point\u2019s Next Generation Firewalls (NGFW\u2019s) are trusted by customers for their highest security effectiveness and their ability to keep organizations protected from sophisticated fifth generation cyber-attacks. Check Point\u2019s NGFW includes 23 Firewall models optimized for running all threat prevention technologies simultaneously, including full SSL traffic inspection, without compromising on security or performance.","title":"Overview"},{"location":"integrations/checkpoint/#setup","text":"This setup guide will show you how to forward your Checkpoint firewall logs to SEKOIA.IO by means of an Rsyslog transport channel. On most linux servers, two packages need to be installed: rsyslog and rsyslog-gnutls. We are currently supporting the following firewall versions: R77.30, R80.10, R80.20, R80.30.","title":"Setup"},{"location":"integrations/checkpoint/#1-download-the-certificate","text":"In order to allow the connection of your rsyslog server to the SEKOIA.IO intake, please download the SEKOIA.IO intake certificate: 1 $ wget -O /etc/rsyslog.d/SEKOIA-IO-intake.pem https://app.sekoia.io/assets/files/SEKOIA-IO-intake.pem","title":"1. Download the certificate"},{"location":"integrations/checkpoint/#2-configure-checkpoint","text":"The first step is to configure Checkpoint to log the awaited traffic. This could be done differently depending on your current setup, one solution is to export logs with the Log Exporter .","title":"2. Configure Checkpoint"},{"location":"integrations/checkpoint/#3-configure-the-rsyslog-server","text":"You can configure your Rsyslog server to forward your checkpoint logs to SEKOIA.IO. Open or create a new Checkpoint configuration file for rsyslog: 1 sudo vim /etc/rsyslog.d/52-checkpoint.conf Then paste the following configuration: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Define the SEKIOA-IO intake certificate $DefaultNetstreamDriverCAFile /etc/rsyslog.d/SEKOIA-IO-intake.pem # Configure up the network ssl connection $ActionSendStreamDriver gtls # use gtls netstream driver $ActionSendStreamDriverMode 1 # require TLS for the connection $ActionSendStreamDriverAuthMode x509/name # server is authenticated # Template definition [RFC5424](https://tools.ietf.org/html/rfc5424#section-7.2.2) # IMPORTANT: don't forget to set your intake key in the template template ( name = \"SEKOIAIOCheckpointTemplate\" type = \"string\" string = \"<%pri%>1 %timestamp:::date-rfc3339% %hostname% %app-name% %procid% LOG [SEKOIA@53288 intake_key=\\\"YOUR_INTAKE_KEY\\\"] CEF:%msg%\\n\" ) # Send your Checkpoint events to SEKOIA.IO intake servers under SEKOIAIOCheckpointTemplate template if $hostname == \"YOUR_CHECKPOINT_HOSTNAME\" then @@ ( o ) intake.sekoia.io:10514 ; SEKOIAIOCheckpointTemplate In the above template instruction, change the YOUR_CHECKPOINT_HOSTNAME variable with the correct value, and please replace YOUR_INTAKE_KEY variable with your intake key.","title":"3. Configure the Rsyslog server"},{"location":"integrations/checkpoint/#4-restart-rsyslog","text":"1 $ sudo service rsyslog restart","title":"4. Restart rsyslog"},{"location":"integrations/checkpoint/#related-files","text":"SEKOIA-IO-intake.pem : SEKOIA.IO TLS Server Certificate (1674b)","title":"Related files"},{"location":"integrations/checkpoint/#5-enjoy-your-events","text":"Go to the events page to watch your incoming events.","title":"5. Enjoy your events"},{"location":"integrations/cisco_asa/","text":"Overview The Cisco ASA 5500 series is Cisco's follow up of the Cisco PIX 500 series firewall. However, the ASA is not just a pure hardware firewall. The Cisco ASA is a security device that combines firewall, antivirus, intrusion prevention, and virtual private network (VPN) capabilities. It provides proactive threat defense that stops attacks before they spread through the network. Therefore, the Cisco ASA firewall is the whole package, so to speak. Setup This setup guide will show you how to forward your Cisco ASA logs to SEKOIA.IO by means of an Rsyslog transport channel. 1. Download the certificate In order to allow the connection of your rsyslog server to the SEKOIA.IO intake, please download the SEKOIA.IO intake certificate: 1 $ wget -O /etc/rsyslog.d/SEKOIA-IO-intake.pem https://app.sekoia.io/assets/files/SEKOIA-IO-intake.pem 2. Configure Cisco ASA The first step is to configure Cisco ASA to log the awaited traffic. To enable logging, enter the following commands: 1 hostname ( config ) # logging enable You then have to configure an output destination for logs. Here, we choose to send syslog messages to an external syslog server. 1 hostname ( config ) # logging host interface_name syslog_ip [ tcp [/ port ] | udp [/ port ] [ format emblem ]] Explanations: The format emblem keyword enables EMBLEM format logging for the syslog server with UDP only. The interface_name argument specifies the interface through which you access the syslog server. The syslog_ip argument specifies the IP address of the syslog server. The tcp[/ port ] or udp[/ port ] keyword and argument pair specify that the ASA and ASASM should use TCP or UDP to send syslog messages to the syslog server. You can configure the ASA to send data to a syslog server using either UDP or TCP, but not both. The default protocol is UDP if you do not specify a protocol. If you specify TCP, the ASA discover when the syslog server fails and as a security protection, new connections through the ASA are blocked. If you specify UDP, the ASA continue to allow new connections whether or not the syslog server is operational. Valid port values for either protocol are 1025 through 65535. The default UDP port is 514. The default TCP port is 1470. For more information about Cisco ASA logging, please refer to your Cisco documentation. 3. Configure the Rsyslog server You can configure your Rsyslog server to forward your Cisco ASA logs to SEKOIA.IO. Open or create a new Cisco ASA configuration file for Rsyslog: 1 sudo vim /etc/rsyslog.d/11-cisco-asa.conf Then paste the following configuration: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Define the SEKIOA-IO intake certificate $DefaultNetstreamDriverCAFile /etc/rsyslog.d/SEKOIA-IO-intake.pem # Configure up the network ssl connection $ActionSendStreamDriver gtls # use gtls netstream driver $ActionSendStreamDriverMode 1 # require TLS for the connection $ActionSendStreamDriverAuthMode x509/name # server is authenticated # Template definition [RFC5424](https://tools.ietf.org/html/rfc5424#section-7.2.2) # IMPORTANT: don't forget to set your intake key in the template template ( name = \"SEKOIAIOCiscoAsaTemplate\" type = \"string\" string = \"<%pri%>1 %timestamp:::date-rfc3339% %hostname% %app-name% %procid% LOG [SEKOIA@53288 intake_key=\\\"YOUR_INTAKE_KEY\\\"] %msg%\\n\" ) # Send your Cisco ASA events to SEKOIA.IO intake servers under SEKOIAIOCiscoAsaTemplate template if $hostname == \"YOUR_CISCO_ASA_HOSTNAME\" then @@ ( o ) intake.sekoia.io:10514 ; SEKOIAIOCiscoAsaTemplate In the above template instruction, change YOUR_CISCO_ASA_HOSTNAME and YOUR_INTAKE_KEY with the correct values. 4. Restart Rsyslog 1 $ sudo service rsyslog restart 5. Enjoy your events Go to the events page to watch your incoming events.","title":"Cisco"},{"location":"integrations/cisco_asa/#overview","text":"The Cisco ASA 5500 series is Cisco's follow up of the Cisco PIX 500 series firewall. However, the ASA is not just a pure hardware firewall. The Cisco ASA is a security device that combines firewall, antivirus, intrusion prevention, and virtual private network (VPN) capabilities. It provides proactive threat defense that stops attacks before they spread through the network. Therefore, the Cisco ASA firewall is the whole package, so to speak.","title":"Overview"},{"location":"integrations/cisco_asa/#setup","text":"This setup guide will show you how to forward your Cisco ASA logs to SEKOIA.IO by means of an Rsyslog transport channel.","title":"Setup"},{"location":"integrations/cisco_asa/#1-download-the-certificate","text":"In order to allow the connection of your rsyslog server to the SEKOIA.IO intake, please download the SEKOIA.IO intake certificate: 1 $ wget -O /etc/rsyslog.d/SEKOIA-IO-intake.pem https://app.sekoia.io/assets/files/SEKOIA-IO-intake.pem","title":"1. Download the certificate"},{"location":"integrations/cisco_asa/#2-configure-cisco-asa","text":"The first step is to configure Cisco ASA to log the awaited traffic. To enable logging, enter the following commands: 1 hostname ( config ) # logging enable You then have to configure an output destination for logs. Here, we choose to send syslog messages to an external syslog server. 1 hostname ( config ) # logging host interface_name syslog_ip [ tcp [/ port ] | udp [/ port ] [ format emblem ]] Explanations: The format emblem keyword enables EMBLEM format logging for the syslog server with UDP only. The interface_name argument specifies the interface through which you access the syslog server. The syslog_ip argument specifies the IP address of the syslog server. The tcp[/ port ] or udp[/ port ] keyword and argument pair specify that the ASA and ASASM should use TCP or UDP to send syslog messages to the syslog server. You can configure the ASA to send data to a syslog server using either UDP or TCP, but not both. The default protocol is UDP if you do not specify a protocol. If you specify TCP, the ASA discover when the syslog server fails and as a security protection, new connections through the ASA are blocked. If you specify UDP, the ASA continue to allow new connections whether or not the syslog server is operational. Valid port values for either protocol are 1025 through 65535. The default UDP port is 514. The default TCP port is 1470. For more information about Cisco ASA logging, please refer to your Cisco documentation.","title":"2. Configure Cisco ASA"},{"location":"integrations/cisco_asa/#3-configure-the-rsyslog-server","text":"You can configure your Rsyslog server to forward your Cisco ASA logs to SEKOIA.IO. Open or create a new Cisco ASA configuration file for Rsyslog: 1 sudo vim /etc/rsyslog.d/11-cisco-asa.conf Then paste the following configuration: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Define the SEKIOA-IO intake certificate $DefaultNetstreamDriverCAFile /etc/rsyslog.d/SEKOIA-IO-intake.pem # Configure up the network ssl connection $ActionSendStreamDriver gtls # use gtls netstream driver $ActionSendStreamDriverMode 1 # require TLS for the connection $ActionSendStreamDriverAuthMode x509/name # server is authenticated # Template definition [RFC5424](https://tools.ietf.org/html/rfc5424#section-7.2.2) # IMPORTANT: don't forget to set your intake key in the template template ( name = \"SEKOIAIOCiscoAsaTemplate\" type = \"string\" string = \"<%pri%>1 %timestamp:::date-rfc3339% %hostname% %app-name% %procid% LOG [SEKOIA@53288 intake_key=\\\"YOUR_INTAKE_KEY\\\"] %msg%\\n\" ) # Send your Cisco ASA events to SEKOIA.IO intake servers under SEKOIAIOCiscoAsaTemplate template if $hostname == \"YOUR_CISCO_ASA_HOSTNAME\" then @@ ( o ) intake.sekoia.io:10514 ; SEKOIAIOCiscoAsaTemplate In the above template instruction, change YOUR_CISCO_ASA_HOSTNAME and YOUR_INTAKE_KEY with the correct values.","title":"3. Configure the Rsyslog server"},{"location":"integrations/cisco_asa/#4-restart-rsyslog","text":"1 $ sudo service rsyslog restart","title":"4. Restart Rsyslog"},{"location":"integrations/cisco_asa/#5-enjoy-your-events","text":"Go to the events page to watch your incoming events.","title":"5. Enjoy your events"},{"location":"integrations/dhcpd/","text":"Overview ISC DHCP offers a complete open source solution for implementing DHCP servers. Setup This setup guide will show you how to forward logs produced by your DHCP servers to SEKOIA.IO by means of an rsyslog transport channel. 1. Download the certificate In order to allow the connection of your rsyslog server to the SEKOIA.IO intake, please download the SEKOIA.IO intake certificate: On most linux servers, two packages need to be installed: rsyslog and rsyslog-gnutls. 1 $ wget -O /etc/rsyslog.d/SEKOIA-IO-intake.pem https://app.sekoia.io/assets/files/SEKOIA-IO-intake.pem 2. Configure the Rsyslog server Open or create a new DHCP configuration file for rsyslog: 1 sudo vim /etc/rsyslog.d/39-dhcp.conf Paste the following rsyslog configuration to trigger the emission of DHCP logs by your rsyslog server to SEKOIA.IO: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Define the SEKIOA-IO intake certificate $DefaultNetstreamDriverCAFile /etc/rsyslog.d/SEKOIA-IO-intake.pem # Configure up the network ssl connection $ActionSendStreamDriver gtls # use gtls netstream driver $ActionSendStreamDriverMode 1 # require TLS for the connection $ActionSendStreamDriverAuthMode x509/name # server is authenticated # Template definition [RFC5424](https://tools.ietf.org/html/rfc5424#section-7.2.2) # IMPORTANT: don't forget to set your intake key in the template template ( name = \"SEKOIAIOdhcpTemplate\" type = \"string\" string = \"<%pri%>1 %timestamp:::date-rfc3339% %hostname% %app-name% %procid% LOG [SEKOIA@53288 intake_key=\\\"YOUR_INTAKE_KEY\\\"] %msg%\\n\" ) # Send your events to SEKOIA.IO intake servers under SEKOIAIODhcpdTemplate template if $programname startswith 'dhcpd' then @@ ( o ) intake.sekoia.io:10514 ; SEKOIAIOdhcpTemplate In the above template instruction, replace YOUR_INTAKE_KEY variable with your intake key. 3. Restart rsyslog 1 $ sudo service rsyslog restart 4. Enjoy your events Go to the events page to watch your incoming events. Related files SEKOIA-IO-intake.pem : SEKOIA.IO TLS Server Certificate (1674b)","title":"ISC DHCP"},{"location":"integrations/dhcpd/#overview","text":"ISC DHCP offers a complete open source solution for implementing DHCP servers.","title":"Overview"},{"location":"integrations/dhcpd/#setup","text":"This setup guide will show you how to forward logs produced by your DHCP servers to SEKOIA.IO by means of an rsyslog transport channel.","title":"Setup"},{"location":"integrations/dhcpd/#1-download-the-certificate","text":"In order to allow the connection of your rsyslog server to the SEKOIA.IO intake, please download the SEKOIA.IO intake certificate: On most linux servers, two packages need to be installed: rsyslog and rsyslog-gnutls. 1 $ wget -O /etc/rsyslog.d/SEKOIA-IO-intake.pem https://app.sekoia.io/assets/files/SEKOIA-IO-intake.pem","title":"1. Download the certificate"},{"location":"integrations/dhcpd/#2-configure-the-rsyslog-server","text":"Open or create a new DHCP configuration file for rsyslog: 1 sudo vim /etc/rsyslog.d/39-dhcp.conf Paste the following rsyslog configuration to trigger the emission of DHCP logs by your rsyslog server to SEKOIA.IO: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Define the SEKIOA-IO intake certificate $DefaultNetstreamDriverCAFile /etc/rsyslog.d/SEKOIA-IO-intake.pem # Configure up the network ssl connection $ActionSendStreamDriver gtls # use gtls netstream driver $ActionSendStreamDriverMode 1 # require TLS for the connection $ActionSendStreamDriverAuthMode x509/name # server is authenticated # Template definition [RFC5424](https://tools.ietf.org/html/rfc5424#section-7.2.2) # IMPORTANT: don't forget to set your intake key in the template template ( name = \"SEKOIAIOdhcpTemplate\" type = \"string\" string = \"<%pri%>1 %timestamp:::date-rfc3339% %hostname% %app-name% %procid% LOG [SEKOIA@53288 intake_key=\\\"YOUR_INTAKE_KEY\\\"] %msg%\\n\" ) # Send your events to SEKOIA.IO intake servers under SEKOIAIODhcpdTemplate template if $programname startswith 'dhcpd' then @@ ( o ) intake.sekoia.io:10514 ; SEKOIAIOdhcpTemplate In the above template instruction, replace YOUR_INTAKE_KEY variable with your intake key.","title":"2. Configure the Rsyslog server"},{"location":"integrations/dhcpd/#3-restart-rsyslog","text":"1 $ sudo service rsyslog restart","title":"3. Restart rsyslog"},{"location":"integrations/dhcpd/#4-enjoy-your-events","text":"Go to the events page to watch your incoming events.","title":"4. Enjoy your events"},{"location":"integrations/dhcpd/#related-files","text":"SEKOIA-IO-intake.pem : SEKOIA.IO TLS Server Certificate (1674b)","title":"Related files"},{"location":"integrations/f5-big-ip/","text":"Overview F5's BIG-IP is a family of products covering software and hardware designed around application availability, access control, and security solutions. Setup We expect logs formated in priority as CEF, and encapsulated in a syslog message including your intake key, to be sent on intake.sekoia.io:10514 using the following certificate: SEKOIA-IO-intake.pem . The other reporting format (key/value pairs) is also supported, but the required configuration will not be detailed in the following example. In this setup guide you will set up an rsyslog server to add your intake key and forward securely your BIG-IP logs to our servers. We first explain how to configure your rsyslog server, then we show how to configure a Log Publisher to format your logs as CEF and send them to your rsyslog server. Most BIG-IP modules can use Log Publishers, some can directly log messages as CEF to an rsyslog server. On most linux servers, two packages need to be installed: rsyslog and rsyslog-gnutls. 1. Configure the Rsyslog server In order to allow the connection of your rsyslog server to the SEKOIA.IO intake, please download the SEKOIA.IO intake certificate: 1 $ wget -O /etc/rsyslog.d/SEKOIA-IO-intake.pem https://app.sekoia.io/assets/files/SEKOIA-IO-intake.pem You can now configure your Rsyslog server to forward your logs to SEKOIA.IO. Open or create a new configuration file for rsyslog: 1 sudo vim /etc/rsyslog.d/22-big-ip.conf Then paste the following configuration: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Define the SEKIOA-IO intake certificate $DefaultNetstreamDriverCAFile /etc/rsyslog.d/SEKOIA-IO-intake.pem # Configure up the network ssl connection $ActionSendStreamDriver gtls # use gtls netstream driver, make sure rsyslog-gnutls is installed $ActionSendStreamDriverMode 1 # require TLS for the connection $ActionSendStreamDriverAuthMode x509/name # server is authenticated # Template definition [RFC5424](https://tools.ietf.org/html/rfc5424#section-7.2.2) # IMPORTANT: don't forget to set your intake key in the template template ( name = \"SEKOIAIOBigIpTemplate\" type = \"string\" string = \"<%pri%>1 %timestamp:::date-rfc3339% %hostname% %app-name% %procid% LOG [SEKOIA@53288 intake_key=\\\"YOUR_INTAKE_KEY\\\"] %msg%\\n\" ) # send the logs corresponding to a given module, as an example for ASM: if $programname startswith 'ASM' then @@ ( o ) intake.sekoia.io:10514 ; SEKOIAIOBigIpTemplate In the above template instruction, adapt the line corresponding to your use case in the last block, and please replace YOUR_INTAKE_KEY variable with your intake key. Restart rsyslog: 1 $ sudo service rsyslog restart 2. Configure a Log Publisher Before creating a log publisher, you first need a management port log destination: 1 System -> Logs -> Configuration -> Log Destinations -> Create... Give it a name, choose type Management Port , fill the address and port of your rsyslog server and select protocol UDP (alternatively you can define a pool of rsyslog servers and use it as a remote high speed log destination). Then you need another log destination to format your logs in CEF: 1 System -> Logs -> Configuration -> Log Destinations -> Create... Give it a name, choose type ArcSight , and forward to the log destination you just created. You can now create a log publisher: 1 System -> Logs -> Configuration -> Log Publishers -> Create... Give it a name, and select the ArcSight log destination you just created. You can now use this log publisher to define logging profiles in your BIG-IP modules. As an example in: 1 Access -> Overview -> Event Logs -> Settings -> Create -> Access System Logs -> Publisher or 1 Security -> Event Logs -> Logging Profiles -> Create... -> Publisher 3. Direct Configuration Some modules allow direct configuration to the rsyslog server. As an example: 1 Security -> Event Logs -> Logging Profiles -> Create... Then choose Application Security , select Remote Storage as a storage destination, Common Event Format (ArcSight) as a logging format, and fill in your rsyslog server info. The resulting logging profile can be applied to a given virtual server in: 1 Local Traffic -> Virtual Servers -> Virtual Server List Then choose a virtual server, go to the Security -> Policies tab and apply the log profile. Related files SEKOIA-IO-intake.pem : SEKOIA.IO TLS Server Certificate (1674b) 4. Enjoy your events Go to the events page to watch your incoming events.","title":"F5 BigIP"},{"location":"integrations/f5-big-ip/#overview","text":"F5's BIG-IP is a family of products covering software and hardware designed around application availability, access control, and security solutions.","title":"Overview"},{"location":"integrations/f5-big-ip/#setup","text":"We expect logs formated in priority as CEF, and encapsulated in a syslog message including your intake key, to be sent on intake.sekoia.io:10514 using the following certificate: SEKOIA-IO-intake.pem . The other reporting format (key/value pairs) is also supported, but the required configuration will not be detailed in the following example. In this setup guide you will set up an rsyslog server to add your intake key and forward securely your BIG-IP logs to our servers. We first explain how to configure your rsyslog server, then we show how to configure a Log Publisher to format your logs as CEF and send them to your rsyslog server. Most BIG-IP modules can use Log Publishers, some can directly log messages as CEF to an rsyslog server. On most linux servers, two packages need to be installed: rsyslog and rsyslog-gnutls.","title":"Setup"},{"location":"integrations/f5-big-ip/#1-configure-the-rsyslog-server","text":"In order to allow the connection of your rsyslog server to the SEKOIA.IO intake, please download the SEKOIA.IO intake certificate: 1 $ wget -O /etc/rsyslog.d/SEKOIA-IO-intake.pem https://app.sekoia.io/assets/files/SEKOIA-IO-intake.pem You can now configure your Rsyslog server to forward your logs to SEKOIA.IO. Open or create a new configuration file for rsyslog: 1 sudo vim /etc/rsyslog.d/22-big-ip.conf Then paste the following configuration: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Define the SEKIOA-IO intake certificate $DefaultNetstreamDriverCAFile /etc/rsyslog.d/SEKOIA-IO-intake.pem # Configure up the network ssl connection $ActionSendStreamDriver gtls # use gtls netstream driver, make sure rsyslog-gnutls is installed $ActionSendStreamDriverMode 1 # require TLS for the connection $ActionSendStreamDriverAuthMode x509/name # server is authenticated # Template definition [RFC5424](https://tools.ietf.org/html/rfc5424#section-7.2.2) # IMPORTANT: don't forget to set your intake key in the template template ( name = \"SEKOIAIOBigIpTemplate\" type = \"string\" string = \"<%pri%>1 %timestamp:::date-rfc3339% %hostname% %app-name% %procid% LOG [SEKOIA@53288 intake_key=\\\"YOUR_INTAKE_KEY\\\"] %msg%\\n\" ) # send the logs corresponding to a given module, as an example for ASM: if $programname startswith 'ASM' then @@ ( o ) intake.sekoia.io:10514 ; SEKOIAIOBigIpTemplate In the above template instruction, adapt the line corresponding to your use case in the last block, and please replace YOUR_INTAKE_KEY variable with your intake key. Restart rsyslog: 1 $ sudo service rsyslog restart","title":"1. Configure the Rsyslog server"},{"location":"integrations/f5-big-ip/#2-configure-a-log-publisher","text":"Before creating a log publisher, you first need a management port log destination: 1 System -> Logs -> Configuration -> Log Destinations -> Create... Give it a name, choose type Management Port , fill the address and port of your rsyslog server and select protocol UDP (alternatively you can define a pool of rsyslog servers and use it as a remote high speed log destination). Then you need another log destination to format your logs in CEF: 1 System -> Logs -> Configuration -> Log Destinations -> Create... Give it a name, choose type ArcSight , and forward to the log destination you just created. You can now create a log publisher: 1 System -> Logs -> Configuration -> Log Publishers -> Create... Give it a name, and select the ArcSight log destination you just created. You can now use this log publisher to define logging profiles in your BIG-IP modules. As an example in: 1 Access -> Overview -> Event Logs -> Settings -> Create -> Access System Logs -> Publisher or 1 Security -> Event Logs -> Logging Profiles -> Create... -> Publisher","title":"2. Configure a Log Publisher"},{"location":"integrations/f5-big-ip/#3-direct-configuration","text":"Some modules allow direct configuration to the rsyslog server. As an example: 1 Security -> Event Logs -> Logging Profiles -> Create... Then choose Application Security , select Remote Storage as a storage destination, Common Event Format (ArcSight) as a logging format, and fill in your rsyslog server info. The resulting logging profile can be applied to a given virtual server in: 1 Local Traffic -> Virtual Servers -> Virtual Server List Then choose a virtual server, go to the Security -> Policies tab and apply the log profile.","title":"3. Direct Configuration"},{"location":"integrations/f5-big-ip/#related-files","text":"SEKOIA-IO-intake.pem : SEKOIA.IO TLS Server Certificate (1674b)","title":"Related files"},{"location":"integrations/f5-big-ip/#4-enjoy-your-events","text":"Go to the events page to watch your incoming events.","title":"4. Enjoy your events"},{"location":"integrations/fortigate/","text":"Overview The range of Fortigate firewalls is a complete appliance solution whose security functions are highly developed. FortiGate next-generation firewalls provide high performance, multilayered security and deep visibility for end-to-end protection across the enterprise network. Security services from FortiGuard Labs provide threat intelligence updates and automated mitigation. The firewalls run on the FortiOS operating system. Setup This setup guide will show you how to forward your Fortigate firewall logs to SEKOIA.IO by means of an Rsyslog transport channel. On most linux servers, two packages need to be installed: rsyslog and rsyslog-gnutls. 1. Download the certificate In order to allow the connection of your rsyslog server to the SEKOIA.IO intake, please download the SEKOIA.IO intake certificate: 1 $ wget -O /etc/rsyslog.d/SEKOIA-IO-intake.pem https://app.sekoia.io/assets/files/SEKOIA-IO-intake.pem 2. Configure Fortigate The first step is to configure Fortigate to log the awaited traffic. You can configure FortiOS to send log messages to remote syslog servers in standard, CSV or CEF (Common Event Format) format. These three formats are accepted by the SEKOIA.IO intake. To enable syslog, log into the CLI and enter the following commands: 1 2 3 4 5 6 config log syslogd setting set status enable set port 514 set server [ IP address of syslog server ] set facility user end Most FortiGate features are enabled for logging by default, but you can make sure the Traffic, Web and URL Filtering features are enabled for logging with the following commands: 1 2 3 4 5 config log syslogd filter set traffic enable set web enable set url-filter enable end With some Fortigate appliance it may not be possible to do the above configuration through the command line. An alternative method is to use the graphical interface and go to the Log Settings menu. From there you can choose every logging options within Event Logging and Local Traffic Log except for the Denied options. Then in order to use CEF format, use the following commands : 1 2 3 config log syslogd setting set format cef end 3. Configure the Rsyslog server You can configure your Rsyslog server to forward your fortigate logs to SEKOIA.IO. Open or create a new Fortigate configuration file for rsyslog: 1 sudo vim /etc/rsyslog.d/12-fortigate.conf Then paste the following configuration: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Define the SEKIOA-IO intake certificate $DefaultNetstreamDriverCAFile /etc/rsyslog.d/SEKOIA-IO-intake.pem # Configure up the network ssl connection $ActionSendStreamDriver gtls # use gtls netstream driver $ActionSendStreamDriverMode 1 # require TLS for the connection $ActionSendStreamDriverAuthMode x509/name # server is authenticated # Template definition [RFC5424](https://tools.ietf.org/html/rfc5424#section-7.2.2) # IMPORTANT: don't forget to set your intake key in the template template ( name = \"SEKOIAIOFortigateTemplate\" type = \"string\" string = \"<%pri%>1 %timestamp:::date-rfc3339% %hostname% %app-name% %procid% LOG [SEKOIA@53288 intake_key=\\\"YOUR_INTAKE_KEY\\\"] CEF:%msg%\\n\" ) # Send your Fortigate events to SEKOIA.IO intake servers under SEKOIAIOFortigateTemplate template if $hostname == \"YOUR_FORTIGATE_HOSTNAME\" then @@ ( o ) intake.sekoia.io:10514 ; SEKOIAIOFortigateTemplate In the above template instruction, change the YOUR_FORTIGATE_HOSTNAME variable with the correct value, and please replace YOUR_INTAKE_KEY variable with your intake key. 4. Restart rsyslog 1 $ sudo service rsyslog restart Related files SEKOIA-IO-intake.pem : SEKOIA.IO TLS Server Certificate (1674b) 5. Enjoy your events Go to the events page to watch your incoming events.","title":"Fortigate"},{"location":"integrations/fortigate/#overview","text":"The range of Fortigate firewalls is a complete appliance solution whose security functions are highly developed. FortiGate next-generation firewalls provide high performance, multilayered security and deep visibility for end-to-end protection across the enterprise network. Security services from FortiGuard Labs provide threat intelligence updates and automated mitigation. The firewalls run on the FortiOS operating system.","title":"Overview"},{"location":"integrations/fortigate/#setup","text":"This setup guide will show you how to forward your Fortigate firewall logs to SEKOIA.IO by means of an Rsyslog transport channel. On most linux servers, two packages need to be installed: rsyslog and rsyslog-gnutls.","title":"Setup"},{"location":"integrations/fortigate/#1-download-the-certificate","text":"In order to allow the connection of your rsyslog server to the SEKOIA.IO intake, please download the SEKOIA.IO intake certificate: 1 $ wget -O /etc/rsyslog.d/SEKOIA-IO-intake.pem https://app.sekoia.io/assets/files/SEKOIA-IO-intake.pem","title":"1. Download the certificate"},{"location":"integrations/fortigate/#2-configure-fortigate","text":"The first step is to configure Fortigate to log the awaited traffic. You can configure FortiOS to send log messages to remote syslog servers in standard, CSV or CEF (Common Event Format) format. These three formats are accepted by the SEKOIA.IO intake. To enable syslog, log into the CLI and enter the following commands: 1 2 3 4 5 6 config log syslogd setting set status enable set port 514 set server [ IP address of syslog server ] set facility user end Most FortiGate features are enabled for logging by default, but you can make sure the Traffic, Web and URL Filtering features are enabled for logging with the following commands: 1 2 3 4 5 config log syslogd filter set traffic enable set web enable set url-filter enable end With some Fortigate appliance it may not be possible to do the above configuration through the command line. An alternative method is to use the graphical interface and go to the Log Settings menu. From there you can choose every logging options within Event Logging and Local Traffic Log except for the Denied options. Then in order to use CEF format, use the following commands : 1 2 3 config log syslogd setting set format cef end","title":"2. Configure Fortigate"},{"location":"integrations/fortigate/#3-configure-the-rsyslog-server","text":"You can configure your Rsyslog server to forward your fortigate logs to SEKOIA.IO. Open or create a new Fortigate configuration file for rsyslog: 1 sudo vim /etc/rsyslog.d/12-fortigate.conf Then paste the following configuration: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Define the SEKIOA-IO intake certificate $DefaultNetstreamDriverCAFile /etc/rsyslog.d/SEKOIA-IO-intake.pem # Configure up the network ssl connection $ActionSendStreamDriver gtls # use gtls netstream driver $ActionSendStreamDriverMode 1 # require TLS for the connection $ActionSendStreamDriverAuthMode x509/name # server is authenticated # Template definition [RFC5424](https://tools.ietf.org/html/rfc5424#section-7.2.2) # IMPORTANT: don't forget to set your intake key in the template template ( name = \"SEKOIAIOFortigateTemplate\" type = \"string\" string = \"<%pri%>1 %timestamp:::date-rfc3339% %hostname% %app-name% %procid% LOG [SEKOIA@53288 intake_key=\\\"YOUR_INTAKE_KEY\\\"] CEF:%msg%\\n\" ) # Send your Fortigate events to SEKOIA.IO intake servers under SEKOIAIOFortigateTemplate template if $hostname == \"YOUR_FORTIGATE_HOSTNAME\" then @@ ( o ) intake.sekoia.io:10514 ; SEKOIAIOFortigateTemplate In the above template instruction, change the YOUR_FORTIGATE_HOSTNAME variable with the correct value, and please replace YOUR_INTAKE_KEY variable with your intake key.","title":"3. Configure the Rsyslog server"},{"location":"integrations/fortigate/#4-restart-rsyslog","text":"1 $ sudo service rsyslog restart","title":"4. Restart rsyslog"},{"location":"integrations/fortigate/#related-files","text":"SEKOIA-IO-intake.pem : SEKOIA.IO TLS Server Certificate (1674b)","title":"Related files"},{"location":"integrations/fortigate/#5-enjoy-your-events","text":"Go to the events page to watch your incoming events.","title":"5. Enjoy your events"},{"location":"integrations/haproxy/","text":"Overview HAProxy is a free, open source software that provides a high availability load balancer and proxy server for TCP and HTTP-based applications that spreads requests across multiple servers. HAProxy has a lot of features and because it is located between your infrastructure and your clients, it can give you a lot of information about either of them. Setup This setup guide will show you how to forward your HAProxy logs to SEKOIA.IO by means of an rsyslog transport channel. On most linux servers, two packages need to be installed: rsyslog and rsyslog-gnutls. 1. Download the certificate In order to allow the connection of your rsyslog server to the SEKOIA.IO intake, please download the SEKOIA.IO intake certificate: 1 $ wget -O /etc/rsyslog.d/SEKOIA-IO-intake.pem https://app.sekoia.io/assets/files/SEKOIA-IO-intake.pem 2. Configure the Rsyslog server Open or create a new Haproxy configuration file for rsyslog: 1 sudo vim /etc/rsyslog.d/49-haproxy.conf Paste the following rsyslog configuration to trigger the emission of haproxy logs by your rsyslog server to SEKOIA.IO. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # Define the SEKIOA-IO intake certificate $DefaultNetstreamDriverCAFile /etc/rsyslog.d/SEKOIA-IO-intake.pem # Configure up the network ssl connection $ActionSendStreamDriver gtls # use gtls netstream driver $ActionSendStreamDriverMode 1 # require TLS for the connection $ActionSendStreamDriverAuthMode x509/name # server is authenticated # Collects haproxy logs out of the dedicated HAProxy socket $AddUnixListenSocket /var/lib/haproxy/dev/log # Template definition [RFC5424](https://tools.ietf.org/html/rfc5424#section-7.2.2) # IMPORTANT: don't forget to set your intake key in the template template ( name = \"SEKOIAIOHaproxyTemplate\" type = \"string\" string = \"<%pri%>1 %timestamp:::date-rfc3339% %hostname% %app-name% %procid% LOG [SEKOIA@53288 intake_key=\\\"YOUR_INTAKE_KEY\\\"] %msg%\\n\" ) # Send your HAProxy events to SEKOIA.IO intake servers under SEKOIAIOHaproxyTemplate template if $programname startswith 'haproxy' then @@ ( o ) intake.sekoia.io:10514 ; SEKOIAIOHaproxyTemplate In the above template instruction, please replace YOUR_INTAKE_KEY variable with your intake key. 3. Restart rsyslog 1 $ sudo service rsyslog restart 4. Enjoy your events Go to the events page to watch your incoming events. Related files SEKOIA-IO-intake.pem : SEKOIA.IO TLS Server Certificate (1674b) Further Reading HAProxy Official Documentation","title":"HAProxy"},{"location":"integrations/haproxy/#overview","text":"HAProxy is a free, open source software that provides a high availability load balancer and proxy server for TCP and HTTP-based applications that spreads requests across multiple servers. HAProxy has a lot of features and because it is located between your infrastructure and your clients, it can give you a lot of information about either of them.","title":"Overview"},{"location":"integrations/haproxy/#setup","text":"This setup guide will show you how to forward your HAProxy logs to SEKOIA.IO by means of an rsyslog transport channel. On most linux servers, two packages need to be installed: rsyslog and rsyslog-gnutls.","title":"Setup"},{"location":"integrations/haproxy/#1-download-the-certificate","text":"In order to allow the connection of your rsyslog server to the SEKOIA.IO intake, please download the SEKOIA.IO intake certificate: 1 $ wget -O /etc/rsyslog.d/SEKOIA-IO-intake.pem https://app.sekoia.io/assets/files/SEKOIA-IO-intake.pem","title":"1. Download the certificate"},{"location":"integrations/haproxy/#2-configure-the-rsyslog-server","text":"Open or create a new Haproxy configuration file for rsyslog: 1 sudo vim /etc/rsyslog.d/49-haproxy.conf Paste the following rsyslog configuration to trigger the emission of haproxy logs by your rsyslog server to SEKOIA.IO. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # Define the SEKIOA-IO intake certificate $DefaultNetstreamDriverCAFile /etc/rsyslog.d/SEKOIA-IO-intake.pem # Configure up the network ssl connection $ActionSendStreamDriver gtls # use gtls netstream driver $ActionSendStreamDriverMode 1 # require TLS for the connection $ActionSendStreamDriverAuthMode x509/name # server is authenticated # Collects haproxy logs out of the dedicated HAProxy socket $AddUnixListenSocket /var/lib/haproxy/dev/log # Template definition [RFC5424](https://tools.ietf.org/html/rfc5424#section-7.2.2) # IMPORTANT: don't forget to set your intake key in the template template ( name = \"SEKOIAIOHaproxyTemplate\" type = \"string\" string = \"<%pri%>1 %timestamp:::date-rfc3339% %hostname% %app-name% %procid% LOG [SEKOIA@53288 intake_key=\\\"YOUR_INTAKE_KEY\\\"] %msg%\\n\" ) # Send your HAProxy events to SEKOIA.IO intake servers under SEKOIAIOHaproxyTemplate template if $programname startswith 'haproxy' then @@ ( o ) intake.sekoia.io:10514 ; SEKOIAIOHaproxyTemplate In the above template instruction, please replace YOUR_INTAKE_KEY variable with your intake key.","title":"2. Configure the Rsyslog server"},{"location":"integrations/haproxy/#3-restart-rsyslog","text":"1 $ sudo service rsyslog restart","title":"3. Restart rsyslog"},{"location":"integrations/haproxy/#4-enjoy-your-events","text":"Go to the events page to watch your incoming events.","title":"4. Enjoy your events"},{"location":"integrations/haproxy/#related-files","text":"SEKOIA-IO-intake.pem : SEKOIA.IO TLS Server Certificate (1674b)","title":"Related files"},{"location":"integrations/haproxy/#further-reading","text":"HAProxy Official Documentation","title":"Further Reading"},{"location":"integrations/linux/","text":"Overview Linux is a family of free and open-source software operating systems built around the Linux kernel. Setup This setup guide will show you how to forward logs produced by your Linux servers to SEKOIA.IO by means of an rsyslog transport channel. On most linux servers, two packages need to be installed: rsyslog and rsyslog-gnutls. 1. Download the certificate In order to allow the connection of your rsyslog server to the SEKOIA.IO intake, please download the SEKOIA.IO intake certificate: 1 $ wget -O /etc/rsyslog.d/SEKOIA-IO-intake.pem https://app.sekoia.io/assets/files/SEKOIA-IO-intake.pem 2. Configure the Rsyslog server By default, a Linux server logs common daemons activities, the above configuration forwards everything. Depending of the linux distribution and installed software, more configuration tuning could be required. Open or create a new Linux configuration file for rsyslog: 1 sudo vim /etc/rsyslog.d/8-linux.conf Paste the following rsyslog configuration to trigger the emission of Linux logs by your rsyslog server to SEKOIA.IO: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Define the SEKIOA-IO intake certificate $DefaultNetstreamDriverCAFile /etc/rsyslog.d/SEKOIA-IO-intake.pem # Configure up the network ssl connection $ActionSendStreamDriver gtls # use gtls netstream driver $ActionSendStreamDriverMode 1 # require TLS for the connection $ActionSendStreamDriverAuthMode x509/name # server is authenticated # Template definition [RFC5424](https://tools.ietf.org/html/rfc5424#section-7.2.2) # IMPORTANT: don't forget to set your intake key in the template template ( name = \"SEKOIAIOLinuxTemplate\" type = \"string\" string = \"<%pri%>1 %timestamp:::date-rfc3339% %hostname% %app-name% %procid% LOG [SEKOIA@53288 intake_key=\\\"YOUR_INTAKE_KEY\\\"] %msg%\\n\" ) # Send your events to SEKOIA.IO intake servers under SEKOIAIOLinuxTemplate template if $hostname == \"YOUR_LINUX_HOSTNAME\" then @@ ( o ) intake.sekoia.io:10514 ; SEKOIAIOLinuxTemplate In the above template instruction, change the YOUR_LINUX_HOSTNAME variable with the correct value, and please replace YOUR_INTAKE_KEY variable with your intake key. 3. Restart rsyslog 1 $ sudo service rsyslog restart 4. Enjoy your events Go to the events page to watch your incoming events. Related files SEKOIA-IO-intake.pem : SEKOIA.IO TLS Server Certificate (1674b) Further Readings Logging with rsyslog on Redhat","title":"Linux"},{"location":"integrations/linux/#overview","text":"Linux is a family of free and open-source software operating systems built around the Linux kernel.","title":"Overview"},{"location":"integrations/linux/#setup","text":"This setup guide will show you how to forward logs produced by your Linux servers to SEKOIA.IO by means of an rsyslog transport channel. On most linux servers, two packages need to be installed: rsyslog and rsyslog-gnutls.","title":"Setup"},{"location":"integrations/linux/#1-download-the-certificate","text":"In order to allow the connection of your rsyslog server to the SEKOIA.IO intake, please download the SEKOIA.IO intake certificate: 1 $ wget -O /etc/rsyslog.d/SEKOIA-IO-intake.pem https://app.sekoia.io/assets/files/SEKOIA-IO-intake.pem","title":"1. Download the certificate"},{"location":"integrations/linux/#2-configure-the-rsyslog-server","text":"By default, a Linux server logs common daemons activities, the above configuration forwards everything. Depending of the linux distribution and installed software, more configuration tuning could be required. Open or create a new Linux configuration file for rsyslog: 1 sudo vim /etc/rsyslog.d/8-linux.conf Paste the following rsyslog configuration to trigger the emission of Linux logs by your rsyslog server to SEKOIA.IO: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Define the SEKIOA-IO intake certificate $DefaultNetstreamDriverCAFile /etc/rsyslog.d/SEKOIA-IO-intake.pem # Configure up the network ssl connection $ActionSendStreamDriver gtls # use gtls netstream driver $ActionSendStreamDriverMode 1 # require TLS for the connection $ActionSendStreamDriverAuthMode x509/name # server is authenticated # Template definition [RFC5424](https://tools.ietf.org/html/rfc5424#section-7.2.2) # IMPORTANT: don't forget to set your intake key in the template template ( name = \"SEKOIAIOLinuxTemplate\" type = \"string\" string = \"<%pri%>1 %timestamp:::date-rfc3339% %hostname% %app-name% %procid% LOG [SEKOIA@53288 intake_key=\\\"YOUR_INTAKE_KEY\\\"] %msg%\\n\" ) # Send your events to SEKOIA.IO intake servers under SEKOIAIOLinuxTemplate template if $hostname == \"YOUR_LINUX_HOSTNAME\" then @@ ( o ) intake.sekoia.io:10514 ; SEKOIAIOLinuxTemplate In the above template instruction, change the YOUR_LINUX_HOSTNAME variable with the correct value, and please replace YOUR_INTAKE_KEY variable with your intake key.","title":"2. Configure the Rsyslog server"},{"location":"integrations/linux/#3-restart-rsyslog","text":"1 $ sudo service rsyslog restart","title":"3. Restart rsyslog"},{"location":"integrations/linux/#4-enjoy-your-events","text":"Go to the events page to watch your incoming events.","title":"4. Enjoy your events"},{"location":"integrations/linux/#related-files","text":"SEKOIA-IO-intake.pem : SEKOIA.IO TLS Server Certificate (1674b)","title":"Related files"},{"location":"integrations/linux/#further-readings","text":"Logging with rsyslog on Redhat","title":"Further Readings"},{"location":"integrations/log_insight_windows/","text":"Overview Microsoft Windows is a popular operating system developed by Microsoft since 1985. It's available in three variants: Windows for desktop/laptop computers, tablets and smartphones Windows Server for servers Windows PE as a lightweight version. Setup This setup guide will show you how to forward events produced by a Windows system, collected by Log Insight agent and forward to SEKOIA.IO through your local rsyslog server. Configure the forwarder through rsyslog Rsyslog setup on Linux Server Download the certificate In order to allow the connection of your rsyslog server to the SEKOIA.IO intake, please download the SEKOIA.IO intake certificate: 1 $ wget -O /etc/rsyslog.d/SEKOIA-IO-intake.pem https://app.sekoia.io/assets/files/SEKOIA-IO-intake.pem Configure the Rsyslog server Open or create a new windows configuration file for rsyslog: 1 sudo vim /etc/rsyslog.d/15-windows.conf Paste the following rsyslog configuration to trigger the emission of windows logs by your rsyslog server to SEKOIA.IO: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Define the SEKIOA-IO intake certificate $DefaultNetstreamDriverCAFile /etc/rsyslog.d/SEKOIA-IO-intake.pem # Configure up the network ssl connection $ActionSendStreamDriver gtls # use gtls netstream driver $ActionSendStreamDriverMode 1 # require TLS for the connection $ActionSendStreamDriverAuthMode x509/name # server is authenticated # Template definition [RFC5424](https://tools.ietf.org/html/rfc5424#section-7.2.2) # IMPORTANT: don't forget to set your intake key in the template template ( name = \"SEKOIAIOWindowsTemplate\" type = \"string\" string = \"<%pri%>1 %timestamp:::date-rfc3339% %hostname% %app-name% %procid% LOG [SEKOIA@53288 intake_key=\\\"YOUR_INTAKE_KEY\\\"] %msg%\\n\" ) # Send your events to SEKOIA.IO intake servers under SEKOIAIOWindowsTemplate template if $programname contains 'Microsoft-Windows' then @@ ( o ) intake.sekoia.io:10514 ; SEKOIAIOWindowsTemplate In the above template instruction, please replace YOUR_INTAKE_KEY variable with your intake key. Restart rsyslog 1 $ sudo service rsyslog restart 3. Enjoy your events Go to the events page to watch your incoming events.","title":"Log Insight Windows"},{"location":"integrations/log_insight_windows/#overview","text":"Microsoft Windows is a popular operating system developed by Microsoft since 1985. It's available in three variants: Windows for desktop/laptop computers, tablets and smartphones Windows Server for servers Windows PE as a lightweight version.","title":"Overview"},{"location":"integrations/log_insight_windows/#setup","text":"This setup guide will show you how to forward events produced by a Windows system, collected by Log Insight agent and forward to SEKOIA.IO through your local rsyslog server.","title":"Setup"},{"location":"integrations/log_insight_windows/#configure-the-forwarder-through-rsyslog","text":"","title":"Configure the forwarder through rsyslog"},{"location":"integrations/log_insight_windows/#rsyslog-setup-on-linux-server","text":"","title":"Rsyslog setup on Linux Server"},{"location":"integrations/log_insight_windows/#download-the-certificate","text":"In order to allow the connection of your rsyslog server to the SEKOIA.IO intake, please download the SEKOIA.IO intake certificate: 1 $ wget -O /etc/rsyslog.d/SEKOIA-IO-intake.pem https://app.sekoia.io/assets/files/SEKOIA-IO-intake.pem","title":"Download the certificate"},{"location":"integrations/log_insight_windows/#configure-the-rsyslog-server","text":"Open or create a new windows configuration file for rsyslog: 1 sudo vim /etc/rsyslog.d/15-windows.conf Paste the following rsyslog configuration to trigger the emission of windows logs by your rsyslog server to SEKOIA.IO: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Define the SEKIOA-IO intake certificate $DefaultNetstreamDriverCAFile /etc/rsyslog.d/SEKOIA-IO-intake.pem # Configure up the network ssl connection $ActionSendStreamDriver gtls # use gtls netstream driver $ActionSendStreamDriverMode 1 # require TLS for the connection $ActionSendStreamDriverAuthMode x509/name # server is authenticated # Template definition [RFC5424](https://tools.ietf.org/html/rfc5424#section-7.2.2) # IMPORTANT: don't forget to set your intake key in the template template ( name = \"SEKOIAIOWindowsTemplate\" type = \"string\" string = \"<%pri%>1 %timestamp:::date-rfc3339% %hostname% %app-name% %procid% LOG [SEKOIA@53288 intake_key=\\\"YOUR_INTAKE_KEY\\\"] %msg%\\n\" ) # Send your events to SEKOIA.IO intake servers under SEKOIAIOWindowsTemplate template if $programname contains 'Microsoft-Windows' then @@ ( o ) intake.sekoia.io:10514 ; SEKOIAIOWindowsTemplate In the above template instruction, please replace YOUR_INTAKE_KEY variable with your intake key.","title":"Configure the Rsyslog server"},{"location":"integrations/log_insight_windows/#restart-rsyslog","text":"1 $ sudo service rsyslog restart","title":"Restart rsyslog"},{"location":"integrations/log_insight_windows/#3-enjoy-your-events","text":"Go to the events page to watch your incoming events.","title":"3. Enjoy your events"},{"location":"integrations/netfilter/","text":"Overview Netfilter is a framework provided by the Linux kernel that offers various functions and operations for packet filtering, network address translation, and port translation. The firewall ruleset might be configured by using several user-space tools such as iptables or nftables or even with high level configuration tools such as firewalld, UFW or ferm. The framework also provides several ways to log events ( LOG , NFLOG , ULOG , etc.). In this example, we only cover the iptables syntax and the basic LOG targets that sends messages to your local syslog server. The only requirement from SEKOIA.IO\u2019s perspective is that your iptables uses the following prefix: IPTables/XXX: ( XXX is user configurable and represents the action, could be Dropped for example). Setup This setup guide will show you how to forward your Linux firewall logs to SEKOIA.IO by means of an Rsyslog transport channel. On most linux servers, two packages need to be installed: rsyslog and rsyslog-gnutls. 1. Download the certificate In order to allow the connection of your rsyslog server to the SEKOIA.IO intake, please download the SEKOIA.IO intake certificate: 1 $ wget -O /etc/rsyslog.d/SEKOIA-IO-intake.pem https://app.sekoia.io/assets/files/SEKOIA-IO-intake.pem 2. Configure Netfilter The first step is to configure Netfilter to log the awaited trafic. For example, if you want to only allow HTTP and HTTPS trafic and log everything else, you could use the following iptables commands: 1 2 3 4 5 6 7 8 9 10 11 12 13 # Create a chain that logs packets and then drops them. $ iptables -N DROP_LOGGING $ iptables -A DROP_LOGGING -m limit --limit 60 /min -j LOG --log-prefix \"IPTables/Dropped: \" --log-level 4 $ iptables -A DROP_LOGGING -j DROP # Allow established communications. $ iptables -A INPUT -m conntrack --ctstate ESTABLISHED,RELATED -j ACCEPT # Allow HTTP communications. $ iptables -A INPUT -p tcp --dport 80 ,443 -m conntrack --ctstate NEW,ESTABLISHED -j ACCEPT # Log and drop everything else. $ iptables -A INPUT -j DROP_LOGGING 3. Configure the Rsyslog server You can configure your Rsyslog server to forward your iptables logs to SEKOIA.IO. Open or create a new Netfilter configuration file for rsyslog: 1 sudo vim /etc/rsyslog.d/11-netfilter.conf Then paste the following configuration: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Define the SEKIOA-IO intake certificate $DefaultNetstreamDriverCAFile /etc/rsyslog.d/SEKOIA-IO-intake.pem # Configure up the network ssl connection $ActionSendStreamDriver gtls # use gtls netstream driver $ActionSendStreamDriverMode 1 # require TLS for the connection $ActionSendStreamDriverAuthMode x509/name # server is authenticated # Template definition [RFC5424](https://tools.ietf.org/html/rfc5424#section-7.2.2) # IMPORTANT: don't forget to set your intake key in the template template ( name = \"SEKOIAIONetfilterTemplate\" type = \"string\" string = \"<%pri%>1 %timestamp:::date-rfc3339% %hostname% %app-name% %procid% LOG [SEKOIA@53288 intake_key=\\\"YOUR_INTAKE_KEY\\\"] %msg%\\n\" ) # Send your Netfilter events to SEKOIA.IO intake servers under SEKOIAIONetfilterTemplate template if $programname == \"kernel\" and $msg contains \"IPTables/\" then @@ ( o ) intake.sekoia.io:10514 ; SEKOIAIONetfilterTemplate In the above template instruction, please replace YOUR_INTAKE_KEY variable with your intake key. 4. Restart rsyslog 1 $ sudo service rsyslog restart 5. Enjoy your events Go to the events page to watch your incoming events. Related files SEKOIA-IO-intake.pem : SEKOIA.IO TLS Server Certificate (1674b) Further Reading netfilter/iptables project homepage","title":"NetFilter"},{"location":"integrations/netfilter/#overview","text":"Netfilter is a framework provided by the Linux kernel that offers various functions and operations for packet filtering, network address translation, and port translation. The firewall ruleset might be configured by using several user-space tools such as iptables or nftables or even with high level configuration tools such as firewalld, UFW or ferm. The framework also provides several ways to log events ( LOG , NFLOG , ULOG , etc.). In this example, we only cover the iptables syntax and the basic LOG targets that sends messages to your local syslog server. The only requirement from SEKOIA.IO\u2019s perspective is that your iptables uses the following prefix: IPTables/XXX: ( XXX is user configurable and represents the action, could be Dropped for example).","title":"Overview"},{"location":"integrations/netfilter/#setup","text":"This setup guide will show you how to forward your Linux firewall logs to SEKOIA.IO by means of an Rsyslog transport channel. On most linux servers, two packages need to be installed: rsyslog and rsyslog-gnutls.","title":"Setup"},{"location":"integrations/netfilter/#1-download-the-certificate","text":"In order to allow the connection of your rsyslog server to the SEKOIA.IO intake, please download the SEKOIA.IO intake certificate: 1 $ wget -O /etc/rsyslog.d/SEKOIA-IO-intake.pem https://app.sekoia.io/assets/files/SEKOIA-IO-intake.pem","title":"1. Download the certificate"},{"location":"integrations/netfilter/#2-configure-netfilter","text":"The first step is to configure Netfilter to log the awaited trafic. For example, if you want to only allow HTTP and HTTPS trafic and log everything else, you could use the following iptables commands: 1 2 3 4 5 6 7 8 9 10 11 12 13 # Create a chain that logs packets and then drops them. $ iptables -N DROP_LOGGING $ iptables -A DROP_LOGGING -m limit --limit 60 /min -j LOG --log-prefix \"IPTables/Dropped: \" --log-level 4 $ iptables -A DROP_LOGGING -j DROP # Allow established communications. $ iptables -A INPUT -m conntrack --ctstate ESTABLISHED,RELATED -j ACCEPT # Allow HTTP communications. $ iptables -A INPUT -p tcp --dport 80 ,443 -m conntrack --ctstate NEW,ESTABLISHED -j ACCEPT # Log and drop everything else. $ iptables -A INPUT -j DROP_LOGGING","title":"2. Configure Netfilter"},{"location":"integrations/netfilter/#3-configure-the-rsyslog-server","text":"You can configure your Rsyslog server to forward your iptables logs to SEKOIA.IO. Open or create a new Netfilter configuration file for rsyslog: 1 sudo vim /etc/rsyslog.d/11-netfilter.conf Then paste the following configuration: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Define the SEKIOA-IO intake certificate $DefaultNetstreamDriverCAFile /etc/rsyslog.d/SEKOIA-IO-intake.pem # Configure up the network ssl connection $ActionSendStreamDriver gtls # use gtls netstream driver $ActionSendStreamDriverMode 1 # require TLS for the connection $ActionSendStreamDriverAuthMode x509/name # server is authenticated # Template definition [RFC5424](https://tools.ietf.org/html/rfc5424#section-7.2.2) # IMPORTANT: don't forget to set your intake key in the template template ( name = \"SEKOIAIONetfilterTemplate\" type = \"string\" string = \"<%pri%>1 %timestamp:::date-rfc3339% %hostname% %app-name% %procid% LOG [SEKOIA@53288 intake_key=\\\"YOUR_INTAKE_KEY\\\"] %msg%\\n\" ) # Send your Netfilter events to SEKOIA.IO intake servers under SEKOIAIONetfilterTemplate template if $programname == \"kernel\" and $msg contains \"IPTables/\" then @@ ( o ) intake.sekoia.io:10514 ; SEKOIAIONetfilterTemplate In the above template instruction, please replace YOUR_INTAKE_KEY variable with your intake key.","title":"3. Configure the Rsyslog server"},{"location":"integrations/netfilter/#4-restart-rsyslog","text":"1 $ sudo service rsyslog restart","title":"4. Restart rsyslog"},{"location":"integrations/netfilter/#5-enjoy-your-events","text":"Go to the events page to watch your incoming events.","title":"5. Enjoy your events"},{"location":"integrations/netfilter/#related-files","text":"SEKOIA-IO-intake.pem : SEKOIA.IO TLS Server Certificate (1674b)","title":"Related files"},{"location":"integrations/netfilter/#further-reading","text":"netfilter/iptables project homepage","title":"Further Reading"},{"location":"integrations/nginx/","text":"Overview Nginx is an HTTP and reverse proxy server, a mail proxy server, and a generic TCP/UDP proxy server. It has a lot of features and because it is located between your application and your clients, it can give you a lot of information about either of them. Setup This setup guide will show you how to forward both your NGINX access and error logs to SEKOIA.IO by means of an rsyslog transport channel. 1. Download the certificate In order to allow the connection of your rsyslog server to the SEKOIA.IO intake, please download the SEKOIA.IO intake certificate: On most linux servers, two packages need to be installed: rsyslog and rsyslog-gnutls. 1 $ wget -O /etc/rsyslog.d/SEKOIA-IO-intake.pem https://app.sekoia.io/assets/files/SEKOIA-IO-intake.pem 2. Configure the Rsyslog server We can configure rsyslog to parse the access_log and error_log and report its entries to SEKOIA.IO. Open or create a new Nginx configuration file for rsyslog: 1 sudo vim /etc/rsyslog.d/28-nginx.conf At the beginning of the configuration file, paste the following instruction to order the rsyslog server to load the module imfile : 1 $ModLoad imfile Then paste the following configuration to leverage this module to monitor Nginx access and error output files (please note that the path to the log file may change depending on the OS and your configuration): 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 # Define the SEKIOA-IO intake certificate $DefaultNetstreamDriverCAFile /etc/rsyslog.d/SEKOIA-IO-intake.pem # Configure up the network ssl connection $ActionSendStreamDriver gtls # use gtls netstream driver $ActionSendStreamDriverMode 1 # require TLS for the connection $ActionSendStreamDriverAuthMode x509/name # server is authenticated # error log $InputFileName /var/log/nginx/error.log $InputFileTag nginx: $InputFileStateFile stat-nginx-error $InputFileSeverity error $InputFileFacility local5 $InputFilePollInterval 1 $InputRunFileMonitor # access log $InputFileName /var/log/nginx/access.log $InputFileTag nginx: $InputFileStateFile stat-nginx-access $InputFileSeverity notice $InputFileFacility local5 $InputFilePollInterval 1 $InputRunFileMonitor # Template definition [RFC5424](https://tools.ietf.org/html/rfc5424#section-7.2.2) # IMPORTANT: don't forget to set your intake key in the template template ( name = \"SEKOIAIONginxTemplate\" type = \"string\" string = \"<%pri%>1 %timestamp:::date-rfc3339% %hostname% %app-name% %procid% LOG [SEKOIA@53288 intake_key=\\\"YOUR_INTAKE_KEY\\\"] %msg%\\n\" ) # Send your events to SEKOIA.IO intake servers under SEKOIAIONginxTemplate template if $programname startswith 'nginx' then @@ ( o ) intake.sekoia.io:10514 ; SEKOIAIONginxTemplate In the above template instruction, please replace YOUR_INTAKE_KEY variable with your intake key. 3. Restart rsyslog 1 $ sudo service rsyslog restart 4. Enjoy your events Go to the events page to watch your incoming events. Related files SEKOIA-IO-intake.pem : SEKOIA.IO TLS Server Certificate (1674b) Further Reading Nginx Wiki Rsyslog IMFile module","title":"Nginx"},{"location":"integrations/nginx/#overview","text":"Nginx is an HTTP and reverse proxy server, a mail proxy server, and a generic TCP/UDP proxy server. It has a lot of features and because it is located between your application and your clients, it can give you a lot of information about either of them.","title":"Overview"},{"location":"integrations/nginx/#setup","text":"This setup guide will show you how to forward both your NGINX access and error logs to SEKOIA.IO by means of an rsyslog transport channel.","title":"Setup"},{"location":"integrations/nginx/#1-download-the-certificate","text":"In order to allow the connection of your rsyslog server to the SEKOIA.IO intake, please download the SEKOIA.IO intake certificate: On most linux servers, two packages need to be installed: rsyslog and rsyslog-gnutls. 1 $ wget -O /etc/rsyslog.d/SEKOIA-IO-intake.pem https://app.sekoia.io/assets/files/SEKOIA-IO-intake.pem","title":"1. Download the certificate"},{"location":"integrations/nginx/#2-configure-the-rsyslog-server","text":"We can configure rsyslog to parse the access_log and error_log and report its entries to SEKOIA.IO. Open or create a new Nginx configuration file for rsyslog: 1 sudo vim /etc/rsyslog.d/28-nginx.conf At the beginning of the configuration file, paste the following instruction to order the rsyslog server to load the module imfile : 1 $ModLoad imfile Then paste the following configuration to leverage this module to monitor Nginx access and error output files (please note that the path to the log file may change depending on the OS and your configuration): 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 # Define the SEKIOA-IO intake certificate $DefaultNetstreamDriverCAFile /etc/rsyslog.d/SEKOIA-IO-intake.pem # Configure up the network ssl connection $ActionSendStreamDriver gtls # use gtls netstream driver $ActionSendStreamDriverMode 1 # require TLS for the connection $ActionSendStreamDriverAuthMode x509/name # server is authenticated # error log $InputFileName /var/log/nginx/error.log $InputFileTag nginx: $InputFileStateFile stat-nginx-error $InputFileSeverity error $InputFileFacility local5 $InputFilePollInterval 1 $InputRunFileMonitor # access log $InputFileName /var/log/nginx/access.log $InputFileTag nginx: $InputFileStateFile stat-nginx-access $InputFileSeverity notice $InputFileFacility local5 $InputFilePollInterval 1 $InputRunFileMonitor # Template definition [RFC5424](https://tools.ietf.org/html/rfc5424#section-7.2.2) # IMPORTANT: don't forget to set your intake key in the template template ( name = \"SEKOIAIONginxTemplate\" type = \"string\" string = \"<%pri%>1 %timestamp:::date-rfc3339% %hostname% %app-name% %procid% LOG [SEKOIA@53288 intake_key=\\\"YOUR_INTAKE_KEY\\\"] %msg%\\n\" ) # Send your events to SEKOIA.IO intake servers under SEKOIAIONginxTemplate template if $programname startswith 'nginx' then @@ ( o ) intake.sekoia.io:10514 ; SEKOIAIONginxTemplate In the above template instruction, please replace YOUR_INTAKE_KEY variable with your intake key.","title":"2. Configure the Rsyslog server"},{"location":"integrations/nginx/#3-restart-rsyslog","text":"1 $ sudo service rsyslog restart","title":"3. Restart rsyslog"},{"location":"integrations/nginx/#4-enjoy-your-events","text":"Go to the events page to watch your incoming events.","title":"4. Enjoy your events"},{"location":"integrations/nginx/#related-files","text":"SEKOIA-IO-intake.pem : SEKOIA.IO TLS Server Certificate (1674b)","title":"Related files"},{"location":"integrations/nginx/#further-reading","text":"Nginx Wiki Rsyslog IMFile module","title":"Further Reading"},{"location":"integrations/o365/","text":"Overview Office 365 is a line of subscription services offered by Microsoft as part of the Microsoft Office product line. Setup This setup guide will show you how to forward events produced by Office 365 service to SEKOIA.IO. Theses changes have to be made from the Azure web portal ( https://portal.azure.com ). 1. Event hubs As a prerequisite you need an Event Hubs (e.g. company-eventhub) and to choose an existing resourceGroup or create a new one (e.g. company-resource-group). You also need your Subscription ID if you don't have a default one. Navigate to: Home > Cost Management + Billing > Subscriptions . From there, copy the relevant Subscription ID that will be used in the command line (e.g. uuid) Then you use Azure powershell (within Cloud Shell interface for example): you will a create a global Event Hubs , then specific Event Hub (e.g. o365-event). 1 2 3 PS Azure : \\> az eventhubs namespace create - -name company-eventhub - -resource-group company-resource-group - -enable-kafka true - -subscription uuid PS Azure : \\> az eventhubs eventhub create - -resource-group company-resource-group - -namespace-name company-eventhub - -name o365-event - -message-retention 3 - -partition-count 4 - -subscription uuid Navigate to: Home > Event Hubs > company-eventhub - Shared access policies . From there, you can create a policy (e.g. RootManageSharedAccessKey) with the claims Manage , Send and Listen , and note the Primary Key that will be used as the SharedAccessKey . Navigate to: Home > Event Hubs > company-eventhub > o365-event - Shared access policies . From there, you can create a policy (e.g. sekoiaio-nifi) with the claims Listen . Once created, click on the policy and save the Connection string-primary key , to be sent to SEKOIA.IO. Navigate to: Home > Event Hubs > company-eventhub > o365-event - Consumer groups . From there, you can create a consumer group (e.g. sekoiaio-nifi). 2. Office 365 Office 365 has to be added through Azure portal following the Microsoft documentation Then you need to activate and configure the Office 365 diagnostic settings. Navigate to: Home > Office 365 > Monitoring > Diagnostic settings : Add a new diagnostic setting, and select Stream to an event hub and click on configure. Select the previously created Event hubs , Event Hub and SharedAccessKey . Choose a name for this configuration and click on Save . 3. Enjoy your events You can send to Sekoia the Connection string-primary key previously mentioned. Once the configuration has been done on Sekoia side, you can go to the events page to watch your incoming events. Further Readings Microsoft Stream Azure monitoring data to an event hub","title":"Microsoft Office 365"},{"location":"integrations/o365/#overview","text":"Office 365 is a line of subscription services offered by Microsoft as part of the Microsoft Office product line.","title":"Overview"},{"location":"integrations/o365/#setup","text":"This setup guide will show you how to forward events produced by Office 365 service to SEKOIA.IO. Theses changes have to be made from the Azure web portal ( https://portal.azure.com ).","title":"Setup"},{"location":"integrations/o365/#1-event-hubs","text":"As a prerequisite you need an Event Hubs (e.g. company-eventhub) and to choose an existing resourceGroup or create a new one (e.g. company-resource-group). You also need your Subscription ID if you don't have a default one. Navigate to: Home > Cost Management + Billing > Subscriptions . From there, copy the relevant Subscription ID that will be used in the command line (e.g. uuid) Then you use Azure powershell (within Cloud Shell interface for example): you will a create a global Event Hubs , then specific Event Hub (e.g. o365-event). 1 2 3 PS Azure : \\> az eventhubs namespace create - -name company-eventhub - -resource-group company-resource-group - -enable-kafka true - -subscription uuid PS Azure : \\> az eventhubs eventhub create - -resource-group company-resource-group - -namespace-name company-eventhub - -name o365-event - -message-retention 3 - -partition-count 4 - -subscription uuid Navigate to: Home > Event Hubs > company-eventhub - Shared access policies . From there, you can create a policy (e.g. RootManageSharedAccessKey) with the claims Manage , Send and Listen , and note the Primary Key that will be used as the SharedAccessKey . Navigate to: Home > Event Hubs > company-eventhub > o365-event - Shared access policies . From there, you can create a policy (e.g. sekoiaio-nifi) with the claims Listen . Once created, click on the policy and save the Connection string-primary key , to be sent to SEKOIA.IO. Navigate to: Home > Event Hubs > company-eventhub > o365-event - Consumer groups . From there, you can create a consumer group (e.g. sekoiaio-nifi).","title":"1. Event hubs"},{"location":"integrations/o365/#2-office-365","text":"Office 365 has to be added through Azure portal following the Microsoft documentation Then you need to activate and configure the Office 365 diagnostic settings. Navigate to: Home > Office 365 > Monitoring > Diagnostic settings : Add a new diagnostic setting, and select Stream to an event hub and click on configure. Select the previously created Event hubs , Event Hub and SharedAccessKey . Choose a name for this configuration and click on Save .","title":"2. Office 365"},{"location":"integrations/o365/#3-enjoy-your-events","text":"You can send to Sekoia the Connection string-primary key previously mentioned. Once the configuration has been done on Sekoia side, you can go to the events page to watch your incoming events.","title":"3. Enjoy your events"},{"location":"integrations/o365/#further-readings","text":"Microsoft Stream Azure monitoring data to an event hub","title":"Further Readings"},{"location":"integrations/openssh/","text":"Overview OpenSSH is the premier connectivity tool for remote login with the SSH protocol. It encrypts all traffic to eliminate eavesdropping, connection hijacking, and other attacks. In addition, OpenSSH provides a large suite of secure tunneling capabilities, several authentication methods, and sophisticated configuration options. Setup This setup guide will show you how to forward logs produced by your OpenSSH servers to SEKOIA.IO by means of an rsyslog transport channel. On most linux servers, two packages need to be installed: rsyslog and rsyslog-gnutls. 1. Download the certificate In order to allow the connection of your rsyslog server to the SEKOIA.IO intake, please download the SEKOIA.IO intake certificate: 1 $ wget -O /etc/rsyslog.d/SEKOIA-IO-intake.pem https://app.sekoia.io/assets/files/SEKOIA-IO-intake.pem 2. Configure the Rsyslog server By default, the OpenSSH server ( sshd ) leverages the log level INFO and the system log facility AUTH . Open or create a new OpenSSH configuration file for rsyslog: 1 sudo vim /etc/rsyslog.d/6-openssh.conf Paste the following rsyslog configuration to trigger the emission of OpenSSH logs by your rsyslog server to SEKOIA.IO: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Define the SEKIOA-IO intake certificate $DefaultNetstreamDriverCAFile /etc/rsyslog.d/SEKOIA-IO-intake.pem # Configure up the network ssl connection $ActionSendStreamDriver gtls # use gtls netstream driver $ActionSendStreamDriverMode 1 # require TLS for the connection $ActionSendStreamDriverAuthMode x509/name # server is authenticated # Template definition [RFC5424](https://tools.ietf.org/html/rfc5424#section-7.2.2) # IMPORTANT: don't forget to set your intake key in the template template ( name = \"SEKOIAIOOpenSSHTemplate\" type = \"string\" string = \"<%pri%>1 %timestamp:::date-rfc3339% %hostname% %app-name% %procid% LOG [SEKOIA@53288 intake_key=\\\"YOUR_INTAKE_KEY\\\"] %msg%\\n\" ) # Send your events to SEKOIA.IO intake servers under SEKOIAIOOpenSSHTemplate template if $programname startswith 'sshd' then @@ ( o ) intake.sekoia.io:10514 ; SEKOIAIOOpenSSHTemplate In the above template instruction, please replace YOUR_INTAKE_KEY variable with your intake key. 3. Restart rsyslog 1 $ sudo service rsyslog restart 4. Enjoy your events Go to the events page to watch your incoming events. Related files SEKOIA-IO-intake.pem : SEKOIA.IO TLS Server Certificate (1674b) Further Readings OpenSSH Manuals OpenSSH Logging and Troubleshooting","title":"OpenSSH"},{"location":"integrations/openssh/#overview","text":"OpenSSH is the premier connectivity tool for remote login with the SSH protocol. It encrypts all traffic to eliminate eavesdropping, connection hijacking, and other attacks. In addition, OpenSSH provides a large suite of secure tunneling capabilities, several authentication methods, and sophisticated configuration options.","title":"Overview"},{"location":"integrations/openssh/#setup","text":"This setup guide will show you how to forward logs produced by your OpenSSH servers to SEKOIA.IO by means of an rsyslog transport channel. On most linux servers, two packages need to be installed: rsyslog and rsyslog-gnutls.","title":"Setup"},{"location":"integrations/openssh/#1-download-the-certificate","text":"In order to allow the connection of your rsyslog server to the SEKOIA.IO intake, please download the SEKOIA.IO intake certificate: 1 $ wget -O /etc/rsyslog.d/SEKOIA-IO-intake.pem https://app.sekoia.io/assets/files/SEKOIA-IO-intake.pem","title":"1. Download the certificate"},{"location":"integrations/openssh/#2-configure-the-rsyslog-server","text":"By default, the OpenSSH server ( sshd ) leverages the log level INFO and the system log facility AUTH . Open or create a new OpenSSH configuration file for rsyslog: 1 sudo vim /etc/rsyslog.d/6-openssh.conf Paste the following rsyslog configuration to trigger the emission of OpenSSH logs by your rsyslog server to SEKOIA.IO: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Define the SEKIOA-IO intake certificate $DefaultNetstreamDriverCAFile /etc/rsyslog.d/SEKOIA-IO-intake.pem # Configure up the network ssl connection $ActionSendStreamDriver gtls # use gtls netstream driver $ActionSendStreamDriverMode 1 # require TLS for the connection $ActionSendStreamDriverAuthMode x509/name # server is authenticated # Template definition [RFC5424](https://tools.ietf.org/html/rfc5424#section-7.2.2) # IMPORTANT: don't forget to set your intake key in the template template ( name = \"SEKOIAIOOpenSSHTemplate\" type = \"string\" string = \"<%pri%>1 %timestamp:::date-rfc3339% %hostname% %app-name% %procid% LOG [SEKOIA@53288 intake_key=\\\"YOUR_INTAKE_KEY\\\"] %msg%\\n\" ) # Send your events to SEKOIA.IO intake servers under SEKOIAIOOpenSSHTemplate template if $programname startswith 'sshd' then @@ ( o ) intake.sekoia.io:10514 ; SEKOIAIOOpenSSHTemplate In the above template instruction, please replace YOUR_INTAKE_KEY variable with your intake key.","title":"2. Configure the Rsyslog server"},{"location":"integrations/openssh/#3-restart-rsyslog","text":"1 $ sudo service rsyslog restart","title":"3. Restart rsyslog"},{"location":"integrations/openssh/#4-enjoy-your-events","text":"Go to the events page to watch your incoming events.","title":"4. Enjoy your events"},{"location":"integrations/openssh/#related-files","text":"SEKOIA-IO-intake.pem : SEKOIA.IO TLS Server Certificate (1674b)","title":"Related files"},{"location":"integrations/openssh/#further-readings","text":"OpenSSH Manuals OpenSSH Logging and Troubleshooting","title":"Further Readings"},{"location":"integrations/paloalto/","text":"Overview Palo Alto Networks offers an enterprise cybersecurity platform which provides network security, cloud security, endpoint protection, and various cloud-delivered security services. Setup This setup guide will show you how to forward logs produced by your Palo Alto firewalls to SEKOIA.IO by means of an rsyslog transport channel. 1. Download the certificate In order to allow the connection of your rsyslog server to the SEKOIA.IO intake, please download the SEKOIA.IO intake certificate: On most linux servers, two packages need to be installed: rsyslog and rsyslog-gnutls. 1 $ wget -O /etc/rsyslog.d/SEKOIA-IO-intake.pem https://app.sekoia.io/assets/files/SEKOIA-IO-intake.pem 2. Configure the Rsyslog server Open or create a new Palo Alto configuration file for rsyslog: 1 sudo vim /etc/rsyslog.d/38-paloalto.conf Paste the following rsyslog configuration to trigger the emission of Palo Alto logs by your rsyslog server to SEKOIA.IO: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Define the SEKIOA-IO intake certificate $DefaultNetstreamDriverCAFile /etc/rsyslog.d/SEKOIA-IO-intake.pem # Configure up the network ssl connection $ActionSendStreamDriver gtls # use gtls netstream driver $ActionSendStreamDriverMode 1 # require TLS for the connection $ActionSendStreamDriverAuthMode x509/name # server is authenticated # Template definition [RFC5424](https://tools.ietf.org/html/rfc5424#section-7.2.2) # IMPORTANT: don't forget to set your intake key in the template template ( name = \"SEKOIAIOPaloAltoTemplate\" type = \"string\" string = \"<%pri%>1 %timestamp:::date-rfc3339% %hostname% %app-name% %procid% LOG [SEKOIA@53288 intake_key=\\\"YOUR_INTAKE_KEY\\\"] %msg%\\n\" ) # Send your events to SEKOIA.IO intake servers under SEKOIAIOPaloAltoTemplate template if $hostname == \"YOUR_PALOALTO_HOSTNAME\" then @@ ( o ) intake.sekoia.io:10514 ; SEKOIAIOPaloAltoTemplate In the above template instruction, change the YOUR_PALOALTO_HOSTNAME variable with the correct value, and please replace YOUR_INTAKE_KEY variable with your intake key. 3. Restart rsyslog 1 $ sudo service rsyslog restart Related files SEKOIA-IO-intake.pem : SEKOIA.IO TLS Server Certificate (1674b) 4. Enjoy your events Go to the events page to watch your incoming events.","title":"PaloAlto"},{"location":"integrations/paloalto/#overview","text":"Palo Alto Networks offers an enterprise cybersecurity platform which provides network security, cloud security, endpoint protection, and various cloud-delivered security services.","title":"Overview"},{"location":"integrations/paloalto/#setup","text":"This setup guide will show you how to forward logs produced by your Palo Alto firewalls to SEKOIA.IO by means of an rsyslog transport channel.","title":"Setup"},{"location":"integrations/paloalto/#1-download-the-certificate","text":"In order to allow the connection of your rsyslog server to the SEKOIA.IO intake, please download the SEKOIA.IO intake certificate: On most linux servers, two packages need to be installed: rsyslog and rsyslog-gnutls. 1 $ wget -O /etc/rsyslog.d/SEKOIA-IO-intake.pem https://app.sekoia.io/assets/files/SEKOIA-IO-intake.pem","title":"1. Download the certificate"},{"location":"integrations/paloalto/#2-configure-the-rsyslog-server","text":"Open or create a new Palo Alto configuration file for rsyslog: 1 sudo vim /etc/rsyslog.d/38-paloalto.conf Paste the following rsyslog configuration to trigger the emission of Palo Alto logs by your rsyslog server to SEKOIA.IO: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Define the SEKIOA-IO intake certificate $DefaultNetstreamDriverCAFile /etc/rsyslog.d/SEKOIA-IO-intake.pem # Configure up the network ssl connection $ActionSendStreamDriver gtls # use gtls netstream driver $ActionSendStreamDriverMode 1 # require TLS for the connection $ActionSendStreamDriverAuthMode x509/name # server is authenticated # Template definition [RFC5424](https://tools.ietf.org/html/rfc5424#section-7.2.2) # IMPORTANT: don't forget to set your intake key in the template template ( name = \"SEKOIAIOPaloAltoTemplate\" type = \"string\" string = \"<%pri%>1 %timestamp:::date-rfc3339% %hostname% %app-name% %procid% LOG [SEKOIA@53288 intake_key=\\\"YOUR_INTAKE_KEY\\\"] %msg%\\n\" ) # Send your events to SEKOIA.IO intake servers under SEKOIAIOPaloAltoTemplate template if $hostname == \"YOUR_PALOALTO_HOSTNAME\" then @@ ( o ) intake.sekoia.io:10514 ; SEKOIAIOPaloAltoTemplate In the above template instruction, change the YOUR_PALOALTO_HOSTNAME variable with the correct value, and please replace YOUR_INTAKE_KEY variable with your intake key.","title":"2. Configure the Rsyslog server"},{"location":"integrations/paloalto/#3-restart-rsyslog","text":"1 $ sudo service rsyslog restart","title":"3. Restart rsyslog"},{"location":"integrations/paloalto/#related-files","text":"SEKOIA-IO-intake.pem : SEKOIA.IO TLS Server Certificate (1674b)","title":"Related files"},{"location":"integrations/paloalto/#4-enjoy-your-events","text":"Go to the events page to watch your incoming events.","title":"4. Enjoy your events"},{"location":"integrations/postfix/","text":"Overview Postfix is a free and open-source mail transfer agent that routes and delivers electronic mail. Setup This setup guide will show you how to forward logs produced by your Postfix servers to SEKOIA.IO by means of an rsyslog transport channel. On most linux servers, two packages need to be installed: rsyslog and rsyslog-gnutls. 1. Download the certificate In order to allow the connection of your rsyslog server to the SEKOIA.IO intake, please download the SEKOIA.IO intake certificate: 1 $ wget -O /etc/rsyslog.d/SEKOIA-IO-intake.pem https://app.sekoia.io/assets/files/SEKOIA-IO-intake.pem 2. Configure the Rsyslog server Open or create a new Postfix configuration file for rsyslog: 1 sudo vim /etc/rsyslog.d/36-postfix.conf Paste the following rsyslog configuration to trigger the emission of Postfix logs by your rsyslog server to SEKOIA.IO: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Define the SEKIOA-IO intake certificate $DefaultNetstreamDriverCAFile /etc/rsyslog.d/SEKOIA-IO-intake.pem # Configure up the network ssl connection $ActionSendStreamDriver gtls # use gtls netstream driver $ActionSendStreamDriverMode 1 # require TLS for the connection $ActionSendStreamDriverAuthMode x509/name # server is authenticated # Template definition [RFC5424](https://tools.ietf.org/html/rfc5424#section-7.2.2) # IMPORTANT: don't forget to set your intake key in the template template ( name = \"SEKOIAIOPostfixTemplate\" type = \"string\" string = \"<%pri%>1 %timestamp:::date-rfc3339% %hostname% %app-name% %procid% LOG [SEKOIA@53288 intake_key=\\\"YOUR_INTAKE_KEY\\\"] %msg%\\n\" ) # Send your events to SEKOIA.IO intake servers under SEKOIAIOPostfixTemplate template if $programname startswith 'postfix' then @@ ( o ) intake.sekoia.io:10514 ; SEKOIAIOPostfixTemplate In the above template instruction, please replace YOUR_INTAKE_KEY variable with your intake key. 3. Restart rsyslog 1 $ sudo service rsyslog restart Related files SEKOIA-IO-intake.pem : SEKOIA.IO TLS Server Certificate (1674b) 4. Enjoy your events Go to the events page to watch your incoming events.","title":"Postfix"},{"location":"integrations/postfix/#overview","text":"Postfix is a free and open-source mail transfer agent that routes and delivers electronic mail.","title":"Overview"},{"location":"integrations/postfix/#setup","text":"This setup guide will show you how to forward logs produced by your Postfix servers to SEKOIA.IO by means of an rsyslog transport channel. On most linux servers, two packages need to be installed: rsyslog and rsyslog-gnutls.","title":"Setup"},{"location":"integrations/postfix/#1-download-the-certificate","text":"In order to allow the connection of your rsyslog server to the SEKOIA.IO intake, please download the SEKOIA.IO intake certificate: 1 $ wget -O /etc/rsyslog.d/SEKOIA-IO-intake.pem https://app.sekoia.io/assets/files/SEKOIA-IO-intake.pem","title":"1. Download the certificate"},{"location":"integrations/postfix/#2-configure-the-rsyslog-server","text":"Open or create a new Postfix configuration file for rsyslog: 1 sudo vim /etc/rsyslog.d/36-postfix.conf Paste the following rsyslog configuration to trigger the emission of Postfix logs by your rsyslog server to SEKOIA.IO: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Define the SEKIOA-IO intake certificate $DefaultNetstreamDriverCAFile /etc/rsyslog.d/SEKOIA-IO-intake.pem # Configure up the network ssl connection $ActionSendStreamDriver gtls # use gtls netstream driver $ActionSendStreamDriverMode 1 # require TLS for the connection $ActionSendStreamDriverAuthMode x509/name # server is authenticated # Template definition [RFC5424](https://tools.ietf.org/html/rfc5424#section-7.2.2) # IMPORTANT: don't forget to set your intake key in the template template ( name = \"SEKOIAIOPostfixTemplate\" type = \"string\" string = \"<%pri%>1 %timestamp:::date-rfc3339% %hostname% %app-name% %procid% LOG [SEKOIA@53288 intake_key=\\\"YOUR_INTAKE_KEY\\\"] %msg%\\n\" ) # Send your events to SEKOIA.IO intake servers under SEKOIAIOPostfixTemplate template if $programname startswith 'postfix' then @@ ( o ) intake.sekoia.io:10514 ; SEKOIAIOPostfixTemplate In the above template instruction, please replace YOUR_INTAKE_KEY variable with your intake key.","title":"2. Configure the Rsyslog server"},{"location":"integrations/postfix/#3-restart-rsyslog","text":"1 $ sudo service rsyslog restart","title":"3. Restart rsyslog"},{"location":"integrations/postfix/#related-files","text":"SEKOIA-IO-intake.pem : SEKOIA.IO TLS Server Certificate (1674b)","title":"Related files"},{"location":"integrations/postfix/#4-enjoy-your-events","text":"Go to the events page to watch your incoming events.","title":"4. Enjoy your events"},{"location":"integrations/sophos/","text":"Overview Sophos firewalls offer an integrated software solution that provides superior performance in an all-in-one firewall. Its hardened operating system, stateful packet inspection, content filtering (virus & surf protection), application proxies and IPsec based VPN provides powerful solutions to today's security issues. It is designed to maximise networks security without compromising its performance enabling telecommuters, branch offices, customers and suppliers to safely share critical business information. Setup This setup guide will show you how to forward your Sophos logs to SEKOIA.IO by means of an Rsyslog transport channel. 1. Download the certificate In order to allow the connection of your rsyslog server to the SEKOIA.IO intake, please download the SEKOIA.IO intake certificate: 1 $ wget -O /etc/rsyslog.d/SEKOIA-IO-intake.pem https://app.sekoia.io/assets/files/SEKOIA-IO-intake.pem 2. Configure Sophos Firewall You can configure a syslog server in Sophos Firewall by following the instructions below (Which is appropriate for an XG Firewall, please refer to your documentation in other cases). Go to System Services > Log Settings and click Add to configure a syslog server. Enter a name for the syslog server. Enter the IP Address of the syslog server. Messages from the device will be sent to the entered IP address. Enter a Port number that the device will use for communicating with the syslog server. Device will send messages using the selected port. Select the Facility from the available options. Note: Facility informs the syslog server of the log message's source. It is defined by the syslog protocol. You can configure the facility to distinguish log messages from different devices. This parameter helps you identify the device that recorded a specific log file. Select the Severity Level from the available options. Click Save to save the configuration. 3. Configure the Rsyslog server You can configure your Rsyslog server to forward your Sophos logs to SEKOIA.IO. Open or create a new Sophos configuration file for rsyslog: 1 sudo vim /etc/rsyslog.d/23-sophos.conf Then paste the following configuration: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Define the SEKIOA-IO intake certificate $DefaultNetstreamDriverCAFile /etc/rsyslog.d/SEKOIA-IO-intake.pem # Configure up the network ssl connection $ActionSendStreamDriver gtls # use gtls netstream driver $ActionSendStreamDriverMode 1 # require TLS for the connection $ActionSendStreamDriverAuthMode x509/name # server is authenticated # Template definition [RFC5424](https://tools.ietf.org/html/rfc5424#section-7.2.2) # IMPORTANT: don't forget to set your intake key in the template template ( name = \"SEKOIAIOSophosTemplate\" type = \"string\" string = \"<%pri%>1 %timestamp:::date-rfc3339% %hostname% %app-name% %procid% LOG [SEKOIA@53288 intake_key=\\\"YOUR_INTAKE_KEY\\\"] %msg%\\n\" ) # Send your Sophos events to SEKOIA.IO intake servers under SEKOIAIOSophosTemplate template if $hostname == \\\" YOUR_SOPHOS_HOSTNAME \\\" then @@ ( o ) intake.sekoia.io:10514 ; SEKOIAIOSophosTemplate In the above template instruction, change YOUR_SOPHOS_HOSTNAME and YOUR_INTAKE_KEY with the correct values. 4. Restart rsyslog 1 $ sudo service rsyslog restart 5. Enjoy your events Go to the events page to watch your incoming events.","title":"Sophos"},{"location":"integrations/sophos/#overview","text":"Sophos firewalls offer an integrated software solution that provides superior performance in an all-in-one firewall. Its hardened operating system, stateful packet inspection, content filtering (virus & surf protection), application proxies and IPsec based VPN provides powerful solutions to today's security issues. It is designed to maximise networks security without compromising its performance enabling telecommuters, branch offices, customers and suppliers to safely share critical business information.","title":"Overview"},{"location":"integrations/sophos/#setup","text":"This setup guide will show you how to forward your Sophos logs to SEKOIA.IO by means of an Rsyslog transport channel.","title":"Setup"},{"location":"integrations/sophos/#1-download-the-certificate","text":"In order to allow the connection of your rsyslog server to the SEKOIA.IO intake, please download the SEKOIA.IO intake certificate: 1 $ wget -O /etc/rsyslog.d/SEKOIA-IO-intake.pem https://app.sekoia.io/assets/files/SEKOIA-IO-intake.pem","title":"1. Download the certificate"},{"location":"integrations/sophos/#2-configure-sophos-firewall","text":"You can configure a syslog server in Sophos Firewall by following the instructions below (Which is appropriate for an XG Firewall, please refer to your documentation in other cases). Go to System Services > Log Settings and click Add to configure a syslog server. Enter a name for the syslog server. Enter the IP Address of the syslog server. Messages from the device will be sent to the entered IP address. Enter a Port number that the device will use for communicating with the syslog server. Device will send messages using the selected port. Select the Facility from the available options. Note: Facility informs the syslog server of the log message's source. It is defined by the syslog protocol. You can configure the facility to distinguish log messages from different devices. This parameter helps you identify the device that recorded a specific log file. Select the Severity Level from the available options. Click Save to save the configuration.","title":"2. Configure Sophos Firewall"},{"location":"integrations/sophos/#3-configure-the-rsyslog-server","text":"You can configure your Rsyslog server to forward your Sophos logs to SEKOIA.IO. Open or create a new Sophos configuration file for rsyslog: 1 sudo vim /etc/rsyslog.d/23-sophos.conf Then paste the following configuration: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Define the SEKIOA-IO intake certificate $DefaultNetstreamDriverCAFile /etc/rsyslog.d/SEKOIA-IO-intake.pem # Configure up the network ssl connection $ActionSendStreamDriver gtls # use gtls netstream driver $ActionSendStreamDriverMode 1 # require TLS for the connection $ActionSendStreamDriverAuthMode x509/name # server is authenticated # Template definition [RFC5424](https://tools.ietf.org/html/rfc5424#section-7.2.2) # IMPORTANT: don't forget to set your intake key in the template template ( name = \"SEKOIAIOSophosTemplate\" type = \"string\" string = \"<%pri%>1 %timestamp:::date-rfc3339% %hostname% %app-name% %procid% LOG [SEKOIA@53288 intake_key=\\\"YOUR_INTAKE_KEY\\\"] %msg%\\n\" ) # Send your Sophos events to SEKOIA.IO intake servers under SEKOIAIOSophosTemplate template if $hostname == \\\" YOUR_SOPHOS_HOSTNAME \\\" then @@ ( o ) intake.sekoia.io:10514 ; SEKOIAIOSophosTemplate In the above template instruction, change YOUR_SOPHOS_HOSTNAME and YOUR_INTAKE_KEY with the correct values.","title":"3. Configure the Rsyslog server"},{"location":"integrations/sophos/#4-restart-rsyslog","text":"1 $ sudo service rsyslog restart","title":"4. Restart rsyslog"},{"location":"integrations/sophos/#5-enjoy-your-events","text":"Go to the events page to watch your incoming events.","title":"5. Enjoy your events"},{"location":"integrations/spamassassin/","text":"Overview SpamAssassin is a computer program used for e-mail spam filtering. SpamAssassin uses a variety of spam-detection techniques, including DNS-based and fuzzy-checksum-based spam detection, Bayesian filtering, external programs, blacklists and online databases. It is released under the Apache License 2.0 and is now part of the Apache Foundation. Setup This setup guide will show you how to forward logs produced by your SpamAssassin servers to SEKOIA.IO by means of an rsyslog transport channel. On most linux servers, two packages need to be installed: rsyslog and rsyslog-gnutls. 1. Download the certificate In order to allow the connection of your rsyslog server to the SEKOIA.IO intake, please download the SEKOIA.IO intake certificate: 1 $ wget -O /etc/rsyslog.d/SEKOIA-IO-intake.pem https://app.sekoia.io/assets/files/SEKOIA-IO-intake.pem 2. Configure the Rsyslog server Open or create a new SpamAssassin configuration file for rsyslog: 1 sudo vim /etc/rsyslog.d/34-spamassassin.conf Paste the following rsyslog configuration to trigger the emission of SpamAssassin logs by your rsyslog server to SEKOIA.IO: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Define the SEKIOA-IO intake certificate $DefaultNetstreamDriverCAFile /etc/rsyslog.d/SEKOIA-IO-intake.pem # Configure up the network ssl connection $ActionSendStreamDriver gtls # use gtls netstream driver $ActionSendStreamDriverMode 1 # require TLS for the connection $ActionSendStreamDriverAuthMode x509/name # server is authenticated # Template definition [RFC5424](https://tools.ietf.org/html/rfc5424#section-7.2.2) # IMPORTANT: don't forget to set your intake key in the template template ( name = \"SEKOIAIOSpamAssassinTemplate\" type = \"string\" string = \"<%pri%>1 %timestamp:::date-rfc3339% %hostname% %app-name% %procid% LOG [SEKOIA@53288 intake_key=\\\"YOUR_INTAKE_KEY\\\"] %msg%\\n\" ) # Send your events to SEKOIA.IO intake servers under SEKOIAIOSpamAssassinTemplate template if $programname startswith 'spamd' then @@ ( o ) intake.sekoia.io:10514 ; SEKOIAIOSpamAssassinTemplate In the above template instruction, please replace YOUR_INTAKE_KEY variable with your intake key. 3. Restart rsyslog 1 $ sudo service rsyslog restart Related files SEKOIA-IO-intake.pem : SEKOIA.IO TLS Server Certificate (1674b) 4. Enjoy your events Go to the events page to watch your incoming events.","title":"SpamAssassin"},{"location":"integrations/spamassassin/#overview","text":"SpamAssassin is a computer program used for e-mail spam filtering. SpamAssassin uses a variety of spam-detection techniques, including DNS-based and fuzzy-checksum-based spam detection, Bayesian filtering, external programs, blacklists and online databases. It is released under the Apache License 2.0 and is now part of the Apache Foundation.","title":"Overview"},{"location":"integrations/spamassassin/#setup","text":"This setup guide will show you how to forward logs produced by your SpamAssassin servers to SEKOIA.IO by means of an rsyslog transport channel. On most linux servers, two packages need to be installed: rsyslog and rsyslog-gnutls.","title":"Setup"},{"location":"integrations/spamassassin/#1-download-the-certificate","text":"In order to allow the connection of your rsyslog server to the SEKOIA.IO intake, please download the SEKOIA.IO intake certificate: 1 $ wget -O /etc/rsyslog.d/SEKOIA-IO-intake.pem https://app.sekoia.io/assets/files/SEKOIA-IO-intake.pem","title":"1. Download the certificate"},{"location":"integrations/spamassassin/#2-configure-the-rsyslog-server","text":"Open or create a new SpamAssassin configuration file for rsyslog: 1 sudo vim /etc/rsyslog.d/34-spamassassin.conf Paste the following rsyslog configuration to trigger the emission of SpamAssassin logs by your rsyslog server to SEKOIA.IO: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Define the SEKIOA-IO intake certificate $DefaultNetstreamDriverCAFile /etc/rsyslog.d/SEKOIA-IO-intake.pem # Configure up the network ssl connection $ActionSendStreamDriver gtls # use gtls netstream driver $ActionSendStreamDriverMode 1 # require TLS for the connection $ActionSendStreamDriverAuthMode x509/name # server is authenticated # Template definition [RFC5424](https://tools.ietf.org/html/rfc5424#section-7.2.2) # IMPORTANT: don't forget to set your intake key in the template template ( name = \"SEKOIAIOSpamAssassinTemplate\" type = \"string\" string = \"<%pri%>1 %timestamp:::date-rfc3339% %hostname% %app-name% %procid% LOG [SEKOIA@53288 intake_key=\\\"YOUR_INTAKE_KEY\\\"] %msg%\\n\" ) # Send your events to SEKOIA.IO intake servers under SEKOIAIOSpamAssassinTemplate template if $programname startswith 'spamd' then @@ ( o ) intake.sekoia.io:10514 ; SEKOIAIOSpamAssassinTemplate In the above template instruction, please replace YOUR_INTAKE_KEY variable with your intake key.","title":"2. Configure the Rsyslog server"},{"location":"integrations/spamassassin/#3-restart-rsyslog","text":"1 $ sudo service rsyslog restart","title":"3. Restart rsyslog"},{"location":"integrations/spamassassin/#related-files","text":"SEKOIA-IO-intake.pem : SEKOIA.IO TLS Server Certificate (1674b)","title":"Related files"},{"location":"integrations/spamassassin/#4-enjoy-your-events","text":"Go to the events page to watch your incoming events.","title":"4. Enjoy your events"},{"location":"integrations/squid/","text":"Overview Squid is a caching proxy for the Web supporting HTTP, HTTPS, FTP, and more. It reduces bandwidth and improves response times by caching and reusing frequently-requested web pages. Squid has extensive access controls and makes a great server accelerator. Setup This setup guide will show you how to forward logs produced by your SQUID servers to SEKOIA.IO by means of an rsyslog transport channel. On most linux servers, two packages need to be installed: rsyslog and rsyslog-gnutls. 1. Download the certificate In order to allow the connection of your rsyslog server to the SEKOIA.IO intake, please download the SEKOIA.IO intake certificate: 1 $ wget -O /etc/rsyslog.d/SEKOIA-IO-intake.pem https://app.sekoia.io/assets/files/SEKOIA-IO-intake.pem 2. Configure Squid We can configure SQUID to report access logs to your syslog server. Open the squid configuration file (please note that the path to the configuration file may change depending on the OS and your configuration): 1 sudo vim /etc/squid/squid.conf Then update the access_log directive like the following line: 1 access_log syslog:local5.info squid 3. Configure the Rsyslog server Open or create a new Squid configuration file for rsyslog: 1 sudo vim /etc/rsyslog.d/17-squid.conf Then paste the following configuration: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Define the SEKIOA-IO intake certificate $DefaultNetstreamDriverCAFile /etc/rsyslog.d/SEKOIA-IO-intake.pem # Configure up the network ssl connection $ActionSendStreamDriver gtls # use gtls netstream driver $ActionSendStreamDriverMode 1 # require TLS for the connection $ActionSendStreamDriverAuthMode x509/name # server is authenticated # Template definition [RFC5424](https://tools.ietf.org/html/rfc5424#section-7.2.2) # IMPORTANT: don't forget to set your intake key in the template template ( name = \"SEKOIAIOSquidTemplate\" type = \"string\" string = \"<%pri%>1 %timestamp:::date-rfc3339% %hostname% %app-name% %procid% LOG [SEKOIA@53288 intake_key=\\\"YOUR_INTAKE_KEY\\\"] %msg%\\n\" ) # Send your events to SEKOIA.IO intake servers under SEKOIAIOSquidTemplate template if $programname contains 'squid' then @@ ( o ) intake.sekoia.io:10514 ; SEKOIAIOSquidTemplate In the above template instruction, please replace YOUR_INTAKE_KEY variable with your intake key. 4. Restart rsyslog 1 $ sudo service rsyslog restart 5. Enjoy your events Go to the events page to watch your incoming events. Related files SEKOIA-IO-intake.pem : SEKOIA.IO TLS Server Certificate (1674b) Further Readings Squid Wiki - Log configuration","title":"Squid"},{"location":"integrations/squid/#overview","text":"Squid is a caching proxy for the Web supporting HTTP, HTTPS, FTP, and more. It reduces bandwidth and improves response times by caching and reusing frequently-requested web pages. Squid has extensive access controls and makes a great server accelerator.","title":"Overview"},{"location":"integrations/squid/#setup","text":"This setup guide will show you how to forward logs produced by your SQUID servers to SEKOIA.IO by means of an rsyslog transport channel. On most linux servers, two packages need to be installed: rsyslog and rsyslog-gnutls.","title":"Setup"},{"location":"integrations/squid/#1-download-the-certificate","text":"In order to allow the connection of your rsyslog server to the SEKOIA.IO intake, please download the SEKOIA.IO intake certificate: 1 $ wget -O /etc/rsyslog.d/SEKOIA-IO-intake.pem https://app.sekoia.io/assets/files/SEKOIA-IO-intake.pem","title":"1. Download the certificate"},{"location":"integrations/squid/#2-configure-squid","text":"We can configure SQUID to report access logs to your syslog server. Open the squid configuration file (please note that the path to the configuration file may change depending on the OS and your configuration): 1 sudo vim /etc/squid/squid.conf Then update the access_log directive like the following line: 1 access_log syslog:local5.info squid","title":"2. Configure Squid"},{"location":"integrations/squid/#3-configure-the-rsyslog-server","text":"Open or create a new Squid configuration file for rsyslog: 1 sudo vim /etc/rsyslog.d/17-squid.conf Then paste the following configuration: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Define the SEKIOA-IO intake certificate $DefaultNetstreamDriverCAFile /etc/rsyslog.d/SEKOIA-IO-intake.pem # Configure up the network ssl connection $ActionSendStreamDriver gtls # use gtls netstream driver $ActionSendStreamDriverMode 1 # require TLS for the connection $ActionSendStreamDriverAuthMode x509/name # server is authenticated # Template definition [RFC5424](https://tools.ietf.org/html/rfc5424#section-7.2.2) # IMPORTANT: don't forget to set your intake key in the template template ( name = \"SEKOIAIOSquidTemplate\" type = \"string\" string = \"<%pri%>1 %timestamp:::date-rfc3339% %hostname% %app-name% %procid% LOG [SEKOIA@53288 intake_key=\\\"YOUR_INTAKE_KEY\\\"] %msg%\\n\" ) # Send your events to SEKOIA.IO intake servers under SEKOIAIOSquidTemplate template if $programname contains 'squid' then @@ ( o ) intake.sekoia.io:10514 ; SEKOIAIOSquidTemplate In the above template instruction, please replace YOUR_INTAKE_KEY variable with your intake key.","title":"3. Configure the Rsyslog server"},{"location":"integrations/squid/#4-restart-rsyslog","text":"1 $ sudo service rsyslog restart","title":"4. Restart rsyslog"},{"location":"integrations/squid/#5-enjoy-your-events","text":"Go to the events page to watch your incoming events.","title":"5. Enjoy your events"},{"location":"integrations/squid/#related-files","text":"SEKOIA-IO-intake.pem : SEKOIA.IO TLS Server Certificate (1674b)","title":"Related files"},{"location":"integrations/squid/#further-readings","text":"Squid Wiki - Log configuration","title":"Further Readings"},{"location":"integrations/suricata/","text":"Overview Suricata is a free and open source, mature, fast and robust network threat detection engine. Suricata inspects the network traffic using a powerful and extensive rules and signature language, and has powerful Lua scripting support for detection of complex threats. Setup Suricata leverages its EVE output module to report alerts, metadata, file info and protocol records in JSON. As described in the official documentation, this module can report its findings through the syslog facility. On most linux servers, two packages need to be installed: rsyslog and rsyslog-gnutls. 1. Download the certificate In order to allow the connection of your rsyslog server to the SEKOIA.IO intake, please download the SEKOIA.IO intake certificate: 1 $ wget -O /etc/rsyslog.d/SEKOIA-IO-intake.pem https://app.sekoia.io/assets/files/SEKOIA-IO-intake.pem 2. Configure Suricata to forward events to rsyslog Open the Suricata configuration file (please note that the path to the configuration file may change depending on the OS and your configuration): 1 sudo vim /etc/suricata/suricata.yaml Paste the following declaration in your suricata configuration to trigger the production of syslog entries under the local5 facility: 1 2 3 4 5 6 7 8 9 10 11 12 outputs: - eve-log: enabled: yes type:syslog identity: suricata facility: local5 level: Info types: - alert - http - dns - tls 3. Configure the Rsyslog server Given this Suricata configuration, your local rsyslog server will handle produced records. To report these to SEKOIA.IO, open or create a new suricata configuration file for rsyslog: 1 sudo vim /etc/rsyslog.d/11-suricata.conf Then paste the following rsyslog configuration: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Define the SEKIOA-IO intake certificate $DefaultNetstreamDriverCAFile /etc/rsyslog.d/SEKOIA-IO-intake.pem # Configure up the network ssl connection $ActionSendStreamDriver gtls # use gtls netstream driver $ActionSendStreamDriverMode 1 # require TLS for the connection $ActionSendStreamDriverAuthMode x509/name # server is authenticated # Template definition [RFC5424](https://tools.ietf.org/html/rfc5424#section-7.2.2) # IMPORTANT: don't forget to set your intake key in the template template ( name = \"SEKOIAIOSuricataTemplate\" type = \"string\" string = \"<%pri%>1 %timestamp:::date-rfc3339% %hostname% %app-name% %procid% LOG [SEKOIA@53288 intake_key=\\\"YOUR_INTAKE_KEY\\\"] %msg%\\n\" ) # Send your Suricata events to SEKOIA.IO intake servers under SEKOIAIOSuricataTemplate template if $app -name == 'suricata' then @@ ( o ) intake.sekoia.io:10514 ; SEKOIAIOSuricataTemplate In the above template instruction, please replace YOUR_INTAKE_KEY variable with your intake key. 4. Restart rsyslog 1 $ sudo service rsyslog restart 5. Enjoy your events Go to the events page to watch your incoming events. Related files SEKOIA-IO-intake.pem : SEKOIA.IO TLS Server Certificate (1674b) Further Readings Suricata User Guide","title":"Suricata"},{"location":"integrations/suricata/#overview","text":"Suricata is a free and open source, mature, fast and robust network threat detection engine. Suricata inspects the network traffic using a powerful and extensive rules and signature language, and has powerful Lua scripting support for detection of complex threats.","title":"Overview"},{"location":"integrations/suricata/#setup","text":"Suricata leverages its EVE output module to report alerts, metadata, file info and protocol records in JSON. As described in the official documentation, this module can report its findings through the syslog facility. On most linux servers, two packages need to be installed: rsyslog and rsyslog-gnutls.","title":"Setup"},{"location":"integrations/suricata/#1-download-the-certificate","text":"In order to allow the connection of your rsyslog server to the SEKOIA.IO intake, please download the SEKOIA.IO intake certificate: 1 $ wget -O /etc/rsyslog.d/SEKOIA-IO-intake.pem https://app.sekoia.io/assets/files/SEKOIA-IO-intake.pem","title":"1. Download the certificate"},{"location":"integrations/suricata/#2-configure-suricata-to-forward-events-to-rsyslog","text":"Open the Suricata configuration file (please note that the path to the configuration file may change depending on the OS and your configuration): 1 sudo vim /etc/suricata/suricata.yaml Paste the following declaration in your suricata configuration to trigger the production of syslog entries under the local5 facility: 1 2 3 4 5 6 7 8 9 10 11 12 outputs: - eve-log: enabled: yes type:syslog identity: suricata facility: local5 level: Info types: - alert - http - dns - tls","title":"2. Configure Suricata to forward events to rsyslog"},{"location":"integrations/suricata/#3-configure-the-rsyslog-server","text":"Given this Suricata configuration, your local rsyslog server will handle produced records. To report these to SEKOIA.IO, open or create a new suricata configuration file for rsyslog: 1 sudo vim /etc/rsyslog.d/11-suricata.conf Then paste the following rsyslog configuration: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Define the SEKIOA-IO intake certificate $DefaultNetstreamDriverCAFile /etc/rsyslog.d/SEKOIA-IO-intake.pem # Configure up the network ssl connection $ActionSendStreamDriver gtls # use gtls netstream driver $ActionSendStreamDriverMode 1 # require TLS for the connection $ActionSendStreamDriverAuthMode x509/name # server is authenticated # Template definition [RFC5424](https://tools.ietf.org/html/rfc5424#section-7.2.2) # IMPORTANT: don't forget to set your intake key in the template template ( name = \"SEKOIAIOSuricataTemplate\" type = \"string\" string = \"<%pri%>1 %timestamp:::date-rfc3339% %hostname% %app-name% %procid% LOG [SEKOIA@53288 intake_key=\\\"YOUR_INTAKE_KEY\\\"] %msg%\\n\" ) # Send your Suricata events to SEKOIA.IO intake servers under SEKOIAIOSuricataTemplate template if $app -name == 'suricata' then @@ ( o ) intake.sekoia.io:10514 ; SEKOIAIOSuricataTemplate In the above template instruction, please replace YOUR_INTAKE_KEY variable with your intake key.","title":"3. Configure the Rsyslog server"},{"location":"integrations/suricata/#4-restart-rsyslog","text":"1 $ sudo service rsyslog restart","title":"4. Restart rsyslog"},{"location":"integrations/suricata/#5-enjoy-your-events","text":"Go to the events page to watch your incoming events.","title":"5. Enjoy your events"},{"location":"integrations/suricata/#related-files","text":"SEKOIA-IO-intake.pem : SEKOIA.IO TLS Server Certificate (1674b)","title":"Related files"},{"location":"integrations/suricata/#further-readings","text":"Suricata User Guide","title":"Further Readings"},{"location":"integrations/umbrella_dns/","text":"Overview Cisco Umbrella offers flexible, cloud-delivered security. It combines multiple security functions into one solution, so that protection can be extended to devices, remote users, and distributed locations anywhere. CISCO Umbrella is a leading provider of network security and recursive DNS services. With the intelligent proxy, if a site is considered potentially suspicious or could host malicious content, Umbrella returns the intelligent proxy's IP address. The request to that domain is then routed through their cloud-based secure gateway, and malicious content is found and stopped before it's sent to their customers. Setup This setup guide will show you how to forward logs produced by CISCO Umbrella service to SEKOIA.IO by means of an Rsyslog transport channel. On most linux servers, two packages need to be installed: rsyslog and rsyslog-gnutls. 1. Download the certificate In order to allow the connection of your rsyslog server to the SEKOIA.IO intake, please download the SEKOIA.IO intake certificate: 1 $ wget -O /etc/rsyslog.d/SEKOIA-IO-intake.pem https://app.sekoia.io/assets/files/SEKOIA-IO-intake.pem 2. Collect proxylogs files and send them to rsyslog After configuring Umbrella Log Management with AWS S3, the logs you download will be gzipped CSVs in appropriate subfolder with the following naming format: 1 dnslogs/<year>-<month>-<day>/<year>-<month>-<day>-<hour>-<minute>.csv.gz To send these logs to SEKOIA.IO, we suggest the use of the logger Unix command. For each unzipped file, use the following command line: 1 logger -t dnslogs -f <YYYY>-<MM>-<DD>-<hh>-<mm>-<xxxx>.csv 3. Configure the Rsyslog server You can configure your Rsyslog server to forward your fortigate logs to SEKOIA.IO. Open or create a new Umbrella configuration file for rsyslog: 1 sudo vim /etc/rsyslog.d/6-umbrella.conf Then paste the following configuration: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Define the SEKIOA-IO intake certificate $DefaultNetstreamDriverCAFile /etc/rsyslog.d/SEKOIA-IO-intake.pem # Configure up the network ssl connection $ActionSendStreamDriver gtls # use gtls netstream driver $ActionSendStreamDriverMode 1 # require TLS for the connection $ActionSendStreamDriverAuthMode x509/name # server is authenticated # Template definition [RFC5424](https://tools.ietf.org/html/rfc5424#section-7.2.2) # IMPORTANT: don't forget to set your intake key in the template template ( name = \"SEKOIAIOUmbrellaDnslogsTemplate\" type = \"string\" string = \"<%pri%>1 %timestamp:::date-rfc3339% %hostname% %app-name% %procid% LOG [SEKOIA@53288 intake_key=\\\"YOUR_INTAKE_KEY\\\"] %msg%\\n\" ) # Send your Umbrella events to SEKOIA.IO intake servers under SEKOIAIOUmbrellaDnslogsTemplate template if $syslogtag contains \"dnslogs\" then @@ ( o ) intake.sekoia.io:10514 ; SEKOIAIOUmbrellaDnslogsTemplate In the above template instruction, replace YOUR_INTAKE_KEY variable with the intake key available in the Intakes menu of SEKOIA.IO. 4. Restart rsyslog 1 $ sudo service rsyslog restart 5. Enjoy your events Once the configuration has been done on Sekoia side, you can go to the events page to watch your incoming events. Further Readings CISCO Umbrella User Guide - Logs Management","title":"Dns Logs"},{"location":"integrations/umbrella_dns/#overview","text":"Cisco Umbrella offers flexible, cloud-delivered security. It combines multiple security functions into one solution, so that protection can be extended to devices, remote users, and distributed locations anywhere. CISCO Umbrella is a leading provider of network security and recursive DNS services. With the intelligent proxy, if a site is considered potentially suspicious or could host malicious content, Umbrella returns the intelligent proxy's IP address. The request to that domain is then routed through their cloud-based secure gateway, and malicious content is found and stopped before it's sent to their customers.","title":"Overview"},{"location":"integrations/umbrella_dns/#setup","text":"This setup guide will show you how to forward logs produced by CISCO Umbrella service to SEKOIA.IO by means of an Rsyslog transport channel. On most linux servers, two packages need to be installed: rsyslog and rsyslog-gnutls.","title":"Setup"},{"location":"integrations/umbrella_dns/#1-download-the-certificate","text":"In order to allow the connection of your rsyslog server to the SEKOIA.IO intake, please download the SEKOIA.IO intake certificate: 1 $ wget -O /etc/rsyslog.d/SEKOIA-IO-intake.pem https://app.sekoia.io/assets/files/SEKOIA-IO-intake.pem","title":"1. Download the certificate"},{"location":"integrations/umbrella_dns/#2-collect-proxylogs-files-and-send-them-to-rsyslog","text":"After configuring Umbrella Log Management with AWS S3, the logs you download will be gzipped CSVs in appropriate subfolder with the following naming format: 1 dnslogs/<year>-<month>-<day>/<year>-<month>-<day>-<hour>-<minute>.csv.gz To send these logs to SEKOIA.IO, we suggest the use of the logger Unix command. For each unzipped file, use the following command line: 1 logger -t dnslogs -f <YYYY>-<MM>-<DD>-<hh>-<mm>-<xxxx>.csv","title":"2. Collect proxylogs files and send them to rsyslog"},{"location":"integrations/umbrella_dns/#3-configure-the-rsyslog-server","text":"You can configure your Rsyslog server to forward your fortigate logs to SEKOIA.IO. Open or create a new Umbrella configuration file for rsyslog: 1 sudo vim /etc/rsyslog.d/6-umbrella.conf Then paste the following configuration: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Define the SEKIOA-IO intake certificate $DefaultNetstreamDriverCAFile /etc/rsyslog.d/SEKOIA-IO-intake.pem # Configure up the network ssl connection $ActionSendStreamDriver gtls # use gtls netstream driver $ActionSendStreamDriverMode 1 # require TLS for the connection $ActionSendStreamDriverAuthMode x509/name # server is authenticated # Template definition [RFC5424](https://tools.ietf.org/html/rfc5424#section-7.2.2) # IMPORTANT: don't forget to set your intake key in the template template ( name = \"SEKOIAIOUmbrellaDnslogsTemplate\" type = \"string\" string = \"<%pri%>1 %timestamp:::date-rfc3339% %hostname% %app-name% %procid% LOG [SEKOIA@53288 intake_key=\\\"YOUR_INTAKE_KEY\\\"] %msg%\\n\" ) # Send your Umbrella events to SEKOIA.IO intake servers under SEKOIAIOUmbrellaDnslogsTemplate template if $syslogtag contains \"dnslogs\" then @@ ( o ) intake.sekoia.io:10514 ; SEKOIAIOUmbrellaDnslogsTemplate In the above template instruction, replace YOUR_INTAKE_KEY variable with the intake key available in the Intakes menu of SEKOIA.IO.","title":"3. Configure the Rsyslog server"},{"location":"integrations/umbrella_dns/#4-restart-rsyslog","text":"1 $ sudo service rsyslog restart","title":"4. Restart rsyslog"},{"location":"integrations/umbrella_dns/#5-enjoy-your-events","text":"Once the configuration has been done on Sekoia side, you can go to the events page to watch your incoming events.","title":"5. Enjoy your events"},{"location":"integrations/umbrella_dns/#further-readings","text":"CISCO Umbrella User Guide - Logs Management","title":"Further Readings"},{"location":"integrations/umbrella_ip/","text":"Overview Cisco Umbrella offers flexible, cloud-delivered security. It combines multiple security functions into one solution, so that protection can be extended to devices, remote users, and distributed locations anywhere. CISCO Umbrella is a leading provider of network security and recursive DNS services. With the intelligent proxy, if a site is considered potentially suspicious or could host malicious content, Umbrella returns the intelligent proxy's IP address. The request to that domain is then routed through their cloud-based secure gateway, and malicious content is found and stopped before it's sent to their customers. Setup This setup guide will show you how to forward logs produced by CISCO Umbrella service to SEKOIA.IO by means of an Rsyslog transport channel. On most linux servers, two packages need to be installed: rsyslog and rsyslog-gnutls. 1. Download the certificate In order to allow the connection of your rsyslog server to the SEKOIA.IO intake, please download the SEKOIA.IO intake certificate: 1 $ wget -O /etc/rsyslog.d/SEKOIA-IO-intake.pem https://app.sekoia.io/assets/files/SEKOIA-IO-intake.pem 2. Collect proxylogs files and send them to rsyslog After configuring Umbrella Log Management with AWS S3, the logs you download will be gzipped CSVs in appropriate subfolder with the following naming format: 1 iplogs/<year>-<month>-<day>/<year>-<month>-<day>-<hour>-<minute>.csv.gz To send these logs to SEKOIA.IO, we suggest the use of the logger Unix command. For each unzipped file, use the following command line: 1 logger -t iplogs -f <YYYY>-<MM>-<DD>-<hh>-<mm>-<xxxx>.csv 3. Configure the Rsyslog server You can configure your Rsyslog server to forward your fortigate logs to SEKOIA.IO. Open or create a new Umbrella configuration file for rsyslog: 1 sudo vim /etc/rsyslog.d/6-umbrella.conf Then paste the following configuration: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Define the SEKIOA-IO intake certificate $DefaultNetstreamDriverCAFile /etc/rsyslog.d/SEKOIA-IO-intake.pem # Configure up the network ssl connection $ActionSendStreamDriver gtls # use gtls netstream driver $ActionSendStreamDriverMode 1 # require TLS for the connection $ActionSendStreamDriverAuthMode x509/name # server is authenticated # Template definition [RFC5424](https://tools.ietf.org/html/rfc5424#section-7.2.2) # IMPORTANT: don't forget to set your intake key in the template template ( name = \"SEKOIAIOUmbrellaIplogsTemplate\" type = \"string\" string = \"<%pri%>1 %timestamp:::date-rfc3339% %hostname% %app-name% %procid% LOG [SEKOIA@53288 intake_key=\\\"YOUR_INTAKE_KEY\\\"] %msg%\\n\" ) # Send your Umbrella events to SEKOIA.IO intake servers under SEKOIAIOUmbrellaIplogsTemplate template if $syslogtag contains \"iplogs\" then @@ ( o ) intake.sekoia.io:10514 ; SEKOIAIOUmbrellaIplogsTemplate In the above template instruction, replace YOUR_INTAKE_KEY variable with the intake key available in the Intakes menu of SEKOIA.IO. 4. Restart rsyslog 1 $ sudo service rsyslog restart 5. Enjoy your events Once the configuration has been done on Sekoia side, you can go to the events page to watch your incoming events. Further Readings CISCO Umbrella User Guide - Logs Management","title":"Ip Logs"},{"location":"integrations/umbrella_ip/#overview","text":"Cisco Umbrella offers flexible, cloud-delivered security. It combines multiple security functions into one solution, so that protection can be extended to devices, remote users, and distributed locations anywhere. CISCO Umbrella is a leading provider of network security and recursive DNS services. With the intelligent proxy, if a site is considered potentially suspicious or could host malicious content, Umbrella returns the intelligent proxy's IP address. The request to that domain is then routed through their cloud-based secure gateway, and malicious content is found and stopped before it's sent to their customers.","title":"Overview"},{"location":"integrations/umbrella_ip/#setup","text":"This setup guide will show you how to forward logs produced by CISCO Umbrella service to SEKOIA.IO by means of an Rsyslog transport channel. On most linux servers, two packages need to be installed: rsyslog and rsyslog-gnutls.","title":"Setup"},{"location":"integrations/umbrella_ip/#1-download-the-certificate","text":"In order to allow the connection of your rsyslog server to the SEKOIA.IO intake, please download the SEKOIA.IO intake certificate: 1 $ wget -O /etc/rsyslog.d/SEKOIA-IO-intake.pem https://app.sekoia.io/assets/files/SEKOIA-IO-intake.pem","title":"1. Download the certificate"},{"location":"integrations/umbrella_ip/#2-collect-proxylogs-files-and-send-them-to-rsyslog","text":"After configuring Umbrella Log Management with AWS S3, the logs you download will be gzipped CSVs in appropriate subfolder with the following naming format: 1 iplogs/<year>-<month>-<day>/<year>-<month>-<day>-<hour>-<minute>.csv.gz To send these logs to SEKOIA.IO, we suggest the use of the logger Unix command. For each unzipped file, use the following command line: 1 logger -t iplogs -f <YYYY>-<MM>-<DD>-<hh>-<mm>-<xxxx>.csv","title":"2. Collect proxylogs files and send them to rsyslog"},{"location":"integrations/umbrella_ip/#3-configure-the-rsyslog-server","text":"You can configure your Rsyslog server to forward your fortigate logs to SEKOIA.IO. Open or create a new Umbrella configuration file for rsyslog: 1 sudo vim /etc/rsyslog.d/6-umbrella.conf Then paste the following configuration: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Define the SEKIOA-IO intake certificate $DefaultNetstreamDriverCAFile /etc/rsyslog.d/SEKOIA-IO-intake.pem # Configure up the network ssl connection $ActionSendStreamDriver gtls # use gtls netstream driver $ActionSendStreamDriverMode 1 # require TLS for the connection $ActionSendStreamDriverAuthMode x509/name # server is authenticated # Template definition [RFC5424](https://tools.ietf.org/html/rfc5424#section-7.2.2) # IMPORTANT: don't forget to set your intake key in the template template ( name = \"SEKOIAIOUmbrellaIplogsTemplate\" type = \"string\" string = \"<%pri%>1 %timestamp:::date-rfc3339% %hostname% %app-name% %procid% LOG [SEKOIA@53288 intake_key=\\\"YOUR_INTAKE_KEY\\\"] %msg%\\n\" ) # Send your Umbrella events to SEKOIA.IO intake servers under SEKOIAIOUmbrellaIplogsTemplate template if $syslogtag contains \"iplogs\" then @@ ( o ) intake.sekoia.io:10514 ; SEKOIAIOUmbrellaIplogsTemplate In the above template instruction, replace YOUR_INTAKE_KEY variable with the intake key available in the Intakes menu of SEKOIA.IO.","title":"3. Configure the Rsyslog server"},{"location":"integrations/umbrella_ip/#4-restart-rsyslog","text":"1 $ sudo service rsyslog restart","title":"4. Restart rsyslog"},{"location":"integrations/umbrella_ip/#5-enjoy-your-events","text":"Once the configuration has been done on Sekoia side, you can go to the events page to watch your incoming events.","title":"5. Enjoy your events"},{"location":"integrations/umbrella_ip/#further-readings","text":"CISCO Umbrella User Guide - Logs Management","title":"Further Readings"},{"location":"integrations/umbrella_proxy/","text":"Overview Cisco Umbrella offers flexible, cloud-delivered security. It combines multiple security functions into one solution, so that protection can be extended to devices, remote users, and distributed locations anywhere. CISCO Umbrella is a leading provider of network security and recursive DNS services. With the intelligent proxy, if a site is considered potentially suspicious or could host malicious content, Umbrella returns the intelligent proxy's IP address. The request to that domain is then routed through their cloud-based secure gateway, and malicious content is found and stopped before it's sent to their customers. Setup This setup guide will show you how to forward logs produced by CISCO Umbrella service to SEKOIA.IO by means of an Rsyslog transport channel. On most linux servers, two packages need to be installed: rsyslog and rsyslog-gnutls. 1. Download the certificate In order to allow the connection of your rsyslog server to the SEKOIA.IO intake, please download the SEKOIA.IO intake certificate: 1 $ wget -O /etc/rsyslog.d/SEKOIA-IO-intake.pem https://app.sekoia.io/assets/files/SEKOIA-IO-intake.pem 2. Collect proxylogs files and send them to rsyslog After configuring Umbrella Log Management with AWS S3, the logs you download will be gzipped CSVs in appropriate subfolder with the following naming format: 1 proxylogs/<year>-<month>-<day>/<year>-<month>-<day>-<hour>-<minute>.csv.gz To send these logs to SEKOIA.IO, we suggest the use of the logger Unix command. For each unzipped file, use the following command line: 1 logger -t proxylogs -f <YYYY>-<MM>-<DD>-<hh>-<mm>-<xxxx>.csv 3. Configure the Rsyslog server You can configure your Rsyslog server to forward your fortigate logs to SEKOIA.IO. Open or create a new Umbrella configuration file for rsyslog: 1 sudo vim /etc/rsyslog.d/6-umbrella.conf Then paste the following configuration: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Define the SEKIOA-IO intake certificate $DefaultNetstreamDriverCAFile /etc/rsyslog.d/SEKOIA-IO-intake.pem # Configure up the network ssl connection $ActionSendStreamDriver gtls # use gtls netstream driver $ActionSendStreamDriverMode 1 # require TLS for the connection $ActionSendStreamDriverAuthMode x509/name # server is authenticated # Template definition [RFC5424](https://tools.ietf.org/html/rfc5424#section-7.2.2) # IMPORTANT: don't forget to set your intake key in the template template ( name = \"SEKOIAIOUmbrellaProxylogsTemplate\" type = \"string\" string = \"<%pri%>1 %timestamp:::date-rfc3339% %hostname% %app-name% %procid% LOG [SEKOIA@53288 intake_key=\\\"YOUR_INTAKE_KEY\\\"] %msg%\\n\" ) # Send your Umbrella events to SEKOIA.IO intake servers under SEKOIAIOUmbrellaProxylogsTemplate template if $syslogtag contains \"proxylogs\" then @@ ( o ) intake.sekoia.io:10514 ; SEKOIAIOUmbrellaProxylogsTemplate In the above template instruction, replace YOUR_INTAKE_KEY variable with the intake key available in the Intakes menu of SEKOIA.IO. 4. Restart rsyslog 1 $ sudo service rsyslog restart 5. Enjoy your events Once the configuration has been done on Sekoia side, you can go to the events page to watch your incoming events. Further Readings CISCO Umbrella User Guide - Logs Management","title":"Proxy Logs"},{"location":"integrations/umbrella_proxy/#overview","text":"Cisco Umbrella offers flexible, cloud-delivered security. It combines multiple security functions into one solution, so that protection can be extended to devices, remote users, and distributed locations anywhere. CISCO Umbrella is a leading provider of network security and recursive DNS services. With the intelligent proxy, if a site is considered potentially suspicious or could host malicious content, Umbrella returns the intelligent proxy's IP address. The request to that domain is then routed through their cloud-based secure gateway, and malicious content is found and stopped before it's sent to their customers.","title":"Overview"},{"location":"integrations/umbrella_proxy/#setup","text":"This setup guide will show you how to forward logs produced by CISCO Umbrella service to SEKOIA.IO by means of an Rsyslog transport channel. On most linux servers, two packages need to be installed: rsyslog and rsyslog-gnutls.","title":"Setup"},{"location":"integrations/umbrella_proxy/#1-download-the-certificate","text":"In order to allow the connection of your rsyslog server to the SEKOIA.IO intake, please download the SEKOIA.IO intake certificate: 1 $ wget -O /etc/rsyslog.d/SEKOIA-IO-intake.pem https://app.sekoia.io/assets/files/SEKOIA-IO-intake.pem","title":"1. Download the certificate"},{"location":"integrations/umbrella_proxy/#2-collect-proxylogs-files-and-send-them-to-rsyslog","text":"After configuring Umbrella Log Management with AWS S3, the logs you download will be gzipped CSVs in appropriate subfolder with the following naming format: 1 proxylogs/<year>-<month>-<day>/<year>-<month>-<day>-<hour>-<minute>.csv.gz To send these logs to SEKOIA.IO, we suggest the use of the logger Unix command. For each unzipped file, use the following command line: 1 logger -t proxylogs -f <YYYY>-<MM>-<DD>-<hh>-<mm>-<xxxx>.csv","title":"2. Collect proxylogs files and send them to rsyslog"},{"location":"integrations/umbrella_proxy/#3-configure-the-rsyslog-server","text":"You can configure your Rsyslog server to forward your fortigate logs to SEKOIA.IO. Open or create a new Umbrella configuration file for rsyslog: 1 sudo vim /etc/rsyslog.d/6-umbrella.conf Then paste the following configuration: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Define the SEKIOA-IO intake certificate $DefaultNetstreamDriverCAFile /etc/rsyslog.d/SEKOIA-IO-intake.pem # Configure up the network ssl connection $ActionSendStreamDriver gtls # use gtls netstream driver $ActionSendStreamDriverMode 1 # require TLS for the connection $ActionSendStreamDriverAuthMode x509/name # server is authenticated # Template definition [RFC5424](https://tools.ietf.org/html/rfc5424#section-7.2.2) # IMPORTANT: don't forget to set your intake key in the template template ( name = \"SEKOIAIOUmbrellaProxylogsTemplate\" type = \"string\" string = \"<%pri%>1 %timestamp:::date-rfc3339% %hostname% %app-name% %procid% LOG [SEKOIA@53288 intake_key=\\\"YOUR_INTAKE_KEY\\\"] %msg%\\n\" ) # Send your Umbrella events to SEKOIA.IO intake servers under SEKOIAIOUmbrellaProxylogsTemplate template if $syslogtag contains \"proxylogs\" then @@ ( o ) intake.sekoia.io:10514 ; SEKOIAIOUmbrellaProxylogsTemplate In the above template instruction, replace YOUR_INTAKE_KEY variable with the intake key available in the Intakes menu of SEKOIA.IO.","title":"3. Configure the Rsyslog server"},{"location":"integrations/umbrella_proxy/#4-restart-rsyslog","text":"1 $ sudo service rsyslog restart","title":"4. Restart rsyslog"},{"location":"integrations/umbrella_proxy/#5-enjoy-your-events","text":"Once the configuration has been done on Sekoia side, you can go to the events page to watch your incoming events.","title":"5. Enjoy your events"},{"location":"integrations/umbrella_proxy/#further-readings","text":"CISCO Umbrella User Guide - Logs Management","title":"Further Readings"},{"location":"integrations/unbound/","text":"Overview Unbound is a validating, recursive, and caching DNS resolver product from NLnet Labs. It is distributed free of charge in open-source form under the BSD license. Setup This setup guide will show you how to forward logs produced by your Unbound server to SEKOIA.IO by means of an rsyslog transport channel. On most linux servers, two packages need to be installed: rsyslog and rsyslog-gnutls. 1. Download the certificate In order to allow the connection of your rsyslog server to the SEKOIA.IO intake, please download the SEKOIA.IO intake certificate: 1 $ wget -O /etc/rsyslog.d/SEKOIA-IO-intake.pem https://app.sekoia.io/assets/files/SEKOIA-IO-intake.pem 2. Configure the Rsyslog server Open or create a new Unbound configuration file for rsyslog: 1 sudo vim /etc/rsyslog.d/46-unbound.conf Paste the following rsyslog configuration to trigger the emission of Unbound logs by your rsyslog server to SEKOIA.IO: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Define the SEKIOA-IO intake certificate $DefaultNetstreamDriverCAFile /etc/rsyslog.d/SEKOIA-IO-intake.pem # Configure up the network ssl connection $ActionSendStreamDriver gtls # use gtls netstream driver $ActionSendStreamDriverMode 1 # require TLS for the connection $ActionSendStreamDriverAuthMode x509/name # server is authenticated # Template definition [RFC5424](https://tools.ietf.org/html/rfc5424#section-7.2.2) # IMPORTANT: don't forget to set your intake key in the template template ( name = \"SEKOIAIOUnboundTemplate\" type = \"string\" string = \"<%pri%>1 %timestamp:::date-rfc3339% %hostname% %app-name% %procid% LOG [SEKOIA@53288 intake_key=\\\"YOUR_INTAKE_KEY\\\"] %msg%\\n\" ) # Send your events to SEKOIA.IO intake servers under SEKOIAIOUnboundTemplate template if $programname startswith 'unbound' then @@ ( o ) intake.sekoia.io:10514 ; SEKOIAIOUnboundTemplate In the above template instruction, please replace YOUR_INTAKE_KEY variable with your intake key. 3. Restart rsyslog 1 $ sudo service rsyslog restart 4. Enjoy your events Go to the events page to watch your incoming events. Related files SEKOIA-IO-intake.pem : SEKOIA.IO TLS Server Certificate (1674b)","title":"Unbound"},{"location":"integrations/unbound/#overview","text":"Unbound is a validating, recursive, and caching DNS resolver product from NLnet Labs. It is distributed free of charge in open-source form under the BSD license.","title":"Overview"},{"location":"integrations/unbound/#setup","text":"This setup guide will show you how to forward logs produced by your Unbound server to SEKOIA.IO by means of an rsyslog transport channel. On most linux servers, two packages need to be installed: rsyslog and rsyslog-gnutls.","title":"Setup"},{"location":"integrations/unbound/#1-download-the-certificate","text":"In order to allow the connection of your rsyslog server to the SEKOIA.IO intake, please download the SEKOIA.IO intake certificate: 1 $ wget -O /etc/rsyslog.d/SEKOIA-IO-intake.pem https://app.sekoia.io/assets/files/SEKOIA-IO-intake.pem","title":"1. Download the certificate"},{"location":"integrations/unbound/#2-configure-the-rsyslog-server","text":"Open or create a new Unbound configuration file for rsyslog: 1 sudo vim /etc/rsyslog.d/46-unbound.conf Paste the following rsyslog configuration to trigger the emission of Unbound logs by your rsyslog server to SEKOIA.IO: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Define the SEKIOA-IO intake certificate $DefaultNetstreamDriverCAFile /etc/rsyslog.d/SEKOIA-IO-intake.pem # Configure up the network ssl connection $ActionSendStreamDriver gtls # use gtls netstream driver $ActionSendStreamDriverMode 1 # require TLS for the connection $ActionSendStreamDriverAuthMode x509/name # server is authenticated # Template definition [RFC5424](https://tools.ietf.org/html/rfc5424#section-7.2.2) # IMPORTANT: don't forget to set your intake key in the template template ( name = \"SEKOIAIOUnboundTemplate\" type = \"string\" string = \"<%pri%>1 %timestamp:::date-rfc3339% %hostname% %app-name% %procid% LOG [SEKOIA@53288 intake_key=\\\"YOUR_INTAKE_KEY\\\"] %msg%\\n\" ) # Send your events to SEKOIA.IO intake servers under SEKOIAIOUnboundTemplate template if $programname startswith 'unbound' then @@ ( o ) intake.sekoia.io:10514 ; SEKOIAIOUnboundTemplate In the above template instruction, please replace YOUR_INTAKE_KEY variable with your intake key.","title":"2. Configure the Rsyslog server"},{"location":"integrations/unbound/#3-restart-rsyslog","text":"1 $ sudo service rsyslog restart","title":"3. Restart rsyslog"},{"location":"integrations/unbound/#4-enjoy-your-events","text":"Go to the events page to watch your incoming events.","title":"4. Enjoy your events"},{"location":"integrations/unbound/#related-files","text":"SEKOIA-IO-intake.pem : SEKOIA.IO TLS Server Certificate (1674b)","title":"Related files"},{"location":"integrations/windows/","text":"Overview Microsoft Windows is a popular operating system developed by Microsoft since 1985. It's available in three variants: Windows for desktop/laptop computers, tablets and smartphones Windows Server for servers Windows PE as a lightweight version. Setup This setup guide will show you how to forward events produced by a Windows system either directly to SEKOIA.IO, or through your local rsyslog server. On most linux servers, two packages need to be installed: rsyslog and rsyslog-gnutls. Lastly we will propose an example with sysmon tool installed. 1. Configure the forwarder the direct way Download the certificate In order to allow the connection of your events forwarder to the SEKOIA.IO intake, please download the SEKOIA.IO intake certificate. In a PowerShell console run as administrator, retrieve the certificate with the following command: 1 Invoke-WebRequest -Uri https : // app . sekoia . io / assets / files / SEKOIA-IO-intake . pem -OutFile 'C:\\Program Files (x86)\\nxlog\\cert\\SEKOIA-IO-intake.pem' NXLog setup on Windows This section describes how to configure NXLog to forward your Windows events by means of a syslog transport channel. First of all, download NXLog at the following link : https://nxlog.co/products/all/download. Then, open the NXLog configuration file at C:\\Program Files (x86)\\nxlog\\conf\\nxlog.conf and update it with the following instructions: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 ## This is a sample configuration file. See the nxlog reference manual about the ## configuration options. It should be installed locally and is also available ## online at http: //nxlog.org/nxlog-docs/en/nxlog-reference-manual.html ## Please set the ROOT to the folder your nxlog was installed into, ## otherwise it will not start. #define ROOT C:\\Program Files\\nxlog define ROOT C : \\ Program Files ( x86 ) \\ nxlog define CERTDIR % ROOT % \\ cert Moduledir % ROOT % \\ modules CacheDir % ROOT % \\ data Pidfile % ROOT % \\ data \\ nxlog . pid SpoolDir % ROOT % \\ data LogFile % ROOT % \\ data \\ nxlog . log < Extension _syslog > Module xm_syslog </ Extension > < Extension _json > Module xm_json </ Extension > < Input eventlog > # Use 'im_mseventlog' for Windows XP, 2000 and 2003 Module im_msvistalog Exec $ Message = to_json (); </ Input > < Output sekoia_intake > Module om_ssl Host intake . sekoia . io Port 10514 CAFile % CERTDIR % \\ SEKOIA - IO - intake . pem AllowUntrusted FALSE Exec to_syslog_ietf (); Exec $ raw_event = replace ( $ raw_event , ' [ NXLOG @ ' , ' [ SEKOIA @53288 intake_key = \"YOUR_INTAKE_KEY\" ][ NXLOG @ ' , 1 ); OutputType Syslog_TLS </ Output > < Route eventlog_to_sekoia_intake > Path eventlog => sekoia_intake </ Route > In the above template instruction, please replace YOUR_INTAKE_KEY variable with your intake key. Restart the NXLog service through the Services tool. 2. Configure the forwarder through rsyslog NXLog setup on Windows This section describes how to configure NXLog to forward your Windows events by means of a syslog transport channel. First of all, download NXLog at the following link : https://nxlog.co/products/all/download. Then, open the NXLog configuration file at C:\\Program Files (x86)\\nxlog\\conf\\nxlog.conf and update it with the following instructions: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 ## This is a sample configuration file . See the nxlog reference manual about the ## configuration options . It should be installed locally and is also available ## online at http : // nxlog . org / nxlog - docs / en / nxlog - reference - manual . html ## Please set the ROOT to the folder your nxlog was installed into , ## otherwise it will not start . # define ROOT C : \\ Program Files \\ nxlog define ROOT C : \\ Program Files ( x86 ) \\ nxlog define CERTDIR % ROOT% \\ cert Moduledir % ROOT% \\ modules CacheDir % ROOT% \\ data Pidfile % ROOT% \\ data \\ nxlog . pid SpoolDir % ROOT% \\ data LogFile % ROOT% \\ data \\ nxlog . log <Extension _syslog> Module xm_syslog </Extension> <Extension _json> Module xm_json </Extension> <Input eventlog> # Use 'im_mseventlog' for Windows XP, 2000 and 2003 Module im_msvistalog Exec $ Message = to_json () ; </Input> <Output rsyslog> Module om_tcp Host RSYSLOG_HOST Port 514 OutputType Syslog_TLS Exec to_syslog_ietf () ; </Output> <Route eventlog_to_rsyslog> Path eventlog => rsyslog </Route> In the above configuration make sure to replace RSYSLOG_HOST variable by your rsyslog server IP. Restart the NXLog service through the Services tool. Rsyslog setup on Linux Server Download the certificate In order to allow the connection of your rsyslog server to the SEKOIA.IO intake, please download the SEKOIA.IO intake certificate: 1 $ wget -O /etc/rsyslog.d/SEKOIA-IO-intake.pem https://app.sekoia.io/assets/files/SEKOIA-IO-intake.pem Configure the Rsyslog server Open or create a new windows configuration file for rsyslog: 1 sudo vim /etc/rsyslog.d/15-windows.conf Paste the following rsyslog configuration to trigger the emission of windows logs by your rsyslog server to SEKOIA.IO: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Define the SEKIOA-IO intake certificate $DefaultNetstreamDriverCAFile /etc/rsyslog.d/SEKOIA-IO-intake.pem # Configure up the network ssl connection $ActionSendStreamDriver gtls # use gtls netstream driver $ActionSendStreamDriverMode 1 # require TLS for the connection $ActionSendStreamDriverAuthMode x509/name # server is authenticated # Template definition [RFC5424](https://tools.ietf.org/html/rfc5424#section-7.2.2) # IMPORTANT: don't forget to set your intake key in the template template ( name = \"SEKOIAIOWindowsTemplate\" type = \"string\" string = \"<%pri%>1 %timestamp:::date-rfc3339% %hostname% %app-name% %procid% LOG [SEKOIA@53288 intake_key=\\\"YOUR_INTAKE_KEY\\\"] %msg%\\n\" ) # Send your events to SEKOIA.IO intake servers under SEKOIAIOWindowsTemplate template if $programname contains 'Microsoft-Windows' then @@ ( o ) intake.sekoia.io:10514 ; SEKOIAIOWindowsTemplate In the above template instruction, please replace YOUR_INTAKE_KEY variable with your intake key. Restart rsyslog 1 $ sudo service rsyslog restart 3. Sysmon usage Sysmon installation Sysmon is a Microsoft tool you can download on their website . A common installation instruction and configuration file is available on SwiftOnSecurity's Github . NXLog setup with Sysmon Then you need to adapt your NXLog configuration previously made. If your are using the NXLog community edition, there's a limitation in terms of number of different eventlog entries that could be processed. In order to monitor the common ones (Application, System, Security) and Sysmon, you could make the following changes: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 ... <Input eventlog1> Module im_msvistalog Query < QueryList >< Query Id = \"0\" >< Select Path = \"Application\" >*</ Select ></ Query ></ QueryList > Exec $ Message = to_json () ; </Input> <Input eventlog2> Module im_msvistalog Query < QueryList >< Query Id = \"0\" >< Select Path = \"System\" >*</ Select ></ Query ></ QueryList > Exec $ Message = to_json () ; </Input> <Input eventlog3> Module im_msvistalog Query < QueryList >< Query Id = \"0\" >< Select Path = \"Security\" >*</ Select ></ Query ></ QueryList > Exec $ Message = to_json () ; </Input> <Input eventlog4> Module im_msvistalog Query < QueryList >< Query Id = \"0\" >< Select Path = \"Microsoft-Windows-Sysmon/Operational\" >*</ Select ></ Query ></ QueryList > Exec $ Message = to_json () ; </Input> ... <Route eventlog_to_rsyslog> Path eventlog1 , eventlog2 , eventlog3 , eventlog4 => rsyslog </Route> ... 4. Enjoy your events Go to the events page to watch your incoming events. Related files SEKOIA-IO-intake.pem : SEKOIA.IO TLS Server Certificate (1674b) Further Readings NXLog Community Edition Reference Manual","title":"Windows"},{"location":"integrations/windows/#overview","text":"Microsoft Windows is a popular operating system developed by Microsoft since 1985. It's available in three variants: Windows for desktop/laptop computers, tablets and smartphones Windows Server for servers Windows PE as a lightweight version.","title":"Overview"},{"location":"integrations/windows/#setup","text":"This setup guide will show you how to forward events produced by a Windows system either directly to SEKOIA.IO, or through your local rsyslog server. On most linux servers, two packages need to be installed: rsyslog and rsyslog-gnutls. Lastly we will propose an example with sysmon tool installed.","title":"Setup"},{"location":"integrations/windows/#1-configure-the-forwarder-the-direct-way","text":"","title":"1. Configure the forwarder the direct way"},{"location":"integrations/windows/#download-the-certificate","text":"In order to allow the connection of your events forwarder to the SEKOIA.IO intake, please download the SEKOIA.IO intake certificate. In a PowerShell console run as administrator, retrieve the certificate with the following command: 1 Invoke-WebRequest -Uri https : // app . sekoia . io / assets / files / SEKOIA-IO-intake . pem -OutFile 'C:\\Program Files (x86)\\nxlog\\cert\\SEKOIA-IO-intake.pem'","title":"Download the certificate"},{"location":"integrations/windows/#nxlog-setup-on-windows","text":"This section describes how to configure NXLog to forward your Windows events by means of a syslog transport channel. First of all, download NXLog at the following link : https://nxlog.co/products/all/download. Then, open the NXLog configuration file at C:\\Program Files (x86)\\nxlog\\conf\\nxlog.conf and update it with the following instructions: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 ## This is a sample configuration file. See the nxlog reference manual about the ## configuration options. It should be installed locally and is also available ## online at http: //nxlog.org/nxlog-docs/en/nxlog-reference-manual.html ## Please set the ROOT to the folder your nxlog was installed into, ## otherwise it will not start. #define ROOT C:\\Program Files\\nxlog define ROOT C : \\ Program Files ( x86 ) \\ nxlog define CERTDIR % ROOT % \\ cert Moduledir % ROOT % \\ modules CacheDir % ROOT % \\ data Pidfile % ROOT % \\ data \\ nxlog . pid SpoolDir % ROOT % \\ data LogFile % ROOT % \\ data \\ nxlog . log < Extension _syslog > Module xm_syslog </ Extension > < Extension _json > Module xm_json </ Extension > < Input eventlog > # Use 'im_mseventlog' for Windows XP, 2000 and 2003 Module im_msvistalog Exec $ Message = to_json (); </ Input > < Output sekoia_intake > Module om_ssl Host intake . sekoia . io Port 10514 CAFile % CERTDIR % \\ SEKOIA - IO - intake . pem AllowUntrusted FALSE Exec to_syslog_ietf (); Exec $ raw_event = replace ( $ raw_event , ' [ NXLOG @ ' , ' [ SEKOIA @53288 intake_key = \"YOUR_INTAKE_KEY\" ][ NXLOG @ ' , 1 ); OutputType Syslog_TLS </ Output > < Route eventlog_to_sekoia_intake > Path eventlog => sekoia_intake </ Route > In the above template instruction, please replace YOUR_INTAKE_KEY variable with your intake key. Restart the NXLog service through the Services tool.","title":"NXLog setup on Windows"},{"location":"integrations/windows/#2-configure-the-forwarder-through-rsyslog","text":"","title":"2. Configure the forwarder through rsyslog"},{"location":"integrations/windows/#nxlog-setup-on-windows_1","text":"This section describes how to configure NXLog to forward your Windows events by means of a syslog transport channel. First of all, download NXLog at the following link : https://nxlog.co/products/all/download. Then, open the NXLog configuration file at C:\\Program Files (x86)\\nxlog\\conf\\nxlog.conf and update it with the following instructions: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 ## This is a sample configuration file . See the nxlog reference manual about the ## configuration options . It should be installed locally and is also available ## online at http : // nxlog . org / nxlog - docs / en / nxlog - reference - manual . html ## Please set the ROOT to the folder your nxlog was installed into , ## otherwise it will not start . # define ROOT C : \\ Program Files \\ nxlog define ROOT C : \\ Program Files ( x86 ) \\ nxlog define CERTDIR % ROOT% \\ cert Moduledir % ROOT% \\ modules CacheDir % ROOT% \\ data Pidfile % ROOT% \\ data \\ nxlog . pid SpoolDir % ROOT% \\ data LogFile % ROOT% \\ data \\ nxlog . log <Extension _syslog> Module xm_syslog </Extension> <Extension _json> Module xm_json </Extension> <Input eventlog> # Use 'im_mseventlog' for Windows XP, 2000 and 2003 Module im_msvistalog Exec $ Message = to_json () ; </Input> <Output rsyslog> Module om_tcp Host RSYSLOG_HOST Port 514 OutputType Syslog_TLS Exec to_syslog_ietf () ; </Output> <Route eventlog_to_rsyslog> Path eventlog => rsyslog </Route> In the above configuration make sure to replace RSYSLOG_HOST variable by your rsyslog server IP. Restart the NXLog service through the Services tool.","title":"NXLog setup on Windows"},{"location":"integrations/windows/#rsyslog-setup-on-linux-server","text":"","title":"Rsyslog setup on Linux Server"},{"location":"integrations/windows/#download-the-certificate_1","text":"In order to allow the connection of your rsyslog server to the SEKOIA.IO intake, please download the SEKOIA.IO intake certificate: 1 $ wget -O /etc/rsyslog.d/SEKOIA-IO-intake.pem https://app.sekoia.io/assets/files/SEKOIA-IO-intake.pem","title":"Download the certificate"},{"location":"integrations/windows/#configure-the-rsyslog-server","text":"Open or create a new windows configuration file for rsyslog: 1 sudo vim /etc/rsyslog.d/15-windows.conf Paste the following rsyslog configuration to trigger the emission of windows logs by your rsyslog server to SEKOIA.IO: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Define the SEKIOA-IO intake certificate $DefaultNetstreamDriverCAFile /etc/rsyslog.d/SEKOIA-IO-intake.pem # Configure up the network ssl connection $ActionSendStreamDriver gtls # use gtls netstream driver $ActionSendStreamDriverMode 1 # require TLS for the connection $ActionSendStreamDriverAuthMode x509/name # server is authenticated # Template definition [RFC5424](https://tools.ietf.org/html/rfc5424#section-7.2.2) # IMPORTANT: don't forget to set your intake key in the template template ( name = \"SEKOIAIOWindowsTemplate\" type = \"string\" string = \"<%pri%>1 %timestamp:::date-rfc3339% %hostname% %app-name% %procid% LOG [SEKOIA@53288 intake_key=\\\"YOUR_INTAKE_KEY\\\"] %msg%\\n\" ) # Send your events to SEKOIA.IO intake servers under SEKOIAIOWindowsTemplate template if $programname contains 'Microsoft-Windows' then @@ ( o ) intake.sekoia.io:10514 ; SEKOIAIOWindowsTemplate In the above template instruction, please replace YOUR_INTAKE_KEY variable with your intake key.","title":"Configure the Rsyslog server"},{"location":"integrations/windows/#restart-rsyslog","text":"1 $ sudo service rsyslog restart","title":"Restart rsyslog"},{"location":"integrations/windows/#3-sysmon-usage","text":"","title":"3. Sysmon usage"},{"location":"integrations/windows/#sysmon-installation","text":"Sysmon is a Microsoft tool you can download on their website . A common installation instruction and configuration file is available on SwiftOnSecurity's Github .","title":"Sysmon installation"},{"location":"integrations/windows/#nxlog-setup-with-sysmon","text":"Then you need to adapt your NXLog configuration previously made. If your are using the NXLog community edition, there's a limitation in terms of number of different eventlog entries that could be processed. In order to monitor the common ones (Application, System, Security) and Sysmon, you could make the following changes: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 ... <Input eventlog1> Module im_msvistalog Query < QueryList >< Query Id = \"0\" >< Select Path = \"Application\" >*</ Select ></ Query ></ QueryList > Exec $ Message = to_json () ; </Input> <Input eventlog2> Module im_msvistalog Query < QueryList >< Query Id = \"0\" >< Select Path = \"System\" >*</ Select ></ Query ></ QueryList > Exec $ Message = to_json () ; </Input> <Input eventlog3> Module im_msvistalog Query < QueryList >< Query Id = \"0\" >< Select Path = \"Security\" >*</ Select ></ Query ></ QueryList > Exec $ Message = to_json () ; </Input> <Input eventlog4> Module im_msvistalog Query < QueryList >< Query Id = \"0\" >< Select Path = \"Microsoft-Windows-Sysmon/Operational\" >*</ Select ></ Query ></ QueryList > Exec $ Message = to_json () ; </Input> ... <Route eventlog_to_rsyslog> Path eventlog1 , eventlog2 , eventlog3 , eventlog4 => rsyslog </Route> ...","title":"NXLog setup with Sysmon"},{"location":"integrations/windows/#4-enjoy-your-events","text":"Go to the events page to watch your incoming events.","title":"4. Enjoy your events"},{"location":"integrations/windows/#related-files","text":"SEKOIA-IO-intake.pem : SEKOIA.IO TLS Server Certificate (1674b)","title":"Related files"},{"location":"integrations/windows/#further-readings","text":"NXLog Community Edition Reference Manual","title":"Further Readings"},{"location":"integrations/zeek/","text":"Overview Zeek is a free and open-source software network analysis framework; it was originally developed in 1994 by Vern Paxson and was named in reference to George Orwell's Big Brother from his novel Nineteen Eighty-Four. It can be used as a network intrusion detection system (NIDS) but with additional live analysis of network events.It is released under the BSD license. Setup This setup guide will show you how to forward dns, http and conn logs to SEKOIA.IO by means of an rsyslog transport channel. On most linux servers, two packages need to be installed: rsyslog and rsyslog-gnutls. 1. Download the certificate In order to allow the connection of your rsyslog server to the SEKOIA.IO intake, please download the SEKOIA.IO intake certificate: 1 $ wget -O /etc/rsyslog.d/SEKOIA-IO-intake.pem https://app.sekoia.io/assets/files/SEKOIA-IO-intake.pem 2. Configure the Rsyslog server We can configure rsyslog to parse the conn.log http.log and dns.log and report its entries to SEKOIA.IO. Open or create a new Zeek configuration file for rsyslog: 1 sudo vim /etc/rsyslog.d/66-zeek.conf At the beginning of the configuration file, paste the following instruction to order the rsyslog server to load the module imfile : 1 $ModLoad imfile Then paste the following configuration to leverage this module to monitor zeek log files (please note that the path to the log file may change depending on the OS and your configuration): 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 # Define the SEKIOA-IO intake certificate $DefaultNetstreamDriverCAFile /etc/rsyslog.d/SEKOIA-IO-intake.pem # Configure up the network ssl connection $ActionSendStreamDriver gtls # use gtls netstream driver $ActionSendStreamDriverMode 1 # require TLS for the connection $ActionSendStreamDriverAuthMode x509/name # server is authenticated # conn log $InputFileName /var/log/zeek/conn.log $InputFileTag zeek: $InputFileStateFile stat-zeek-conn $InputFileSeverity notice $InputFileFacility local5 $InputFilePollInterval 1 $InputRunFileMonitor # http log $InputFileName /var/log/zeek/http.log $InputFileTag zeek: $InputFileStateFile stat-zeek-http $InputFileSeverity notice $InputFileFacility local5 $InputFilePollInterval 1 $InputRunFileMonitor # dns log $InputFileName /var/log/zeek/dns.log $InputFileTag zeek: $InputFileStateFile stat-zeek-dns $InputFileSeverity notice $InputFileFacility local5 $InputFilePollInterval 1 $InputRunFileMonitor # Template definition [RFC5424](https://tools.ietf.org/html/rfc5424#section-7.2.2) # IMPORTANT: don't forget to set your intake key in the template template ( name = \"SEKOIAIOZeekTemplate\" type = \"string\" string = \"<%pri%>1 %timestamp:::date-rfc3339% %hostname% %app-name% %procid% LOG [SEKOIA@53288 intake_key=\\\"YOUR_INTAKE_KEY\\\"] %msg%\\n\" ) # Send your events to SEKOIA.IO intake servers under SEKOIAIOZeekTemplate template if $programname startswith 'zeek' then @@ ( o ) intake.sekoia.io:10514 ; SEKOIAIOZeekTemplate In the above template instruction, please replace YOUR_INTAKE_KEY variable with your intake key. 3. Restart rsyslog 1 $ sudo service rsyslog restart 4. Enjoy your events Go to the events page to watch your incoming events. Related files SEKOIA-IO-intake.pem : SEKOIA.IO TLS Server Certificate (1674b) Further Reading Zeek documentation Rsyslog IMFile module","title":"Zeek"},{"location":"integrations/zeek/#overview","text":"Zeek is a free and open-source software network analysis framework; it was originally developed in 1994 by Vern Paxson and was named in reference to George Orwell's Big Brother from his novel Nineteen Eighty-Four. It can be used as a network intrusion detection system (NIDS) but with additional live analysis of network events.It is released under the BSD license.","title":"Overview"},{"location":"integrations/zeek/#setup","text":"This setup guide will show you how to forward dns, http and conn logs to SEKOIA.IO by means of an rsyslog transport channel. On most linux servers, two packages need to be installed: rsyslog and rsyslog-gnutls.","title":"Setup"},{"location":"integrations/zeek/#1-download-the-certificate","text":"In order to allow the connection of your rsyslog server to the SEKOIA.IO intake, please download the SEKOIA.IO intake certificate: 1 $ wget -O /etc/rsyslog.d/SEKOIA-IO-intake.pem https://app.sekoia.io/assets/files/SEKOIA-IO-intake.pem","title":"1. Download the certificate"},{"location":"integrations/zeek/#2-configure-the-rsyslog-server","text":"We can configure rsyslog to parse the conn.log http.log and dns.log and report its entries to SEKOIA.IO. Open or create a new Zeek configuration file for rsyslog: 1 sudo vim /etc/rsyslog.d/66-zeek.conf At the beginning of the configuration file, paste the following instruction to order the rsyslog server to load the module imfile : 1 $ModLoad imfile Then paste the following configuration to leverage this module to monitor zeek log files (please note that the path to the log file may change depending on the OS and your configuration): 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 # Define the SEKIOA-IO intake certificate $DefaultNetstreamDriverCAFile /etc/rsyslog.d/SEKOIA-IO-intake.pem # Configure up the network ssl connection $ActionSendStreamDriver gtls # use gtls netstream driver $ActionSendStreamDriverMode 1 # require TLS for the connection $ActionSendStreamDriverAuthMode x509/name # server is authenticated # conn log $InputFileName /var/log/zeek/conn.log $InputFileTag zeek: $InputFileStateFile stat-zeek-conn $InputFileSeverity notice $InputFileFacility local5 $InputFilePollInterval 1 $InputRunFileMonitor # http log $InputFileName /var/log/zeek/http.log $InputFileTag zeek: $InputFileStateFile stat-zeek-http $InputFileSeverity notice $InputFileFacility local5 $InputFilePollInterval 1 $InputRunFileMonitor # dns log $InputFileName /var/log/zeek/dns.log $InputFileTag zeek: $InputFileStateFile stat-zeek-dns $InputFileSeverity notice $InputFileFacility local5 $InputFilePollInterval 1 $InputRunFileMonitor # Template definition [RFC5424](https://tools.ietf.org/html/rfc5424#section-7.2.2) # IMPORTANT: don't forget to set your intake key in the template template ( name = \"SEKOIAIOZeekTemplate\" type = \"string\" string = \"<%pri%>1 %timestamp:::date-rfc3339% %hostname% %app-name% %procid% LOG [SEKOIA@53288 intake_key=\\\"YOUR_INTAKE_KEY\\\"] %msg%\\n\" ) # Send your events to SEKOIA.IO intake servers under SEKOIAIOZeekTemplate template if $programname startswith 'zeek' then @@ ( o ) intake.sekoia.io:10514 ; SEKOIAIOZeekTemplate In the above template instruction, please replace YOUR_INTAKE_KEY variable with your intake key.","title":"2. Configure the Rsyslog server"},{"location":"integrations/zeek/#3-restart-rsyslog","text":"1 $ sudo service rsyslog restart","title":"3. Restart rsyslog"},{"location":"integrations/zeek/#4-enjoy-your-events","text":"Go to the events page to watch your incoming events.","title":"4. Enjoy your events"},{"location":"integrations/zeek/#related-files","text":"SEKOIA-IO-intake.pem : SEKOIA.IO TLS Server Certificate (1674b)","title":"Related files"},{"location":"integrations/zeek/#further-reading","text":"Zeek documentation Rsyslog IMFile module","title":"Further Reading"},{"location":"intelligence_center/","text":"Intelligence Center The Intelligence Center is a Threat Intelligence knowledge base that is being constantly updated by SEKOIA analysts. It is meant to store all levels of Cyber Threat Intelligence (CTI), from strategic (targets, motivations) to technical (indicator of compromises). We recommend you learn about our data model before learning how you can leverage the API .","title":"Overview"},{"location":"intelligence_center/#intelligence-center","text":"The Intelligence Center is a Threat Intelligence knowledge base that is being constantly updated by SEKOIA analysts. It is meant to store all levels of Cyber Threat Intelligence (CTI), from strategic (targets, motivations) to technical (indicator of compromises). We recommend you learn about our data model before learning how you can leverage the API .","title":"Intelligence Center"},{"location":"intelligence_center/api/","text":"Intelligence Center API The API is reachable at https://api.sekoia.io . All Intelligence Center endpoints start with https://api.sekoia.io/v2/inthreat/ . Authentication Authentication is required for all API endpoints. Authentication is done with the Authorization header: 1 Authorization : Bearer < APIKEY > Feeds A feed allows filtering the CTI Objects based on some filters. The available filters are: Types TLPs Targeted sectors of activity Targeted locations Sources A feed can be consumed by all the users belonging to the community that created it. Default Feed A default feed with no filters is available in all communities without having to create it. The special feed ID to use is d6092c37-d8d7-45c3-8aff-c4dc26030608 . Feed Creation The easiest way to create feed configurations is to use the Intelligence Center interface, by clicking on Feeds in the left menu. The dropdown next to the feed's name will allow you to copy the ID or the consumption URLs of the feed. If you would prefer creating the feed with the API, you can use the feeds endpoint. The result should contain the feed id that may be used to consume the feed. Feed Consumption To consume the objects from a feed the following endpoint may be used: GET v2/inthreat/collections/{feed_id}/objects . i.e. GET v2/inthreat/collections/d6092c37-d8d7-45c3-8aff-c4dc26030608/objects/ Be aware that only the users belonging to the feed's community will be able to access it when using a custom feed. Pagination The objects endpoint returns only 100 objects by default but this value can be increased up to 2000 objects per request with the limit parameter. i.e. GET v2/inthreat/collections/{feed_id}/objects?limit=2000 The response contains the STIX Objects in items and a pagination cursor in next_cursor . You can pass this cursor using the cursor parameter to get the next page of content. i.e. GET v2/inthreat/collections/{feed_id}/objects?limit=2000&cursor={next_cursor} You can safely stop iterating when items is empty or less than the requested limit . Incremental Updates It is recommended to only fetch the full feed content the first time and then to use incremental updates. To get only the records that were created and/or modified since your last request, simply use the last next_cursor that was returned in your request. Filtering by Object Type It is possible to filter returned objects by type with the match[type] parameter. Its value should be a comma-separated list of types. i.e. GET v2/inthreat/collections/{feed_id}/objects?match[type]=indicator Note that if the type is not available in the feed it will not be returned even if specified in the query. Example Script Here is a sample Python script to fetch STIX objects from the Intelligence Center: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 import dbm import requests from posixpath import join as urljoin APIKEY = \"APIKEY\" DEFAULT_FEED = \"d6092c37-d8d7-45c3-8aff-c4dc26030608\" BASE_URL = \"https://api.sekoia.io/v2/inthreat/\" CURSOR_FILE = \"cursor.db\" def get_new_objects ( feed_id = DEFAULT_FEED , limit = 2000 ): url = urljoin ( BASE_URL , \"collections\" , feed_id , f \"objects?limit= {limit} \" ) paginated_url = url # Use the builtin dbm module to save the cursors to disk with dbm . open ( CURSOR_FILE , \"c\" ) as cursors : while True : # If a cursor exists for this feed, add it to the URL if feed_id in cursors : paginated_url = f \" {url} &cursor={cursors[feed_id].decode('ascii')}\" # Request the next batch of objects from the API, authenticate with the APIKEY response = requests . get ( paginated_url , headers = { \"Authorization\" : f \"Bearer {APIKEY} \" } ) response . raise_for_status () data = response . json () # Yield individual STIX Objects (SDO & SRO) for item in data [ \"items\" ]: yield item # Update cursor to have incremental updates cursors [ feed_id ] = data [ \"next_cursor\" ] # Stop current iteration if we reached the last updated object if not data [ \"items\" ] or len ( data [ \"items\" ]) < limit : break Getting an indicator's context When using indicators for detection, you might want to fetch all indicators by using a filter on the indicator type and then only fetch additional context when an indicator matched. The v2/inthreat/objects/{indicator_id}/context returns a STIX bundle containing: The indicator The first level relationships and related objects Potential relevant Course-Of-Action objects Referenced Sources and Object Markings Getting an object by its ID It is possible to get a specific object by its ID by using the GET v2/inthreat/objects/{object_id} endpoint. For relationships, use the GET v2/inthreat/relationships/{relationship_id} endpoint instead. Looking for an IOC It is possible to look for a specific indicator of compromise in the Intelligence Center and get its context with the GET v2/inthreat/indicators/context endpoint (see documentation ). 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 import json import requests from posixpath import join as urljoin APIKEY = \"APIKEY\" BASE_URL = \"https://api.sekoia.io/v2/inthreat/\" HEADERS = { \"Authorization\" : f \"Bearer {APIKEY} \" } def get_indicator_context ( observable_type , observable_value ): response = requests . get ( urljoin ( BASE_URL , \"indicators/context\" ), params = { \"type\" : observable_type , \"value\" : observable_value }, headers = HEADERS ) response . raise_for_status () return response . json () TAXII The Intelligence Center also exposes a TAXII 2.1 server that conforms to the specification . The discovery endpoint of the TAXII server is located at https://app.sekoia.io/api/v2/inthreat/taxii-server/taxii . TAXII relies on HTTP Basic Authentication. To authenticate to the TAXII server, you should use your Intelligence Center API key as the Basic Authentication password (you can use any username). Here is an example of a script using the TAXII endpoints to iterate over objects: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 import dbm import requests from basicauth import encode as basicauth_encode # Replace with Intelligence Center API Key APIKEY = \"APIKEY\" # Replace with the TAXII URL copied from the \"feeds\" page FEED_URL = \"https://app.sekoia.io/api/v2/inthreat/taxii-server/collections/d6092c37-d8d7-45c3-8aff-c4dc26030608/objects\" CURSOR_FILE = \"cursor.db\" def get_new_objects ( feed_url = FEED_URL , limit = 2000 , version = \"2.1\" ): has_more = True headers = { \"Accept\" : \"application/taxii+json\" , \"Authorization\" : basicauth_encode ( \"api\" , APIKEY ), } parameters = { \"match[spec_version]\" : version , \"limit\" : limit } # Use the builtin dbm module to save the cursors to disk with dbm . open ( CURSOR_FILE , \"c\" ) as cursors : while has_more : # If a cursor exists for this feed, add it to the parameters if feed_url in cursors : parameters [ \"next\" ] = cursors [ feed_url ] . decode ( \"ascii\" ) # Request the next batch of objects from the API, authenticate with the APIKEY response = requests . get ( feed_url , headers = headers , params = parameters ) response . raise_for_status () data = response . json () has_more = data [ \"more\" ] cursors [ feed_url ] = data [ \"next\" ] yield from data [ \"objects\" ]","title":"API"},{"location":"intelligence_center/api/#intelligence-center-api","text":"The API is reachable at https://api.sekoia.io . All Intelligence Center endpoints start with https://api.sekoia.io/v2/inthreat/ .","title":"Intelligence Center API"},{"location":"intelligence_center/api/#authentication","text":"Authentication is required for all API endpoints. Authentication is done with the Authorization header: 1 Authorization : Bearer < APIKEY >","title":"Authentication"},{"location":"intelligence_center/api/#feeds","text":"A feed allows filtering the CTI Objects based on some filters. The available filters are: Types TLPs Targeted sectors of activity Targeted locations Sources A feed can be consumed by all the users belonging to the community that created it.","title":"Feeds"},{"location":"intelligence_center/api/#default-feed","text":"A default feed with no filters is available in all communities without having to create it. The special feed ID to use is d6092c37-d8d7-45c3-8aff-c4dc26030608 .","title":"Default Feed"},{"location":"intelligence_center/api/#feed-creation","text":"The easiest way to create feed configurations is to use the Intelligence Center interface, by clicking on Feeds in the left menu. The dropdown next to the feed's name will allow you to copy the ID or the consumption URLs of the feed. If you would prefer creating the feed with the API, you can use the feeds endpoint. The result should contain the feed id that may be used to consume the feed.","title":"Feed Creation"},{"location":"intelligence_center/api/#feed-consumption","text":"To consume the objects from a feed the following endpoint may be used: GET v2/inthreat/collections/{feed_id}/objects . i.e. GET v2/inthreat/collections/d6092c37-d8d7-45c3-8aff-c4dc26030608/objects/ Be aware that only the users belonging to the feed's community will be able to access it when using a custom feed.","title":"Feed Consumption"},{"location":"intelligence_center/api/#pagination","text":"The objects endpoint returns only 100 objects by default but this value can be increased up to 2000 objects per request with the limit parameter. i.e. GET v2/inthreat/collections/{feed_id}/objects?limit=2000 The response contains the STIX Objects in items and a pagination cursor in next_cursor . You can pass this cursor using the cursor parameter to get the next page of content. i.e. GET v2/inthreat/collections/{feed_id}/objects?limit=2000&cursor={next_cursor} You can safely stop iterating when items is empty or less than the requested limit .","title":"Pagination"},{"location":"intelligence_center/api/#incremental-updates","text":"It is recommended to only fetch the full feed content the first time and then to use incremental updates. To get only the records that were created and/or modified since your last request, simply use the last next_cursor that was returned in your request.","title":"Incremental Updates"},{"location":"intelligence_center/api/#filtering-by-object-type","text":"It is possible to filter returned objects by type with the match[type] parameter. Its value should be a comma-separated list of types. i.e. GET v2/inthreat/collections/{feed_id}/objects?match[type]=indicator Note that if the type is not available in the feed it will not be returned even if specified in the query.","title":"Filtering by Object Type"},{"location":"intelligence_center/api/#example-script","text":"Here is a sample Python script to fetch STIX objects from the Intelligence Center: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 import dbm import requests from posixpath import join as urljoin APIKEY = \"APIKEY\" DEFAULT_FEED = \"d6092c37-d8d7-45c3-8aff-c4dc26030608\" BASE_URL = \"https://api.sekoia.io/v2/inthreat/\" CURSOR_FILE = \"cursor.db\" def get_new_objects ( feed_id = DEFAULT_FEED , limit = 2000 ): url = urljoin ( BASE_URL , \"collections\" , feed_id , f \"objects?limit= {limit} \" ) paginated_url = url # Use the builtin dbm module to save the cursors to disk with dbm . open ( CURSOR_FILE , \"c\" ) as cursors : while True : # If a cursor exists for this feed, add it to the URL if feed_id in cursors : paginated_url = f \" {url} &cursor={cursors[feed_id].decode('ascii')}\" # Request the next batch of objects from the API, authenticate with the APIKEY response = requests . get ( paginated_url , headers = { \"Authorization\" : f \"Bearer {APIKEY} \" } ) response . raise_for_status () data = response . json () # Yield individual STIX Objects (SDO & SRO) for item in data [ \"items\" ]: yield item # Update cursor to have incremental updates cursors [ feed_id ] = data [ \"next_cursor\" ] # Stop current iteration if we reached the last updated object if not data [ \"items\" ] or len ( data [ \"items\" ]) < limit : break","title":"Example Script"},{"location":"intelligence_center/api/#getting-an-indicators-context","text":"When using indicators for detection, you might want to fetch all indicators by using a filter on the indicator type and then only fetch additional context when an indicator matched. The v2/inthreat/objects/{indicator_id}/context returns a STIX bundle containing: The indicator The first level relationships and related objects Potential relevant Course-Of-Action objects Referenced Sources and Object Markings","title":"Getting an indicator's context"},{"location":"intelligence_center/api/#getting-an-object-by-its-id","text":"It is possible to get a specific object by its ID by using the GET v2/inthreat/objects/{object_id} endpoint. For relationships, use the GET v2/inthreat/relationships/{relationship_id} endpoint instead.","title":"Getting an object by its ID"},{"location":"intelligence_center/api/#looking-for-an-ioc","text":"It is possible to look for a specific indicator of compromise in the Intelligence Center and get its context with the GET v2/inthreat/indicators/context endpoint (see documentation ). 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 import json import requests from posixpath import join as urljoin APIKEY = \"APIKEY\" BASE_URL = \"https://api.sekoia.io/v2/inthreat/\" HEADERS = { \"Authorization\" : f \"Bearer {APIKEY} \" } def get_indicator_context ( observable_type , observable_value ): response = requests . get ( urljoin ( BASE_URL , \"indicators/context\" ), params = { \"type\" : observable_type , \"value\" : observable_value }, headers = HEADERS ) response . raise_for_status () return response . json ()","title":"Looking for an IOC"},{"location":"intelligence_center/api/#taxii","text":"The Intelligence Center also exposes a TAXII 2.1 server that conforms to the specification . The discovery endpoint of the TAXII server is located at https://app.sekoia.io/api/v2/inthreat/taxii-server/taxii . TAXII relies on HTTP Basic Authentication. To authenticate to the TAXII server, you should use your Intelligence Center API key as the Basic Authentication password (you can use any username). Here is an example of a script using the TAXII endpoints to iterate over objects: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 import dbm import requests from basicauth import encode as basicauth_encode # Replace with Intelligence Center API Key APIKEY = \"APIKEY\" # Replace with the TAXII URL copied from the \"feeds\" page FEED_URL = \"https://app.sekoia.io/api/v2/inthreat/taxii-server/collections/d6092c37-d8d7-45c3-8aff-c4dc26030608/objects\" CURSOR_FILE = \"cursor.db\" def get_new_objects ( feed_url = FEED_URL , limit = 2000 , version = \"2.1\" ): has_more = True headers = { \"Accept\" : \"application/taxii+json\" , \"Authorization\" : basicauth_encode ( \"api\" , APIKEY ), } parameters = { \"match[spec_version]\" : version , \"limit\" : limit } # Use the builtin dbm module to save the cursors to disk with dbm . open ( CURSOR_FILE , \"c\" ) as cursors : while has_more : # If a cursor exists for this feed, add it to the parameters if feed_url in cursors : parameters [ \"next\" ] = cursors [ feed_url ] . decode ( \"ascii\" ) # Request the next batch of objects from the API, authenticate with the APIKEY response = requests . get ( feed_url , headers = headers , params = parameters ) response . raise_for_status () data = response . json () has_more = data [ \"more\" ] cursors [ feed_url ] = data [ \"next\" ] yield from data [ \"objects\" ]","title":"TAXII"},{"location":"intelligence_center/dashboard/","text":"Dashboards Default Dashboard When connecting to the Intelligence Center, and if the permissions granted allow it, you arrive on the \"Dashboard\" page. This allows you to have a quick view of the content of the Intelligence Center as well as the most recently added information. This functionality is available to all customers who subscribe to the Intelligence Center. Create and edit dashboards The Default Dashboard cannot be modified. However, each user has the possibility of creating other dashboards, in order to obtain filtered views of data relevant to their use. You also have the possibility to duplicate an existing dashboard and to edit the resulting new one. It is thus possible to create dashboards by sector of activity or by geographical area and the number of dashboards is not limited. Note Each dashboard you create will be available to all members of your community.","title":"Dashboards"},{"location":"intelligence_center/dashboard/#dashboards","text":"","title":"Dashboards"},{"location":"intelligence_center/dashboard/#default-dashboard","text":"When connecting to the Intelligence Center, and if the permissions granted allow it, you arrive on the \"Dashboard\" page. This allows you to have a quick view of the content of the Intelligence Center as well as the most recently added information. This functionality is available to all customers who subscribe to the Intelligence Center.","title":"Default Dashboard"},{"location":"intelligence_center/dashboard/#create-and-edit-dashboards","text":"The Default Dashboard cannot be modified. However, each user has the possibility of creating other dashboards, in order to obtain filtered views of data relevant to their use. You also have the possibility to duplicate an existing dashboard and to edit the resulting new one. It is thus possible to create dashboards by sector of activity or by geographical area and the number of dashboards is not limited. Note Each dashboard you create will be available to all members of your community.","title":"Create and edit dashboards"},{"location":"intelligence_center/data_export/","text":"Data Export When on an Object's page or when looking at a Report, you can export related items directly from the application and download them in the CSV or JSON format. The export modal lets you to select: If you want to export all relationships or select a specific type The format of the created file (CSV or JSON) The CSV format will convert some values (such as the TLP, sources and kill chain phases) to a human-readable format instead of IDs.","title":"Data Export"},{"location":"intelligence_center/data_export/#data-export","text":"When on an Object's page or when looking at a Report, you can export related items directly from the application and download them in the CSV or JSON format. The export modal lets you to select: If you want to export all relationships or select a specific type The format of the created file (CSV or JSON) The CSV format will convert some values (such as the TLP, sources and kill chain phases) to a human-readable format instead of IDs.","title":"Data Export"},{"location":"intelligence_center/data_model/","text":"Data Model The Intelligence Center uses the industry standard STIX to represent information, in its upcoming 2.1 version . STIX uses JSON objects with pre-defined schemas to represent Cyber Threat Intelligence data. The knowledge graph is based on nodes (STIX Domain Objects or SDO) and relationships (STIX Relationship Objects or SRO). The Intelligence Center supports the following STIX Domain Objects: Attack Pattern Campaign Course of Action Identity Indicator Intrusion Set Location Malware Report Threat Actor Tool Vulnerability External Sources One of the founding principle of the Intelligence Center is the consolidation of information coming from several sources. Sources are represented in STIX by Identity objects. Our consolidation strategy means that the created_by_ref field of the STIX objects will always be set to the SEKOIA identity. The sources that contributed to one of our STIX object are available, as references, in the x_inthreat_sources_refs custom field. As an exemple, here are parts of the Spearphishing Link object presented in the screenshot: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 { \"type\" : \"attack-pattern\" , \"name\" : \"Spearphishing Link\" , \"id\" : \"attack-pattern--6cd1a813-ccdf-4ba0-9b54-cb808f1059cc\" , \"created_by_ref\" : \"identity--357447d7-9229-4ce1-b7fa-f1b83587048e\" , # SEKOIA \"x_inthreat_sources_refs\" : [ \"identity--357447d7-9229-4ce1-b7fa-f1b83587048e\" , # SEKOIA \"identity--c78cb6e5-0c4b-4611-8297-d1b8b55e40b5\" # The MITRE Corporation ], [...] } Confidence STIX 2.1 adds an optional confidence field for an object creator to express how confident (s)he is about the information. The Intelligence Center uses the confidence field in two ways: On objects, the confidence score may be specified to express a specific confidence level on an object. When specified, this confidence level should be read with the Admiralty Credibility scale. Score Label Explanation 1 Confirmed by other sources Confirmed by other independent sources; logical in itself; Consistent with other information on the subject 2 Probably True Not confirmed; logical in itself; consistent with other information on the subject 3 Possibly True Not confirmed; reasonably logical in itself; agrees with some other information on the subject 4 Doubtful Not confirmed; possible but not logical; no other information on the subject 5 Improbable Not confirmed; not logical in itself; contradicted by other information on the subject 6 Truth cannot be judged No basis exists for evaluating the validity of the information On source objects (of type Identity ), the confidence score may be specified to express the source's reliability. When specified, this confidence level should be read with the Admiralty Reliability scale. Score Label Explanation A Completely reliable No doubt of authenticity, trustworthiness, or competency; has a history of complete reliability B Usually reliable Minor doubt about authenticity, trustworthiness, or competency; has a history of valid information most of the time C Fairly reliable Doubt of authenticity, trustworthiness, or competency but has provided valid information in the past D Not usually reliable Significant doubt about authenticity, trustworthiness, or competency but has provided valid information in the past E Unreliable Lacking in authenticity, trustworthiness, and competency; history of invalid information F Reliability cannot be judged No basis exists for evaluating the reliability of the source","title":"Data Model"},{"location":"intelligence_center/data_model/#data-model","text":"The Intelligence Center uses the industry standard STIX to represent information, in its upcoming 2.1 version . STIX uses JSON objects with pre-defined schemas to represent Cyber Threat Intelligence data. The knowledge graph is based on nodes (STIX Domain Objects or SDO) and relationships (STIX Relationship Objects or SRO). The Intelligence Center supports the following STIX Domain Objects: Attack Pattern Campaign Course of Action Identity Indicator Intrusion Set Location Malware Report Threat Actor Tool Vulnerability","title":"Data Model"},{"location":"intelligence_center/data_model/#external-sources","text":"One of the founding principle of the Intelligence Center is the consolidation of information coming from several sources. Sources are represented in STIX by Identity objects. Our consolidation strategy means that the created_by_ref field of the STIX objects will always be set to the SEKOIA identity. The sources that contributed to one of our STIX object are available, as references, in the x_inthreat_sources_refs custom field. As an exemple, here are parts of the Spearphishing Link object presented in the screenshot: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 { \"type\" : \"attack-pattern\" , \"name\" : \"Spearphishing Link\" , \"id\" : \"attack-pattern--6cd1a813-ccdf-4ba0-9b54-cb808f1059cc\" , \"created_by_ref\" : \"identity--357447d7-9229-4ce1-b7fa-f1b83587048e\" , # SEKOIA \"x_inthreat_sources_refs\" : [ \"identity--357447d7-9229-4ce1-b7fa-f1b83587048e\" , # SEKOIA \"identity--c78cb6e5-0c4b-4611-8297-d1b8b55e40b5\" # The MITRE Corporation ], [...] }","title":"External Sources"},{"location":"intelligence_center/data_model/#confidence","text":"STIX 2.1 adds an optional confidence field for an object creator to express how confident (s)he is about the information. The Intelligence Center uses the confidence field in two ways: On objects, the confidence score may be specified to express a specific confidence level on an object. When specified, this confidence level should be read with the Admiralty Credibility scale. Score Label Explanation 1 Confirmed by other sources Confirmed by other independent sources; logical in itself; Consistent with other information on the subject 2 Probably True Not confirmed; logical in itself; consistent with other information on the subject 3 Possibly True Not confirmed; reasonably logical in itself; agrees with some other information on the subject 4 Doubtful Not confirmed; possible but not logical; no other information on the subject 5 Improbable Not confirmed; not logical in itself; contradicted by other information on the subject 6 Truth cannot be judged No basis exists for evaluating the validity of the information On source objects (of type Identity ), the confidence score may be specified to express the source's reliability. When specified, this confidence level should be read with the Admiralty Reliability scale. Score Label Explanation A Completely reliable No doubt of authenticity, trustworthiness, or competency; has a history of complete reliability B Usually reliable Minor doubt about authenticity, trustworthiness, or competency; has a history of valid information most of the time C Fairly reliable Doubt of authenticity, trustworthiness, or competency but has provided valid information in the past D Not usually reliable Significant doubt about authenticity, trustworthiness, or competency but has provided valid information in the past E Unreliable Lacking in authenticity, trustworthiness, and competency; history of invalid information F Reliability cannot be judged No basis exists for evaluating the reliability of the source","title":"Confidence"},{"location":"intelligence_center/graph_explorations/","text":"Graph Explorations Graph Explorations enables you to select objects and relationships from the knowledge base and add them to a graphical representation that you can then share with your colleagues. Start an Exploration You can start a Graph Exploration from any object in the Intelligence Center, by clicking on the \"New Graph Exploration\" button at the top right of the page. You can also start an exploration from a Report graph. Add Relationships Clicking on any object on the graph displays related information in the side panel. You can also list relationships with the \"Relationships\" tab. From this list, you can add any relationship to the graph by clicking the hover button. Remove Items You can remove relationships from the graph by clicking on the hover button from the relationship list. Objects can be removed by clicking the red trash icon next to their name. Removing a node automatically removes associated relationships. Save Graph Exploration Whenever you would like to save a newly created graph exploration, or the changes you made to an existing one, click on the Save button in the toolbar. If this is a creation, you will be prompted for a name. List saved Explorations At any time, it is possible to list saved explorations from your community by clicking on the \"Graph Explorations\" item of the menu. From there, you will be able to dive into saved explorations by clicking on any of them.","title":"Graph Explorations"},{"location":"intelligence_center/graph_explorations/#graph-explorations","text":"Graph Explorations enables you to select objects and relationships from the knowledge base and add them to a graphical representation that you can then share with your colleagues.","title":"Graph Explorations"},{"location":"intelligence_center/graph_explorations/#start-an-exploration","text":"You can start a Graph Exploration from any object in the Intelligence Center, by clicking on the \"New Graph Exploration\" button at the top right of the page. You can also start an exploration from a Report graph.","title":"Start an Exploration"},{"location":"intelligence_center/graph_explorations/#add-relationships","text":"Clicking on any object on the graph displays related information in the side panel. You can also list relationships with the \"Relationships\" tab. From this list, you can add any relationship to the graph by clicking the hover button.","title":"Add Relationships"},{"location":"intelligence_center/graph_explorations/#remove-items","text":"You can remove relationships from the graph by clicking on the hover button from the relationship list. Objects can be removed by clicking the red trash icon next to their name. Removing a node automatically removes associated relationships.","title":"Remove Items"},{"location":"intelligence_center/graph_explorations/#save-graph-exploration","text":"Whenever you would like to save a newly created graph exploration, or the changes you made to an existing one, click on the Save button in the toolbar. If this is a creation, you will be prompted for a name.","title":"Save Graph Exploration"},{"location":"intelligence_center/graph_explorations/#list-saved-explorations","text":"At any time, it is possible to list saved explorations from your community by clicking on the \"Graph Explorations\" item of the menu. From there, you will be able to dive into saved explorations by clicking on any of them.","title":"List saved Explorations"},{"location":"intelligence_center/integrations/","text":"Intelligence Center external integrations Intelligence Center data can be consumed using several third party integrations. MISP Feed The default feed is available as a MISP feed. It can be added to an existing MISP instance by following MISP's documentation . The following field values are required for the feed to work properly: Input Source: Network URL: https://api.sekoia.io/api/v2/inthreat/misp Source Format: MISP Feed Headers: Authorization: Bearer <APIKEY> Enabled: True You then need to make sure you have a scheduled task in place to regularly fetch the feed's content. OpenCTI connector An OpenCTI connector is available to consumme a feed. All the instruction to run it are available at the connector GitHub repository: https://github.com/SEKOIA-IO/opencti-connector. Cortex Analyser SEKOIA is also providing a Cortex analyzer to enrich data in TheHive ecosystem. To setup the analyzer please follow this guide . SEKOIA.IO App for Splunk An App for Splunk is available to detect threats in your logs based on our feed. You can find the download links and additional information on the dedicated GitHub repository .","title":"External Integrations"},{"location":"intelligence_center/integrations/#intelligence-center-external-integrations","text":"Intelligence Center data can be consumed using several third party integrations.","title":"Intelligence Center external integrations"},{"location":"intelligence_center/integrations/#misp-feed","text":"The default feed is available as a MISP feed. It can be added to an existing MISP instance by following MISP's documentation . The following field values are required for the feed to work properly: Input Source: Network URL: https://api.sekoia.io/api/v2/inthreat/misp Source Format: MISP Feed Headers: Authorization: Bearer <APIKEY> Enabled: True You then need to make sure you have a scheduled task in place to regularly fetch the feed's content.","title":"MISP Feed"},{"location":"intelligence_center/integrations/#opencti-connector","text":"An OpenCTI connector is available to consumme a feed. All the instruction to run it are available at the connector GitHub repository: https://github.com/SEKOIA-IO/opencti-connector.","title":"OpenCTI connector"},{"location":"intelligence_center/integrations/#cortex-analyser","text":"SEKOIA is also providing a Cortex analyzer to enrich data in TheHive ecosystem. To setup the analyzer please follow this guide .","title":"Cortex Analyser"},{"location":"intelligence_center/integrations/#sekoiaio-app-for-splunk","text":"An App for Splunk is available to detect threats in your logs based on our feed. You can find the download links and additional information on the dedicated GitHub repository .","title":"SEKOIA.IO App for Splunk"},{"location":"operation_center/","text":"Operation Center The Operation Center allows you to integrate and analyze in real time the events produced by your systems. The detection strategy is based on the enhancement of SEKOIA's threat intelligence knowledge base, as well as on the modeling of specific threat scenarios.","title":"Overview"},{"location":"operation_center/#operation-center","text":"The Operation Center allows you to integrate and analyze in real time the events produced by your systems. The detection strategy is based on the enhancement of SEKOIA's threat intelligence knowledge base, as well as on the modeling of specific threat scenarios.","title":"Operation Center"},{"location":"operation_center/alerts/","text":"Alerts Management Alerts List When you first connect to SEKOIA.IO, alerts list is filtered and will diplay 'New today' alerts and sorted in descending order of urgency. The sort and filter choices you make from this list will be kept thereafter. On this screen, you can view the following information: Alert Id, begin with AL followed by 10 alphanumeric characters. On the top right of the ID box, there may be an yellow round with a number, it's the similarity counter. Alert creation date Alert status. When hovering over the icon, a frame indicates the status modification date and who modified it. The entity to which the alert corresponds Urgency of the alert, between 0 and 100, 100 being the highest. The category and sub-category of alerts The name of the rule which triggered the alert The source and destination IP when event is a network event. Alerts can be filtered by two ways: a rapid filter on the top left of the list and a list of cumulative filtering criteria on the top right of the screen. Alert Details The access to the detail of an alert is done by clicking on the Alert ID in the Alert list. The alert detail screen contains several blocks of information. On the largest area of the screen is a graphic representation of the alert. It represents the different objects composing the alert, each type having its self icon. The yellow magnifying glasses represent the observed data, eg the events associated with the alert. Medical suitcase corresponds to proposed countermeasures, bug on red bubble to malware, and so on. When you click on these icons, the left part of the screen will display details of the selected element. Alert type, description, kill chain phase and urgency can be modified, by clicking on the 'pencil' button on the top right of the frame. Tab with a sticking plaster icon will display proposed countermeasures linked to the alert. You can act on countermeasures, confirming or rejecting them by clicking on the corresponding icons. A countermeasure can be constituted of several action steps, which can be confirmed or rejected independently if needed. By confirming a countermeasures, you indicate to the platform that you have undertaken the corresponding action on your system. The urgency of the alert will thereby decrease, as well as the risk indicator. Countermeasures are in OpenC2 format, which you can visualize by clicking on the '<>' icon. Alert statuses and lifecycle There is five possible statuses for an alert: Pending : As soon as an alert is triggered, it is placed in 'Pending' status. If the generation mode for this alert is 'Automatic', this status changes automatically to 'Ongoing'. In other cases, the following actions are accepted: Acknowledge, Reject, Validate. Acknowledged : This status is used when an analysis is ongoing. If the analyst can decide if an alert is a true or a false positive quickly, this status can be optional, time to acknowledge used in statistics will be set to time to change to Ongoing or Rejected status.The following actions are accepted: Validate, Reject. Ongoing : Alert is considered as true positive and countermeasures are not yet been applied. This status is the first one seen in case of automatic mode. The following actions are accepted: Close (countermeasures have been applied, no more alert), Reject (after more analysis, this alert was a false positive). Closed : Every necessary actions have been applied for the alert. This status is a final status, no action accepted. Rejected : The alert was a false positive. This status is a final status, no action accepted. Alert Urgency The Urgency is a number used to give a score to the risk associated with a specific alert. It is calculated from the severity of a rule and the criticality of assets related to the alert. This gives a value between 1 (very low risk) and 100 (very high risk). The urgency is provided under two different representations on alert detail: a numerical and a textual representation. Display Value Low [0-20[ Moderate [20-40[ High [40-60[ Major [60-80[ Urgent [80-100] Similarity Alert similarity aims to regroup similar events in existing alerts. When an event matches with a rule, an alert is raised. If there is already an alert with similar information (rule, entity, source and destination), the event is associated with this existing alert rather than used to create a new one. This association is done only for Pending, Acknowledged and Ongoing alerts. If there's a matching alert on status Closed or Rejected, a new alert will be triggered by the event. Similarity counter is shown on a yellow circle on the top right of the alert id on the list. The number corresponds to the added events to an existing alert. Alert type and category The Alert Type is associated with the rule template, but can be changed with the value associated to specific indicators in case of cti rules. The Alert Type is defined according to a custom set of values derived from theReference Incident Classification Taxonomy of ENISA: abusive-usage bandwidth-download bandwidth-upload p2p high-drop abusive-content spam harmfull-speech violence malicious-code virus worm trojan spyware dialer rootkit malware botnet-drone ransomware malware-configuration c&c information-gathering scanner sniffing social-engineering portscan sweepscan appscan intrusion-attempts ids-alert brute-force exploit intrusions privileged-account-compromise unprivileged-account-compromise application-compromise bot defacement compromised backdoor availability dos ddos sabotage outage information-content-security Unauthorised-information-access Unauthorised-information-modification fraud unauthorized-use-of-resources copyright masquerade phishing vulnerable vulnerable-service other blacklist unknown other test test","title":"Alerts"},{"location":"operation_center/alerts/#alerts-management","text":"","title":"Alerts Management"},{"location":"operation_center/alerts/#alerts-list","text":"When you first connect to SEKOIA.IO, alerts list is filtered and will diplay 'New today' alerts and sorted in descending order of urgency. The sort and filter choices you make from this list will be kept thereafter. On this screen, you can view the following information: Alert Id, begin with AL followed by 10 alphanumeric characters. On the top right of the ID box, there may be an yellow round with a number, it's the similarity counter. Alert creation date Alert status. When hovering over the icon, a frame indicates the status modification date and who modified it. The entity to which the alert corresponds Urgency of the alert, between 0 and 100, 100 being the highest. The category and sub-category of alerts The name of the rule which triggered the alert The source and destination IP when event is a network event. Alerts can be filtered by two ways: a rapid filter on the top left of the list and a list of cumulative filtering criteria on the top right of the screen.","title":"Alerts List"},{"location":"operation_center/alerts/#alert-details","text":"The access to the detail of an alert is done by clicking on the Alert ID in the Alert list. The alert detail screen contains several blocks of information. On the largest area of the screen is a graphic representation of the alert. It represents the different objects composing the alert, each type having its self icon. The yellow magnifying glasses represent the observed data, eg the events associated with the alert. Medical suitcase corresponds to proposed countermeasures, bug on red bubble to malware, and so on. When you click on these icons, the left part of the screen will display details of the selected element. Alert type, description, kill chain phase and urgency can be modified, by clicking on the 'pencil' button on the top right of the frame. Tab with a sticking plaster icon will display proposed countermeasures linked to the alert. You can act on countermeasures, confirming or rejecting them by clicking on the corresponding icons. A countermeasure can be constituted of several action steps, which can be confirmed or rejected independently if needed. By confirming a countermeasures, you indicate to the platform that you have undertaken the corresponding action on your system. The urgency of the alert will thereby decrease, as well as the risk indicator. Countermeasures are in OpenC2 format, which you can visualize by clicking on the '<>' icon.","title":"Alert Details"},{"location":"operation_center/alerts/#alert-statuses-and-lifecycle","text":"There is five possible statuses for an alert: Pending : As soon as an alert is triggered, it is placed in 'Pending' status. If the generation mode for this alert is 'Automatic', this status changes automatically to 'Ongoing'. In other cases, the following actions are accepted: Acknowledge, Reject, Validate. Acknowledged : This status is used when an analysis is ongoing. If the analyst can decide if an alert is a true or a false positive quickly, this status can be optional, time to acknowledge used in statistics will be set to time to change to Ongoing or Rejected status.The following actions are accepted: Validate, Reject. Ongoing : Alert is considered as true positive and countermeasures are not yet been applied. This status is the first one seen in case of automatic mode. The following actions are accepted: Close (countermeasures have been applied, no more alert), Reject (after more analysis, this alert was a false positive). Closed : Every necessary actions have been applied for the alert. This status is a final status, no action accepted. Rejected : The alert was a false positive. This status is a final status, no action accepted.","title":"Alert statuses and lifecycle"},{"location":"operation_center/alerts/#alert-urgency","text":"The Urgency is a number used to give a score to the risk associated with a specific alert. It is calculated from the severity of a rule and the criticality of assets related to the alert. This gives a value between 1 (very low risk) and 100 (very high risk). The urgency is provided under two different representations on alert detail: a numerical and a textual representation. Display Value Low [0-20[ Moderate [20-40[ High [40-60[ Major [60-80[ Urgent [80-100]","title":"Alert Urgency"},{"location":"operation_center/alerts/#similarity","text":"Alert similarity aims to regroup similar events in existing alerts. When an event matches with a rule, an alert is raised. If there is already an alert with similar information (rule, entity, source and destination), the event is associated with this existing alert rather than used to create a new one. This association is done only for Pending, Acknowledged and Ongoing alerts. If there's a matching alert on status Closed or Rejected, a new alert will be triggered by the event. Similarity counter is shown on a yellow circle on the top right of the alert id on the list. The number corresponds to the added events to an existing alert.","title":"Similarity"},{"location":"operation_center/alerts/#alert-type-and-category","text":"The Alert Type is associated with the rule template, but can be changed with the value associated to specific indicators in case of cti rules. The Alert Type is defined according to a custom set of values derived from theReference Incident Classification Taxonomy of ENISA: abusive-usage bandwidth-download bandwidth-upload p2p high-drop abusive-content spam harmfull-speech violence malicious-code virus worm trojan spyware dialer rootkit malware botnet-drone ransomware malware-configuration c&c information-gathering scanner sniffing social-engineering portscan sweepscan appscan intrusion-attempts ids-alert brute-force exploit intrusions privileged-account-compromise unprivileged-account-compromise application-compromise bot defacement compromised backdoor availability dos ddos sabotage outage information-content-security Unauthorised-information-access Unauthorised-information-modification fraud unauthorized-use-of-resources copyright masquerade phishing vulnerable vulnerable-service other blacklist unknown other test test","title":"Alert type and category"},{"location":"operation_center/assets/","text":"Assets management Assets in SEKOIA.IO can be of different types. The most commonly used are: Computers, identified by an ip address or a hostname Networks, identified by cidr Users, identified by an email address ... The numbers of events and alerts associated with assets for the past 7 days, as well as the risk level, are displayed in the asset list. Assets participate to the security workflow of the community, when an incoming event matches with a defined asset, the event is enriched with assets information. Their criticality will be taken into account when calculating the urgency of an alert, together with the severity of the rule that triggered the alert. When more than one asset match with an event, the highest criticality is used for urgency calculation. Criticality of assets ranges from 0 to 100, 100 being the most critical. Assets also permit the selective application of detection rules: rules can be applied to one, several or all entities, and to one, several or all assets.","title":"Assets"},{"location":"operation_center/assets/#assets-management","text":"Assets in SEKOIA.IO can be of different types. The most commonly used are: Computers, identified by an ip address or a hostname Networks, identified by cidr Users, identified by an email address ... The numbers of events and alerts associated with assets for the past 7 days, as well as the risk level, are displayed in the asset list. Assets participate to the security workflow of the community, when an incoming event matches with a defined asset, the event is enriched with assets information. Their criticality will be taken into account when calculating the urgency of an alert, together with the severity of the rule that triggered the alert. When more than one asset match with an event, the highest criticality is used for urgency calculation. Criticality of assets ranges from 0 to 100, 100 being the most critical. Assets also permit the selective application of detection rules: rules can be applied to one, several or all entities, and to one, several or all assets.","title":"Assets management"},{"location":"operation_center/cases/","text":"Cases Management Cases allow information relating to security records to be shared whith members of your community. A case consists of a title, a description, a severity, and may be associated with alerts from the Operation Center. A case has a lifecycle (currently, open or closed) and can be assigned to one or more people. This feature allows, for example, a security supervision team to escalate alerts to another team for clarification or to group alerts that seem related to facilitate analysis.","title":"Cases"},{"location":"operation_center/cases/#cases-management","text":"Cases allow information relating to security records to be shared whith members of your community. A case consists of a title, a description, a severity, and may be associated with alerts from the Operation Center. A case has a lifecycle (currently, open or closed) and can be assigned to one or more people. This feature allows, for example, a security supervision team to escalate alerts to another team for clarification or to group alerts that seem related to facilitate analysis.","title":"Cases Management"},{"location":"operation_center/entities/","text":"Entities Entities allow a logical grouping of your data sources and the associated alerts. It can be a company site, network zone, or any other grouping that you think is relevant. All fields of entities are editable and mandatory. The Alert generation mode affects the alert processing workflow. There are two generation modes: 'automatic', for which the alerts proceed to the status 'Ongoing' immediately after their creation 'manual', for which the alerts remain in the status 'Pending' until a manual action. A default value for alert generation mode is defined for each entity, which can be override in each detection rule. Under the entity details, you will find the associated data sources. To activate a new intake for your entity, please refer to the intakes documentation.","title":"Entities"},{"location":"operation_center/entities/#entities","text":"Entities allow a logical grouping of your data sources and the associated alerts. It can be a company site, network zone, or any other grouping that you think is relevant. All fields of entities are editable and mandatory. The Alert generation mode affects the alert processing workflow. There are two generation modes: 'automatic', for which the alerts proceed to the status 'Ongoing' immediately after their creation 'manual', for which the alerts remain in the status 'Pending' until a manual action. A default value for alert generation mode is defined for each entity, which can be override in each detection rule. Under the entity details, you will find the associated data sources. To activate a new intake for your entity, please refer to the intakes documentation.","title":"Entities"},{"location":"operation_center/events/","text":"Events Page The events page diplays a list of latest events received by SEKOIA.IO. You can search among them by using Dork query langage, for which you can find more information here . On the event page, you can access the raw format of your events, as received by SEKOIA.IO and the STIX format in which it is transformed.","title":"Events"},{"location":"operation_center/events/#events-page","text":"The events page diplays a list of latest events received by SEKOIA.IO. You can search among them by using Dork query langage, for which you can find more information here . On the event page, you can access the raw format of your events, as received by SEKOIA.IO and the STIX format in which it is transformed.","title":"Events Page"},{"location":"operation_center/faq/","text":"Operation Center: Frequently Asked Questions Is the IP behind intake.sekoia.io static? IP for intake.sekoia.io is 145.239.192.38 . intake.sekoia.io is the domain name used to send your logs to SEKOIA.IO, either via Syslog or HTTP protocols. The IP address behind that service is static and stable. You can use that IP to configure your firewalls to allow connections from your forwarding systems to SEKOIA.IO. How to debug Rsyslog\u2019s forward configuration to SEKOIA.IO? If you use Rsyslog to forward your logs to SEKOIA.IO, you will probably have a section like this in your configuration files: 1 2 template ( name = \"SEKOIAIOUnboundTemplate\" type = \"string\" string = \"<%pri%>1 %timestamp:::date-rfc3339% %hostname% %app-name% %procid% LOG [SEKOIA@53288 intake_key= \\\" jOK5bMVXz5Iz7gfogQDbCcC7l7S2IrOs5 \\\" ] %msg% \\n \" ) if $ programname startswith ' unbound ' then @ @( o ) intake . sekoia . io : 10514 ; SEKOIAIOUnboundTemplate If you want to retrieve the raw data that is forwarded to SEKOIA.IO, you can duplicate the last line and make Rsyslog dump logs to a local file: 1 if $programname startswith 'unbound' then /tmp/nginx-output.log;SEKOIAIOUnboundTemplate This way, you will be able to exactly identify what data is sent to SEKOIA.IO. 1 2 # tail -n 1 /tmp/nginx-output.log < 30 > 1 2021 - 01 - 13 T14 : 52 : 06.934860 + 01 : 00 ote unbound - LOG [ SEKOIA @53288 intake_key = \"jOK5bMVXz5Iz7gfogQDbCcC7l7S2IrOs5\" ] [ 596451 : 0 ] info : 127.0.0.1 intake . sekoia . io . A IN","title":"FAQ"},{"location":"operation_center/faq/#operation-center-frequently-asked-questions","text":"","title":"Operation Center: Frequently Asked Questions"},{"location":"operation_center/faq/#is-the-ip-behind-intakesekoiaio-static","text":"IP for intake.sekoia.io is 145.239.192.38 . intake.sekoia.io is the domain name used to send your logs to SEKOIA.IO, either via Syslog or HTTP protocols. The IP address behind that service is static and stable. You can use that IP to configure your firewalls to allow connections from your forwarding systems to SEKOIA.IO.","title":"Is the IP behind intake.sekoia.io static?"},{"location":"operation_center/faq/#how-to-debug-rsyslogs-forward-configuration-to-sekoiaio","text":"If you use Rsyslog to forward your logs to SEKOIA.IO, you will probably have a section like this in your configuration files: 1 2 template ( name = \"SEKOIAIOUnboundTemplate\" type = \"string\" string = \"<%pri%>1 %timestamp:::date-rfc3339% %hostname% %app-name% %procid% LOG [SEKOIA@53288 intake_key= \\\" jOK5bMVXz5Iz7gfogQDbCcC7l7S2IrOs5 \\\" ] %msg% \\n \" ) if $ programname startswith ' unbound ' then @ @( o ) intake . sekoia . io : 10514 ; SEKOIAIOUnboundTemplate If you want to retrieve the raw data that is forwarded to SEKOIA.IO, you can duplicate the last line and make Rsyslog dump logs to a local file: 1 if $programname startswith 'unbound' then /tmp/nginx-output.log;SEKOIAIOUnboundTemplate This way, you will be able to exactly identify what data is sent to SEKOIA.IO. 1 2 # tail -n 1 /tmp/nginx-output.log < 30 > 1 2021 - 01 - 13 T14 : 52 : 06.934860 + 01 : 00 ote unbound - LOG [ SEKOIA @53288 intake_key = \"jOK5bMVXz5Iz7gfogQDbCcC7l7S2IrOs5\" ] [ 596451 : 0 ] info : 127.0.0.1 intake . sekoia . io . A IN","title":"How to debug Rsyslog\u2019s forward configuration to SEKOIA.IO?"},{"location":"operation_center/intakes/","text":"Intakes - Data Sources Management Intakes correspond to data sources sent to SEKOIA.IO. They are identified by a name, a log format and an 'intake key', which is used to configure the sending from your information system. On the intake list, the number of events sent to SEKOIA.IO for the past 7 days and the number of events in error (not integrated) are displayed, as well as the intake key, with a button to copy this value to the clipboard. To add a new intake, you will have to enter a name for it, choose the entity to which you want to associate the corresponding data and to choose the format of the events. All the documentation for integration of your data sources is also available in the integrations page. Do not hesitate to contact us at support@sekoia.io if the settings recommendations provided are not sufficient or not applicable to your system. We can then see with you how to transfer your events in the best conditions. Do neither hesitate to contact us if the format of the logs you want to send us is not in the list, we regularly add new formats, we can tell you when yours will be available.","title":"Intakes"},{"location":"operation_center/intakes/#intakes-data-sources-management","text":"Intakes correspond to data sources sent to SEKOIA.IO. They are identified by a name, a log format and an 'intake key', which is used to configure the sending from your information system. On the intake list, the number of events sent to SEKOIA.IO for the past 7 days and the number of events in error (not integrated) are displayed, as well as the intake key, with a button to copy this value to the clipboard. To add a new intake, you will have to enter a name for it, choose the entity to which you want to associate the corresponding data and to choose the format of the events. All the documentation for integration of your data sources is also available in the integrations page. Do not hesitate to contact us at support@sekoia.io if the settings recommendations provided are not sufficient or not applicable to your system. We can then see with you how to transfer your events in the best conditions. Do neither hesitate to contact us if the format of the logs you want to send us is not in the list, we regularly add new formats, we can tell you when yours will be available.","title":"Intakes - Data Sources Management"},{"location":"operation_center/rules/","text":"Detection Rules Management Rules list On the alerts list, you can see in one look the following information. The status of your rules: Enabled or Disabled, plus the rules that can't compile will appear on a red background. The number of entities and assets to which the rule will be applied (default: all). The total of filtered alerts for the rule, corresponding to the number of alerts that where not raised, because the events corresponding to the signature of the rule where matching filter conditions. The total numbers of alerts raised and rejected during the past 7 days for each rule. A toggle button allows a quick enablement/disablement of rules. Rule details On top of the details of a rule, you can see when it was last updated and by who. The name of the rule will be used to name the corresponding raised alerts by default. Detection rules can be applied to all events, whatever the entity to which they are attached or the assets to which they can be linked, or applied only to some of them. If 'Using all entities' and 'Using all assets' are selected, rules will apply to all events even if new entites or new assets were added since last rule modification. For rules for which some entities or some assets were selected, if new entities or new assets are created, detection will not occur on corresponding events whithout rule modification. The signature part corresponds to the rule itself, the detection pattern applied to events. There're two type of rules: CTI or correlation. For CTI rules, you just have to select the source of the indicators: SEKOIA Intelligence Feed is an IOCs feed managed by SEKOIA's Purple Team (Indicators present in the SEKOIA.IO Intelligence Center). For correlation rules, the language used is STIX Patterning. More details about this langage are given below . Alert filters are used to avoid triggering alerts even if the events match the rule. Events that match the signature rule AND the alert filter criteria won't lead to the raising of an alert. Exclusion patterns are written in STIX patterning, like rules. In the Alert properties part, you must indicate the category and type of the alerts raised by the rule and the severity of the rule, which is used to calculate the urgency of the corresponding raised alerts in association with assets criticality for events matching assets. The alert generation mode affects the alert processing workflow. There are two generation modes: 'Automatic', for which the alerts passed to the status 'Ongoing' immediately after their creation, and 'Manual', for which the alerts remain in the 'Pending' status until a manual action. When selecting 'Inherit from entity', then the generation mode defined for each entity is used. When selecting a generation mode for an alert, it will override the entity's default value. Note Modification of rules parameters will be applied for new alerts, raised after the compilation of the rule. STIX Patterning Correlation rules are written using STIX Patterning. In order to enhance detection of possibly malicious activity on networks and endpoints, a standard language is needed to describe what to look for in a cyber environment. STIX, abbreviation for Structured Threat Information eXpression, is a standardized language developed by MITRE and OASIS Cyber Threat Intelligence (CTI) Technical Committee to describe information about cyber-threats. It has been adopted as an international standard by various communities and organizations sharing information. STIX Patterns are composed of multiple building blocks, ranging from simple key-value comparisons to more complex, context-sensitive expressions. The most fundamental building block is the Comparison Expression, which is a comparison between a single property of a Cyber Observable Object and a given constant using a Comparison Operator. As a simple example, one might use the following Comparison Expression (contained within an Observation Expression) to match against an IPv4 address: 1 [ipv4-addr:value = '127.0.0.1'] Observation Expressions are contained in square brackets [ ... ] and may consist of one or more Comparison Expressions joined by Boolean Operators. Observation Expressions may be followed by one or more Qualifiers, which allow for the expression of further restrictions on the set of data matching the pattern. The final, highest level building block of STIX Patterning combines two or more Object Expressions via Observation Operators, yielding a STIX Pattern capable of matching across multiple STIX Observed Data SDOs. For more information about STIX and STIX Patterning, please refers to the OASIS STIX specification here . Observed Data In order to trigger alerts, rule patterns must match with Observed Data. An \"Observed Data\" is the internal representation of any collected event in SEKOIA.IO. All events are normalized into a JSON object compliant with the STIX Observed Data specification. Detection rules are applied on events in STIX Observed Data format. Here is an example of an Observed Data that could be obtained from a squid event: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 { \"x_sic_entity_by_ref\" : \"identity--d6358bb4-d9bb-47aa-b074-c6d1aeb673e2\" , \"created\" : \"2019-09-20T16:17:42.971Z\" , \"objects\" : { \"0\" : { \"value\" : \"127.0.0.1\" , \"type\" : \"ipv4-addr\" }, \"1\" : { \"value\" : \"216.58.215.48\" , \"type\" : \"ipv4-addr\" }, \"2\" : { \"start\" : \"2019-09-20T16:17:40.935Z\" , \"type\" : \"network-traffic\" , \"end\" : \"2019-09-20T16:17:40.935Z\" , \"extensions\" : { \"http-request-ext\" : { \"request_header\" : { \"Content-Type\" : \"application/xml\" }, \"request_method\" : \"HEAD\" , \"request_value\" : \"http://216.58.215.48/\" } }, \"src_ref\" : \"0\" , \"dst_ref\" : \"1\" , \"protocols\" : [ \"ipv4\" ] }, \"3\" : { \"type\" : \"user-account\" , \"extensions\" : { \"x-log\" : { \"hostname\" : \"DESKTOP-UPU7IFP\" } } } }, \"type\" : \"observed-data\" , ... \"x_event_type\" : \"http\" } The JSON object has a type of observed-data and is composed by smaller objects following another STIX specification: Cyber Observables . The main observable is the third one, with a type of network-traffic. It has references to indicate the source of the packet (src_ref - 127.0.0.1) and its destination (dst_ref - 216.58.215.48). These information can be used to construct correlation rules. Below, a non-exhaustive list of information which can be used in your rules: ipv4-addr:value ipv6-addr:value domain-name:value url:value network-traffic:dst_port network-traffic:src_port network-traffic:dst_packets network-traffic:src_packets network-traffic:dst_ref.value (corresponding to IP value, in the above example, network-traffic:dst_ref refers to object 0, which has a value of '127.0.0.1') network-traffic:src_ref.value network-traffic:extensions.'http-request-ext'.request_value network-traffic:protocols[*] process:pid process:name process:command_line file:hashes.md5 user-account:account_login","title":"Rules"},{"location":"operation_center/rules/#detection-rules-management","text":"","title":"Detection Rules Management"},{"location":"operation_center/rules/#rules-list","text":"On the alerts list, you can see in one look the following information. The status of your rules: Enabled or Disabled, plus the rules that can't compile will appear on a red background. The number of entities and assets to which the rule will be applied (default: all). The total of filtered alerts for the rule, corresponding to the number of alerts that where not raised, because the events corresponding to the signature of the rule where matching filter conditions. The total numbers of alerts raised and rejected during the past 7 days for each rule. A toggle button allows a quick enablement/disablement of rules.","title":"Rules list"},{"location":"operation_center/rules/#rule-details","text":"On top of the details of a rule, you can see when it was last updated and by who. The name of the rule will be used to name the corresponding raised alerts by default. Detection rules can be applied to all events, whatever the entity to which they are attached or the assets to which they can be linked, or applied only to some of them. If 'Using all entities' and 'Using all assets' are selected, rules will apply to all events even if new entites or new assets were added since last rule modification. For rules for which some entities or some assets were selected, if new entities or new assets are created, detection will not occur on corresponding events whithout rule modification. The signature part corresponds to the rule itself, the detection pattern applied to events. There're two type of rules: CTI or correlation. For CTI rules, you just have to select the source of the indicators: SEKOIA Intelligence Feed is an IOCs feed managed by SEKOIA's Purple Team (Indicators present in the SEKOIA.IO Intelligence Center). For correlation rules, the language used is STIX Patterning. More details about this langage are given below . Alert filters are used to avoid triggering alerts even if the events match the rule. Events that match the signature rule AND the alert filter criteria won't lead to the raising of an alert. Exclusion patterns are written in STIX patterning, like rules. In the Alert properties part, you must indicate the category and type of the alerts raised by the rule and the severity of the rule, which is used to calculate the urgency of the corresponding raised alerts in association with assets criticality for events matching assets. The alert generation mode affects the alert processing workflow. There are two generation modes: 'Automatic', for which the alerts passed to the status 'Ongoing' immediately after their creation, and 'Manual', for which the alerts remain in the 'Pending' status until a manual action. When selecting 'Inherit from entity', then the generation mode defined for each entity is used. When selecting a generation mode for an alert, it will override the entity's default value. Note Modification of rules parameters will be applied for new alerts, raised after the compilation of the rule.","title":"Rule details"},{"location":"operation_center/rules/#stix-patterning","text":"Correlation rules are written using STIX Patterning. In order to enhance detection of possibly malicious activity on networks and endpoints, a standard language is needed to describe what to look for in a cyber environment. STIX, abbreviation for Structured Threat Information eXpression, is a standardized language developed by MITRE and OASIS Cyber Threat Intelligence (CTI) Technical Committee to describe information about cyber-threats. It has been adopted as an international standard by various communities and organizations sharing information. STIX Patterns are composed of multiple building blocks, ranging from simple key-value comparisons to more complex, context-sensitive expressions. The most fundamental building block is the Comparison Expression, which is a comparison between a single property of a Cyber Observable Object and a given constant using a Comparison Operator. As a simple example, one might use the following Comparison Expression (contained within an Observation Expression) to match against an IPv4 address: 1 [ipv4-addr:value = '127.0.0.1'] Observation Expressions are contained in square brackets [ ... ] and may consist of one or more Comparison Expressions joined by Boolean Operators. Observation Expressions may be followed by one or more Qualifiers, which allow for the expression of further restrictions on the set of data matching the pattern. The final, highest level building block of STIX Patterning combines two or more Object Expressions via Observation Operators, yielding a STIX Pattern capable of matching across multiple STIX Observed Data SDOs. For more information about STIX and STIX Patterning, please refers to the OASIS STIX specification here .","title":"STIX Patterning"},{"location":"operation_center/rules/#observed-data","text":"In order to trigger alerts, rule patterns must match with Observed Data. An \"Observed Data\" is the internal representation of any collected event in SEKOIA.IO. All events are normalized into a JSON object compliant with the STIX Observed Data specification. Detection rules are applied on events in STIX Observed Data format. Here is an example of an Observed Data that could be obtained from a squid event: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 { \"x_sic_entity_by_ref\" : \"identity--d6358bb4-d9bb-47aa-b074-c6d1aeb673e2\" , \"created\" : \"2019-09-20T16:17:42.971Z\" , \"objects\" : { \"0\" : { \"value\" : \"127.0.0.1\" , \"type\" : \"ipv4-addr\" }, \"1\" : { \"value\" : \"216.58.215.48\" , \"type\" : \"ipv4-addr\" }, \"2\" : { \"start\" : \"2019-09-20T16:17:40.935Z\" , \"type\" : \"network-traffic\" , \"end\" : \"2019-09-20T16:17:40.935Z\" , \"extensions\" : { \"http-request-ext\" : { \"request_header\" : { \"Content-Type\" : \"application/xml\" }, \"request_method\" : \"HEAD\" , \"request_value\" : \"http://216.58.215.48/\" } }, \"src_ref\" : \"0\" , \"dst_ref\" : \"1\" , \"protocols\" : [ \"ipv4\" ] }, \"3\" : { \"type\" : \"user-account\" , \"extensions\" : { \"x-log\" : { \"hostname\" : \"DESKTOP-UPU7IFP\" } } } }, \"type\" : \"observed-data\" , ... \"x_event_type\" : \"http\" } The JSON object has a type of observed-data and is composed by smaller objects following another STIX specification: Cyber Observables . The main observable is the third one, with a type of network-traffic. It has references to indicate the source of the packet (src_ref - 127.0.0.1) and its destination (dst_ref - 216.58.215.48). These information can be used to construct correlation rules. Below, a non-exhaustive list of information which can be used in your rules: ipv4-addr:value ipv6-addr:value domain-name:value url:value network-traffic:dst_port network-traffic:src_port network-traffic:dst_packets network-traffic:src_packets network-traffic:dst_ref.value (corresponding to IP value, in the above example, network-traffic:dst_ref refers to object 0, which has a value of '127.0.0.1') network-traffic:src_ref.value network-traffic:extensions.'http-request-ext'.request_value network-traffic:protocols[*] process:pid process:name process:command_line file:hashes.md5 user-account:account_login","title":"Observed Data"},{"location":"operation_center/templates/","text":"Rule Templates Part of a rule's information can be stored in Templates, which can then be applied to new rules. Templates will have the name of the 'templated' rule by default. Information that will be copied in a new rule are: Type of the rule: correlation or CTI Signature of the rule Type of the alert that will be triggered by the corresponding rules Severity of the rule","title":"Templates"},{"location":"operation_center/templates/#rule-templates","text":"Part of a rule's information can be stored in Templates, which can then be applied to new rules. Templates will have the name of the 'templated' rule by default. Information that will be copied in a new rule are: Type of the rule: correlation or CTI Signature of the rule Type of the alert that will be triggered by the corresponding rules Severity of the rule","title":"Rule Templates"},{"location":"operation_center/threat_exposition/","text":"Dashboards SEKOIA.IO\u2019s Operation Center brings a dashboard mechanism, that is fully configurable and adaptable to all needs. Dashboards are composed of modular widgets that can be placed where you want. Widgets can be configured to specify the date range, applied filters, display, etc. Default Dashboard SEKOIA.IO comes with a pre-configured dashboard that gives a synthetic view of the current community activity, either from an operational security perspective (risk level, number of alerts, etc.) or from an activity perspective (list of last posted comments, last created alerts, etc.). Several of these widgets allow quick access to the relevant elements in the Operation Center. You can manage easily the time range you want to display and the refresh period of your dashboard in the top right of the screen. Create a New Dashboard The default dashboard offered by SEKOIA.IO cannot be modified. In addition to this, you have the possibility of creating your own dashboard, in order to match it as best as possible to your uses. Several widgets are available to you, with the possibility depending on the chosen widget to configure various filters. Note Dashboards you create will be available to all members of your community. You also have the possibility of creating a new dashboard by copying an existing dashboard, as well as the possibility of editing all the dashboards outside the \u201cDefault Dashboard\u201d. Provided Widgets SEKOIA.IO\u2019s Operation Center provides several widgets: Widget Name Description Screenshot Alerts List of alerts, optionally filtered by their status and sorted either by their urgency, their frequency, etc. Number of Alerts Count the number of alerts, optionally filtered by their status and by their associated entity Risk Level Global risk level (ARI) for the current community Cases List of cases, optionally filtered by their status and sorted either by their urgency or they last updated date. Number of Cases Count the number of cases, optionally filtered by their status Number of Events by Data Source Number of events collected by source of data displayed as a list, a doughnut or an histogram. Entities Overview List synthetic view of entities with for each one the risk level, number of alerts and the number of collected events. Last Comments List of comments posted on items such as alerts or cases. Top Observed Threats Show list threats (malware, tool or attack-pattern) observed in alerts.","title":"Dashboards"},{"location":"operation_center/threat_exposition/#dashboards","text":"SEKOIA.IO\u2019s Operation Center brings a dashboard mechanism, that is fully configurable and adaptable to all needs. Dashboards are composed of modular widgets that can be placed where you want. Widgets can be configured to specify the date range, applied filters, display, etc.","title":"Dashboards"},{"location":"operation_center/threat_exposition/#default-dashboard","text":"SEKOIA.IO comes with a pre-configured dashboard that gives a synthetic view of the current community activity, either from an operational security perspective (risk level, number of alerts, etc.) or from an activity perspective (list of last posted comments, last created alerts, etc.). Several of these widgets allow quick access to the relevant elements in the Operation Center. You can manage easily the time range you want to display and the refresh period of your dashboard in the top right of the screen.","title":"Default Dashboard"},{"location":"operation_center/threat_exposition/#create-a-new-dashboard","text":"The default dashboard offered by SEKOIA.IO cannot be modified. In addition to this, you have the possibility of creating your own dashboard, in order to match it as best as possible to your uses. Several widgets are available to you, with the possibility depending on the chosen widget to configure various filters. Note Dashboards you create will be available to all members of your community. You also have the possibility of creating a new dashboard by copying an existing dashboard, as well as the possibility of editing all the dashboards outside the \u201cDefault Dashboard\u201d.","title":"Create a New Dashboard"},{"location":"operation_center/threat_exposition/#provided-widgets","text":"SEKOIA.IO\u2019s Operation Center provides several widgets: Widget Name Description Screenshot Alerts List of alerts, optionally filtered by their status and sorted either by their urgency, their frequency, etc. Number of Alerts Count the number of alerts, optionally filtered by their status and by their associated entity Risk Level Global risk level (ARI) for the current community Cases List of cases, optionally filtered by their status and sorted either by their urgency or they last updated date. Number of Cases Count the number of cases, optionally filtered by their status Number of Events by Data Source Number of events collected by source of data displayed as a list, a doughnut or an histogram. Entities Overview List synthetic view of entities with for each one the risk level, number of alerts and the number of collected events. Last Comments List of comments posted on items such as alerts or cases. Top Observed Threats Show list threats (malware, tool or attack-pattern) observed in alerts.","title":"Provided Widgets"},{"location":"releases/","text":"SEKOIA.IO Release Notes Latest Notes 2021-01-06: Operation Center\u2019s Configurable Dashboard System Previous Release Notes 2020 2020-09-10 : Case management, new events page & SEKOIA.IO Documentation. 2020-07-22 : Improved display of alerts\u2019s observed data, two-factor authentication. 2020-07-07 : Improved display of alerts\u2019s observed data. 2020-02-14 : Detection rules statistics, improved events page 2019 2019-06-18 2019-05-06 2019-01-25 2018 2018-12-03 2018-10-29 2018-10-15 2018-10-08 2018-10-01 2018-09-24","title":"SEKOIA.IO Release Notes"},{"location":"releases/#sekoiaio-release-notes","text":"","title":"SEKOIA.IO Release Notes"},{"location":"releases/#latest-notes","text":"2021-01-06: Operation Center\u2019s Configurable Dashboard System","title":"Latest Notes"},{"location":"releases/#previous-release-notes","text":"","title":"Previous Release Notes"},{"location":"releases/#2020","text":"2020-09-10 : Case management, new events page & SEKOIA.IO Documentation. 2020-07-22 : Improved display of alerts\u2019s observed data, two-factor authentication. 2020-07-07 : Improved display of alerts\u2019s observed data. 2020-02-14 : Detection rules statistics, improved events page","title":"2020"},{"location":"releases/#2019","text":"2019-06-18 2019-05-06 2019-01-25","title":"2019"},{"location":"releases/#2018","text":"2018-12-03 2018-10-29 2018-10-15 2018-10-08 2018-10-01 2018-09-24","title":"2018"},{"location":"releases/2018-09-24/","text":"24/09/2018 This release focuses on the SIC application with a shiny new statistics API and a set of resiliency improvements. Features We followed the quote \u201cEverything is Data and Everyone needs it Analyzed\u201d while implementing out new statistical API for the SIC Application. This brandly new architecture leverages a time series database to expose various counters, risk indicators and datasets on both alerts and events production. This release brings various improvements on our OpenC2 language support in SIC. Among them, we improved the countermeasure descriptions through the use of fine grained-based action-steps. Fixes SIC customers interconnect their exporters to our detection engines by means of VPN connections. In order to reduce the impact of the various connection failures we encountered the last few days, we improved the overall resiliency of our VPN interconnections by means of a fast and automatic failover mechanism. We want to bring features and fixes to our customers as fast as possible while ensuring the quality of our products. One of our bottleneck in our release process was data migration on large sets of data. This release comes with our first data migration process which could be run as background tasks. Resiliencies Our APIs are the foundations of our collaborative applications. This release puts under constant monitoring all our HTTP endpoints to track number of requests and their execution times. A Service Level Objective (SLO) is the key element of a Service Level Agreement (SLA) as it defines the measurement process. This release introduces and actively monitors the first SLO of SEKOIA.IO: our HTTP APIs success rate. Belt and suspenders! Our new shiny alert management system, based on Prometheus, provides a faster outage notifications mechanism. Forecasts In SIC, we identified the need for a faster way to evaluate the operational impact of a detection rule. We designed a new page to expose statistics and aggregated information on all the alerts and incidents that are related to a selected rule. A key feature of SIC is its capacity of identifying the source and the target of a threat. To go even further, we offer a new page that consolidates all the information our detection engines collect on one source/target. For instance, this page will provide details on all the alerts, incidents and rules that are related to an IP address. SEKOIA.IO is built to support inter-application collaborations. As part of this, we designed an \u201caction card\u201d to ease user interactions between applications. More information in the next releases, stay tuned! If you have any concerns, feel free to contact us at support@sekoia.io .","title":"24/09/2018"},{"location":"releases/2018-09-24/#24092018","text":"This release focuses on the SIC application with a shiny new statistics API and a set of resiliency improvements.","title":"24/09/2018"},{"location":"releases/2018-09-24/#features","text":"We followed the quote \u201cEverything is Data and Everyone needs it Analyzed\u201d while implementing out new statistical API for the SIC Application. This brandly new architecture leverages a time series database to expose various counters, risk indicators and datasets on both alerts and events production. This release brings various improvements on our OpenC2 language support in SIC. Among them, we improved the countermeasure descriptions through the use of fine grained-based action-steps.","title":"Features"},{"location":"releases/2018-09-24/#fixes","text":"SIC customers interconnect their exporters to our detection engines by means of VPN connections. In order to reduce the impact of the various connection failures we encountered the last few days, we improved the overall resiliency of our VPN interconnections by means of a fast and automatic failover mechanism. We want to bring features and fixes to our customers as fast as possible while ensuring the quality of our products. One of our bottleneck in our release process was data migration on large sets of data. This release comes with our first data migration process which could be run as background tasks.","title":"Fixes"},{"location":"releases/2018-09-24/#resiliencies","text":"Our APIs are the foundations of our collaborative applications. This release puts under constant monitoring all our HTTP endpoints to track number of requests and their execution times. A Service Level Objective (SLO) is the key element of a Service Level Agreement (SLA) as it defines the measurement process. This release introduces and actively monitors the first SLO of SEKOIA.IO: our HTTP APIs success rate. Belt and suspenders! Our new shiny alert management system, based on Prometheus, provides a faster outage notifications mechanism.","title":"Resiliencies"},{"location":"releases/2018-09-24/#forecasts","text":"In SIC, we identified the need for a faster way to evaluate the operational impact of a detection rule. We designed a new page to expose statistics and aggregated information on all the alerts and incidents that are related to a selected rule. A key feature of SIC is its capacity of identifying the source and the target of a threat. To go even further, we offer a new page that consolidates all the information our detection engines collect on one source/target. For instance, this page will provide details on all the alerts, incidents and rules that are related to an IP address. SEKOIA.IO is built to support inter-application collaborations. As part of this, we designed an \u201caction card\u201d to ease user interactions between applications. More information in the next releases, stay tuned! If you have any concerns, feel free to contact us at support@sekoia.io .","title":"Forecasts"},{"location":"releases/2018-10-01/","text":"01/10/2018 This release focuses on the SIC application with more collaboratives features and resiliency. Collaborative Applications A neat example of two applications that collaborate for a better user experience is the relationship between inThreat and SIC applications. We increased this collaboration by referencing inThreat indicators in the alert produced by SIC. A SIC operator can easily query the inThreat CTI database to improve his comprehension of a threat. Another illustration of such collaboration is the SIC \u201caction card\u201d. This new feature allows one to easily do actions based on a clicked data, such as filter the current display, create a new incident or query the inThreat application to trigger an investigation process. Resiliencies We updated our alert management tool to handle system and business alerts sent by our monitoring system. Besides, we took the opportunity to upgrade the entire monitoring and alerting systems to the latest upstream versions. We improved the overall security and stability of the platform by enabling continuous delivery of security and system updates on all of our servers. If you have any concerns, feel free to contact us at support@sekoia.io .","title":"01/10/2018"},{"location":"releases/2018-10-01/#01102018","text":"This release focuses on the SIC application with more collaboratives features and resiliency.","title":"01/10/2018"},{"location":"releases/2018-10-01/#collaborative-applications","text":"A neat example of two applications that collaborate for a better user experience is the relationship between inThreat and SIC applications. We increased this collaboration by referencing inThreat indicators in the alert produced by SIC. A SIC operator can easily query the inThreat CTI database to improve his comprehension of a threat. Another illustration of such collaboration is the SIC \u201caction card\u201d. This new feature allows one to easily do actions based on a clicked data, such as filter the current display, create a new incident or query the inThreat application to trigger an investigation process.","title":"Collaborative Applications"},{"location":"releases/2018-10-01/#resiliencies","text":"We updated our alert management tool to handle system and business alerts sent by our monitoring system. Besides, we took the opportunity to upgrade the entire monitoring and alerting systems to the latest upstream versions. We improved the overall security and stability of the platform by enabling continuous delivery of security and system updates on all of our servers. If you have any concerns, feel free to contact us at support@sekoia.io .","title":"Resiliencies"},{"location":"releases/2018-10-08/","text":"08/10/2018 This release focuses on the SIC application with performance improvements and enhanced statistics to empower users in creating fine-grained based detection rules. SIC Application SIC security engines rely on user defined rules to perform their detection. These latter needs to be analyzed and adjusted by the teams running SOCs in order to enhance accuracy of raised alerts. To assess rules efficiency, the statistics API of the SIC application was improved to report more details on the effectiveness of detection rules. One can now assess the quality of its ruleset by querying how many alerts were raised given a rule and a specified time period. In addition to the quality of the detection, we also expect our engines to process security events on a real time basis. We significantly optimized our sighting generation process used by our correlation mechanisms to reduce the overall analysis duration. One more step forward our objective of a 1s processing time. As said before, we want to ensure high speed processing events and avoid bottlenecks across our engines. We have added new metrics to help us monitor any lag that could appear between the various components of our workflow. Hence, it helps us to identify if one particular component of the SIC workflow needs to be scaled up to provide more treatment capacity. Resiliencies A lot of our services rely on databases which have a sensible impact on the global responsiveness of the platform. In order to always maintain high performances on our databases, we reduced the amount of I/O on highly sollicited disks. We implemented this major change by adding new hard drives for data that doesn\u2019t require low latency (backups are a good example of such data). If you have any concerns, feel free to contact us at support@sekoia.io .","title":"08/10/2018"},{"location":"releases/2018-10-08/#08102018","text":"This release focuses on the SIC application with performance improvements and enhanced statistics to empower users in creating fine-grained based detection rules.","title":"08/10/2018"},{"location":"releases/2018-10-08/#sic-application","text":"SIC security engines rely on user defined rules to perform their detection. These latter needs to be analyzed and adjusted by the teams running SOCs in order to enhance accuracy of raised alerts. To assess rules efficiency, the statistics API of the SIC application was improved to report more details on the effectiveness of detection rules. One can now assess the quality of its ruleset by querying how many alerts were raised given a rule and a specified time period. In addition to the quality of the detection, we also expect our engines to process security events on a real time basis. We significantly optimized our sighting generation process used by our correlation mechanisms to reduce the overall analysis duration. One more step forward our objective of a 1s processing time. As said before, we want to ensure high speed processing events and avoid bottlenecks across our engines. We have added new metrics to help us monitor any lag that could appear between the various components of our workflow. Hence, it helps us to identify if one particular component of the SIC workflow needs to be scaled up to provide more treatment capacity.","title":"SIC Application"},{"location":"releases/2018-10-08/#resiliencies","text":"A lot of our services rely on databases which have a sensible impact on the global responsiveness of the platform. In order to always maintain high performances on our databases, we reduced the amount of I/O on highly sollicited disks. We implemented this major change by adding new hard drives for data that doesn\u2019t require low latency (backups are a good example of such data). If you have any concerns, feel free to contact us at support@sekoia.io .","title":"Resiliencies"},{"location":"releases/2018-10-15/","text":"15/10/2018 This release brings many improvements on the alert contextualization processes and threats descriptions for better insights on the threats your assets are facing. InThreat Application Faster and more reliable indexation of our Cyber Threat Intelligence indicators. inThreat is Sekoia\u2019s Cyber Threat Intelligence (CTI) solution. One of its mission is provide a knowledge base related to cybercrime and cyberthreats which is fed by our collectors and by our users. To ensure the best operational capacity for this database, we perform a complete and structured indexing of all of the observation collected. Such operation is expensive, hence, to ensure the best user experience, we implemented asynchronous indexing of the collected CTI observations as proposed in the TAXIIv2 standard. Improved threat descriptions of our CTI indicators. Our Cyber Threat Intelligence knowledge base is used, amongst others, by SIC, the detection solution implemented on SEKOIA.IO. To ease the understanding of our indicators by all of our users, we have improved the description related to malwares, threat related tools and attack patterns. This let final users understand precisely the impact of an alert. Enhanced descriptions are well formatted, free of technical terms and contextualized with information regarding to their provenance. SIC Application Detection rules applied to multiple entities SIC security engines rely on user defined rules to perform their detection that apply to a given set of supervised entities. To simplify the day-to-day work of SIC operators, this release enables the creation of detections rules that easily apply to multiple entities. This new feature drastically reduces the required effort to create and maintain a fine grained-based detection strategy. New \u201crule statistics\u201d page in the SIC frontend Recently, SIC introduced statistics about detection rules. A new page that leverages these new metrics was designed to help SIC operators to improve their detection ruleset. Among others, this page introduces a detailed graph that shows how the number of alerts evolves given a period of time and if the rule raised high urgency alerts. Hosting New backup monitoring system Backup is a very important point for our infrastructure that must provide a way to quickly recover from any crash situation or retrieve erroneously removed data. To enhance the confidence we have in our database level backups, a new monitoring mechanism was developed from scratch. This monitoring allows our operational teams to be notified if one of our backup job failed to proceed automatically so they can intervene and dramatically reduce the risk of any data loss. If you have any concerns, feel free to contact us at support@sekoia.io .","title":"15/10/2018"},{"location":"releases/2018-10-15/#15102018","text":"This release brings many improvements on the alert contextualization processes and threats descriptions for better insights on the threats your assets are facing.","title":"15/10/2018"},{"location":"releases/2018-10-15/#inthreat-application","text":"Faster and more reliable indexation of our Cyber Threat Intelligence indicators. inThreat is Sekoia\u2019s Cyber Threat Intelligence (CTI) solution. One of its mission is provide a knowledge base related to cybercrime and cyberthreats which is fed by our collectors and by our users. To ensure the best operational capacity for this database, we perform a complete and structured indexing of all of the observation collected. Such operation is expensive, hence, to ensure the best user experience, we implemented asynchronous indexing of the collected CTI observations as proposed in the TAXIIv2 standard. Improved threat descriptions of our CTI indicators. Our Cyber Threat Intelligence knowledge base is used, amongst others, by SIC, the detection solution implemented on SEKOIA.IO. To ease the understanding of our indicators by all of our users, we have improved the description related to malwares, threat related tools and attack patterns. This let final users understand precisely the impact of an alert. Enhanced descriptions are well formatted, free of technical terms and contextualized with information regarding to their provenance.","title":"InThreat Application"},{"location":"releases/2018-10-15/#sic-application","text":"","title":"SIC Application"},{"location":"releases/2018-10-15/#detection-rules-applied-to-multiple-entities","text":"SIC security engines rely on user defined rules to perform their detection that apply to a given set of supervised entities. To simplify the day-to-day work of SIC operators, this release enables the creation of detections rules that easily apply to multiple entities. This new feature drastically reduces the required effort to create and maintain a fine grained-based detection strategy.","title":"Detection rules applied to multiple entities"},{"location":"releases/2018-10-15/#new-rule-statistics-page-in-the-sic-frontend","text":"Recently, SIC introduced statistics about detection rules. A new page that leverages these new metrics was designed to help SIC operators to improve their detection ruleset. Among others, this page introduces a detailed graph that shows how the number of alerts evolves given a period of time and if the rule raised high urgency alerts.","title":"New \u201crule statistics\u201d page in the SIC frontend"},{"location":"releases/2018-10-15/#hosting","text":"","title":"Hosting"},{"location":"releases/2018-10-15/#new-backup-monitoring-system","text":"Backup is a very important point for our infrastructure that must provide a way to quickly recover from any crash situation or retrieve erroneously removed data. To enhance the confidence we have in our database level backups, a new monitoring mechanism was developed from scratch. This monitoring allows our operational teams to be notified if one of our backup job failed to proceed automatically so they can intervene and dramatically reduce the risk of any data loss. If you have any concerns, feel free to contact us at support@sekoia.io .","title":"New backup monitoring system"},{"location":"releases/2018-10-29/","text":"29/10/2018 This release provides new investigation features for SIC operators to optimize their workload while improving the quality of their analysis. SIC Application New page to display either sources or targets implied in alerts In order to qualify alerts, SIC operators need to have more information about nodes involved in an alert. The new \u201csource/target\u201d page allows one to gain insights on a node. In addition to statistics such as the number of alerts raised by that node or the number of referenced incidents, It also provides the list of the most meaningful alerts and incidents that leads to that node. Bulk actions on alerts SIC operators often apply the same treatment to multiple alerts, for example to change their statuses. To enhance user experience, the ability to perform bulk actions on alerts. This features speeds up the work of SIC operators by avoiding the repetition of the same operation several times. It allows operators to focus more deeply on alerts. SEKOIA.IO Enhanced datastore performances and resiliency for Docker Swarm servers All our virtual machines, which includes servers that are taking part of the Docker Swarm cluster, stores their data on \u201cdatastores\u201d. In order to improve resiliency and performance from an I/O perspective, we have added new datastores. This means that if one of the datastore is overloaded, this won\u2019t have a negative impact on the whole platform. If you have any concerns, feel free to contact us at support@sekoia.io .","title":"29/10/2018"},{"location":"releases/2018-10-29/#29102018","text":"This release provides new investigation features for SIC operators to optimize their workload while improving the quality of their analysis.","title":"29/10/2018"},{"location":"releases/2018-10-29/#sic-application","text":"","title":"SIC Application"},{"location":"releases/2018-10-29/#new-page-to-display-either-sources-or-targets-implied-in-alerts","text":"In order to qualify alerts, SIC operators need to have more information about nodes involved in an alert. The new \u201csource/target\u201d page allows one to gain insights on a node. In addition to statistics such as the number of alerts raised by that node or the number of referenced incidents, It also provides the list of the most meaningful alerts and incidents that leads to that node.","title":"New page to display either sources or targets implied in alerts"},{"location":"releases/2018-10-29/#bulk-actions-on-alerts","text":"SIC operators often apply the same treatment to multiple alerts, for example to change their statuses. To enhance user experience, the ability to perform bulk actions on alerts. This features speeds up the work of SIC operators by avoiding the repetition of the same operation several times. It allows operators to focus more deeply on alerts.","title":"Bulk actions on alerts"},{"location":"releases/2018-10-29/#sekoiaio","text":"","title":"SEKOIA.IO"},{"location":"releases/2018-10-29/#enhanced-datastore-performances-and-resiliency-for-docker-swarm-servers","text":"All our virtual machines, which includes servers that are taking part of the Docker Swarm cluster, stores their data on \u201cdatastores\u201d. In order to improve resiliency and performance from an I/O perspective, we have added new datastores. This means that if one of the datastore is overloaded, this won\u2019t have a negative impact on the whole platform. If you have any concerns, feel free to contact us at support@sekoia.io .","title":"Enhanced datastore performances and resiliency for Docker Swarm servers"},{"location":"releases/2018-12-03/","text":"03/12/2018 This release brings a set of major features such as the support for the Delegation of permissions and the first components of a new SIC detection engine SIC Application Profile pictures are very helpful elements in our interfaces. It allows SIC operators to easily know who did an action and gain some details on the underlying reasons. A simple but really effective optimization was done on our web pages to reduce the number of queries needed to retrieve profile pictures. A SIC operator can preset the severity of a rule through its definition in its related template. Ingested events are enriched with a short description, a source and a target. A SIC Operatior can leverage these information to get a clear and concise definition of the events that triggered the alert he is reviewing. A SIC operator can request a notification with the content of the alert for every updates made on an alert (new comments, status changes, counter-measure updates, \u2026). This notification is sent through the EventsAPI and is available as a stream. Two assets can now share the same name to support any naming strategy followed by the user. SEKOIA.IO There are avatars, API keys, and applications that require access to data and actions from other communities. To address this need, we added a Delegation mechanism to our APIs. A community can delegate a set of permissions to avatars or API keys of another community. The delegation is revocable at any time and community administrators can audit all delegations in their communities. A validity deadline can be set when creating the delegation. SEKOIA.io database architecture is now based on a central database, hosted on multiple replicated servers. This release brings an automatic server failure detection to trigger the re-election of the principal database among the available databases thus improving our SLOs. If you have any concerns, feel free to contact us at support@sekoia.io .","title":"03/12/2018"},{"location":"releases/2018-12-03/#03122018","text":"This release brings a set of major features such as the support for the Delegation of permissions and the first components of a new SIC detection engine","title":"03/12/2018"},{"location":"releases/2018-12-03/#sic-application","text":"Profile pictures are very helpful elements in our interfaces. It allows SIC operators to easily know who did an action and gain some details on the underlying reasons. A simple but really effective optimization was done on our web pages to reduce the number of queries needed to retrieve profile pictures. A SIC operator can preset the severity of a rule through its definition in its related template. Ingested events are enriched with a short description, a source and a target. A SIC Operatior can leverage these information to get a clear and concise definition of the events that triggered the alert he is reviewing. A SIC operator can request a notification with the content of the alert for every updates made on an alert (new comments, status changes, counter-measure updates, \u2026). This notification is sent through the EventsAPI and is available as a stream. Two assets can now share the same name to support any naming strategy followed by the user.","title":"SIC Application"},{"location":"releases/2018-12-03/#sekoiaio","text":"There are avatars, API keys, and applications that require access to data and actions from other communities. To address this need, we added a Delegation mechanism to our APIs. A community can delegate a set of permissions to avatars or API keys of another community. The delegation is revocable at any time and community administrators can audit all delegations in their communities. A validity deadline can be set when creating the delegation. SEKOIA.io database architecture is now based on a central database, hosted on multiple replicated servers. This release brings an automatic server failure detection to trigger the re-election of the principal database among the available databases thus improving our SLOs. If you have any concerns, feel free to contact us at support@sekoia.io .","title":"SEKOIA.IO"},{"location":"releases/2019-01-25/","text":"25/01/2019 This major release brings a large set of new features and bug fixes that improve the configuration, the detection and the qualification of security alerts. Inboarding We redesigned the inboarding process to simplify its execution and reduce frictions. A 7-day free trial period is made available at try.sekoia.io for new members. This trial can be extended up to 25days if the user validates trophies that are destributed along traditionnal user path. A contextual menu offers a precise vision of both validated and not validated trophies. The landing page of SEKOIA.IO has been refreshed to improve the user experience and promote the new usages of the platform. Configuration The user can define the list of the probes he/she wishes to connect to SEKOIA.IO. The intake feature automates the ingestion of events produced by connected probes. This version brings seven different supported formats of probes: Suricata, OpenSSH, HAProxy, Nginx, Netfilter, Squid. Detection A new detection engine is introduced with this version: the threshold engine. This major feature enables the creation fo rules to detect telemetric variations on both the number, the volume and the frequency of the events. Qualification The data model for an alert has been expanded to explicitly link a comment to a state change of the alert. This feature has been introduced so that a user can explain and justify any modification he/she introduced on an alert. A better description of an alert, the associated attack and its structure is offered to the user through the visualization of the estimated step in the Cyber KillChain the alert denotes. Reporting New metrics are offered to the user to improve his understanding of its orchestration. Among these indicators, we can cite the reporting of the type of handled events. The Alert Risk Indicator computation process has been updated to ease its comprehension. The computation is now performed on at most 10 days and only ongoing, closed and rejected alerts are considered. The new statistics API replaces the Stats API to provide a broader set of new counters, datasets and key risk indicators. If you have any concerns, feel free to contact us at support@sekoia.io .","title":"25/01/2019"},{"location":"releases/2019-01-25/#25012019","text":"This major release brings a large set of new features and bug fixes that improve the configuration, the detection and the qualification of security alerts.","title":"25/01/2019"},{"location":"releases/2019-01-25/#inboarding","text":"We redesigned the inboarding process to simplify its execution and reduce frictions. A 7-day free trial period is made available at try.sekoia.io for new members. This trial can be extended up to 25days if the user validates trophies that are destributed along traditionnal user path. A contextual menu offers a precise vision of both validated and not validated trophies. The landing page of SEKOIA.IO has been refreshed to improve the user experience and promote the new usages of the platform.","title":"Inboarding"},{"location":"releases/2019-01-25/#configuration","text":"The user can define the list of the probes he/she wishes to connect to SEKOIA.IO. The intake feature automates the ingestion of events produced by connected probes. This version brings seven different supported formats of probes: Suricata, OpenSSH, HAProxy, Nginx, Netfilter, Squid.","title":"Configuration"},{"location":"releases/2019-01-25/#detection","text":"A new detection engine is introduced with this version: the threshold engine. This major feature enables the creation fo rules to detect telemetric variations on both the number, the volume and the frequency of the events.","title":"Detection"},{"location":"releases/2019-01-25/#qualification","text":"The data model for an alert has been expanded to explicitly link a comment to a state change of the alert. This feature has been introduced so that a user can explain and justify any modification he/she introduced on an alert. A better description of an alert, the associated attack and its structure is offered to the user through the visualization of the estimated step in the Cyber KillChain the alert denotes.","title":"Qualification"},{"location":"releases/2019-01-25/#reporting","text":"New metrics are offered to the user to improve his understanding of its orchestration. Among these indicators, we can cite the reporting of the type of handled events. The Alert Risk Indicator computation process has been updated to ease its comprehension. The computation is now performed on at most 10 days and only ongoing, closed and rejected alerts are considered. The new statistics API replaces the Stats API to provide a broader set of new counters, datasets and key risk indicators. If you have any concerns, feel free to contact us at support@sekoia.io .","title":"Reporting"},{"location":"releases/2019-05-06/","text":"06/05/2019 Because we care about your experience on our platform and we want to make it easier for you to track all of your cyberdefense operations, we are happy to announce the launch of our newest feature on SEKOIA.IO: the Security Performance dashboard. Security Performance is a key performance indicator (KPI) screen that allows users to assess, measure and evaluate the proper functioning of the Security Operations Center and all the defense operations happening on the platform. Thanks to a selection of performance indicators, users can visually enjoy a follow-up on the different parameters (rules/alerts/...) while being able to measure the impact of their decision-making in real time. From a technical point of view, the Security Performance is a board where graphs, figures and metrics are listed to track performance and progress while making sense of all the security performance measures. The data provided on Security Performance is available through the fresh Statistics API and its new endpoints listed in this documentation . Here are the main performance indicators available on the Security Performance feature: Number of new alerts. Number of new incidents. Backlog line shows the proportion of alerts that have been processed or completed. Auto processed alerts refers to the proportion of automatically processed alerts. Reaction Time displays the average time to start processing an alert. Rules refers to the number of detection rules that have been triggered. Alert Workflow Duration shows the time needed to acknowledge and investigate an alert upon the creation of this one. Precision map indicates the proportion of alerts validated by the operators compared to those rejected. It\u2019s an estimation of the accuracy of users\u2019 rules. Time to close shows the average time necessary to close/resolve an alert. Operators\u2019 Activity traces all actions performed by human operators. Time to resolution by severity helps operators distinguish between the most severe alerts and the less important ones by displaying severity and the time needed to resolve each one. Alert by category shows the most frequent categories of alerts. If you have any concerns, feel free to contact us at support@sekoia.io .","title":"06/05/2019"},{"location":"releases/2019-05-06/#06052019","text":"Because we care about your experience on our platform and we want to make it easier for you to track all of your cyberdefense operations, we are happy to announce the launch of our newest feature on SEKOIA.IO: the Security Performance dashboard. Security Performance is a key performance indicator (KPI) screen that allows users to assess, measure and evaluate the proper functioning of the Security Operations Center and all the defense operations happening on the platform. Thanks to a selection of performance indicators, users can visually enjoy a follow-up on the different parameters (rules/alerts/...) while being able to measure the impact of their decision-making in real time. From a technical point of view, the Security Performance is a board where graphs, figures and metrics are listed to track performance and progress while making sense of all the security performance measures. The data provided on Security Performance is available through the fresh Statistics API and its new endpoints listed in this documentation . Here are the main performance indicators available on the Security Performance feature: Number of new alerts. Number of new incidents. Backlog line shows the proportion of alerts that have been processed or completed. Auto processed alerts refers to the proportion of automatically processed alerts. Reaction Time displays the average time to start processing an alert. Rules refers to the number of detection rules that have been triggered. Alert Workflow Duration shows the time needed to acknowledge and investigate an alert upon the creation of this one. Precision map indicates the proportion of alerts validated by the operators compared to those rejected. It\u2019s an estimation of the accuracy of users\u2019 rules. Time to close shows the average time necessary to close/resolve an alert. Operators\u2019 Activity traces all actions performed by human operators. Time to resolution by severity helps operators distinguish between the most severe alerts and the less important ones by displaying severity and the time needed to resolve each one. Alert by category shows the most frequent categories of alerts. If you have any concerns, feel free to contact us at support@sekoia.io .","title":"06/05/2019"},{"location":"releases/2019-06-18/","text":"18/06/2019 The Fresh New UI At SEKOIA.IO, we feel committed to ensuring that our users have the best experience in terms of navigation and usability. This is why we are excited to announce the new UI as the first step of our long list of user interface enhancements. Main Menu Navigation The first thing we\u2019ve changed has to do with the overall navigation on the platform. We\u2019ve moved the main menu which was on the right to a bigger, more intuitive and more responsive one on the left, putting all the sections of the platform in one place to give the user a direct access to every functionality of our platform. The sticky menu will automatically expand when hovering over it, but users can choose to keep it open or close it by using the new Hamburger button \u201cKeep Open\u201d. Even if it is reduced, a set of icons will still be visible, making it easier to navigate from one page to the other. On top of each page, a breadcrumb has been integrated to let users know how one page is nested within other pages and to provide them with direct links to previous pages without having to bother with the back button. Before After Another change has to do with the display of the different tables on the platform. As you know, at SEKOIA.IO we use many complex tables with a lot of data on them. To draw the user's eye to the data that matters most, we've decided to make these tables responsive and thus taking a wider place on the screen depending on what kind of device the user is on. We also got rid of the blue border on the left of each table which used to distract from the data in those tables, and we changed some buttons and icons to have a more consistent design all over the platform. Before After We would like to inform our users that this upgrade will not degrade any existing functionality and does not require upgrade costs or system requirement changes. If you have any concerns, feel free to contact us at support@sekoia.io .","title":"18/06/2019"},{"location":"releases/2019-06-18/#18062019","text":"","title":"18/06/2019"},{"location":"releases/2019-06-18/#the-fresh-new-ui","text":"At SEKOIA.IO, we feel committed to ensuring that our users have the best experience in terms of navigation and usability. This is why we are excited to announce the new UI as the first step of our long list of user interface enhancements.","title":"The Fresh New UI"},{"location":"releases/2019-06-18/#main-menu-navigation","text":"The first thing we\u2019ve changed has to do with the overall navigation on the platform. We\u2019ve moved the main menu which was on the right to a bigger, more intuitive and more responsive one on the left, putting all the sections of the platform in one place to give the user a direct access to every functionality of our platform. The sticky menu will automatically expand when hovering over it, but users can choose to keep it open or close it by using the new Hamburger button \u201cKeep Open\u201d. Even if it is reduced, a set of icons will still be visible, making it easier to navigate from one page to the other. On top of each page, a breadcrumb has been integrated to let users know how one page is nested within other pages and to provide them with direct links to previous pages without having to bother with the back button. Before After Another change has to do with the display of the different tables on the platform. As you know, at SEKOIA.IO we use many complex tables with a lot of data on them. To draw the user's eye to the data that matters most, we've decided to make these tables responsive and thus taking a wider place on the screen depending on what kind of device the user is on. We also got rid of the blue border on the left of each table which used to distract from the data in those tables, and we changed some buttons and icons to have a more consistent design all over the platform. Before After We would like to inform our users that this upgrade will not degrade any existing functionality and does not require upgrade costs or system requirement changes. If you have any concerns, feel free to contact us at support@sekoia.io .","title":"Main Menu Navigation"},{"location":"releases/2020-02-14/","text":"14/02/2020 This release page is now part of our newly designed website SEKOIA.IO on which you can find all the information about our products (presentation, use cases, pricing...) as well as a documentation and our contact if needed. Detection Rules There are some major changes that happened to the rules' page. First, we've added five new columns (entities, assets, total of produced alerts, rejected alerts and filtered alerts in the last 7 days) to add more context and comprehension to each rule. We've also put a toggle button on each row to quickly enable or disable a rule if needed. CTI and Correlation icons act now as the rule type's indicator, and if there is a compilation error, it can be clearly visible in the Status column (it's all red, you can't miss it). By clicking on a rule, we are redirected to a rule's main page which also got a radical makeover. A secondary menu is now visible on the left with all the rules listed as well as their current status to ease the navigation and prevent the user from having to go back to the rules table. A new banner is displayed at the top with the rule's main information like the name, type, and last update as well as an action button sticked on the right. Six collapsable sections are hanging under it to accommodate our users' needs to configure their rules as they please. We've included a new feature in the rule creation: alert filters , which enables our users to filter alerts given custom criteria by specifying an exclusion pattern. And last but not least, it is now possible to create a rule without a template, to save a rule configuration as a template and to use a pre-existing template to fill out information about a rule! Events page Before, we used to list only the last 50 events gathered by our intakes. Now, you can scroll indefinitely in your last events list, but also look for something specific in your events by using the dork language . Intakes Speaking of which, you can now see all of your intakes listed in a separate page with all the information you need to make sense of them. In addition to the intake format and intake key, you can now see the events and errors produced by the intake. If you haven't already, take a look at our on-going list of integrations and let us know if you don't find the format you're looking for. We can make them available for you. :-) User Center To enhance our users' experience on the platform, we created the \"User Center\". From there, it is possible to manage your profile as well as your numerous communities, members, roles, API keys, and delegations. You can access it through the contextual menu on the upper right of your screen.","title":"14/02/2020"},{"location":"releases/2020-02-14/#14022020","text":"This release page is now part of our newly designed website SEKOIA.IO on which you can find all the information about our products (presentation, use cases, pricing...) as well as a documentation and our contact if needed.","title":"14/02/2020"},{"location":"releases/2020-02-14/#detection-rules","text":"There are some major changes that happened to the rules' page. First, we've added five new columns (entities, assets, total of produced alerts, rejected alerts and filtered alerts in the last 7 days) to add more context and comprehension to each rule. We've also put a toggle button on each row to quickly enable or disable a rule if needed. CTI and Correlation icons act now as the rule type's indicator, and if there is a compilation error, it can be clearly visible in the Status column (it's all red, you can't miss it). By clicking on a rule, we are redirected to a rule's main page which also got a radical makeover. A secondary menu is now visible on the left with all the rules listed as well as their current status to ease the navigation and prevent the user from having to go back to the rules table. A new banner is displayed at the top with the rule's main information like the name, type, and last update as well as an action button sticked on the right. Six collapsable sections are hanging under it to accommodate our users' needs to configure their rules as they please. We've included a new feature in the rule creation: alert filters , which enables our users to filter alerts given custom criteria by specifying an exclusion pattern. And last but not least, it is now possible to create a rule without a template, to save a rule configuration as a template and to use a pre-existing template to fill out information about a rule!","title":"Detection Rules"},{"location":"releases/2020-02-14/#events-page","text":"Before, we used to list only the last 50 events gathered by our intakes. Now, you can scroll indefinitely in your last events list, but also look for something specific in your events by using the dork language .","title":"Events page"},{"location":"releases/2020-02-14/#intakes","text":"Speaking of which, you can now see all of your intakes listed in a separate page with all the information you need to make sense of them. In addition to the intake format and intake key, you can now see the events and errors produced by the intake. If you haven't already, take a look at our on-going list of integrations and let us know if you don't find the format you're looking for. We can make them available for you. :-)","title":"Intakes"},{"location":"releases/2020-02-14/#user-center","text":"To enhance our users' experience on the platform, we created the \"User Center\". From there, it is possible to manage your profile as well as your numerous communities, members, roles, API keys, and delegations. You can access it through the contextual menu on the upper right of your screen.","title":"User Center"},{"location":"releases/2020-07-07/","text":"07/07/2020 Improvement of the display of \"Observed Data\" on Alert page Significant work has been done on the display of the detail elements of an alert. The work mainly focused on \u201cObserved Data\u201d, which corresponds to the SEKOIA.IO internal representation of all the events collected. Here is the new display of an Observed Data: Metadata of an \"Observed Data\" A new block has been added at the top of the screen to display the metadata associated with an \"Observed Data\". It is thus possible to distinguish at first glance the type and format of the observed data, its relative date, as well as the entity for which the observation was made. Several redundant or technical information has been removed from this display area, but it is still possible to access all of the raw \"Observed Data\" information by clicking on the icon '<>'. Display of objects associated with \"Observed Data\" (SCO) Various changes have been made to the display of SCOs in an Observed Data. SCOs are the \u201cSTIX Cyber-observable Objects\u201d, corresponding to the observable details objects, such as IP addresses, domain names, ports, file names, e-mail addresses, etc. SCOs involved in raising the alert are now highlighted in blue and unrolled by default. We can therefore understand the alert more quickly and start analyzing it immediately. In addition, any \u201ctags\u201d associated with SCOs are displayed directly on the title of the SCO. These \u201ctags\u201d correspond to enrichments by SEKOIA.IO of the events received. A flag icon is displayed in place of the text for the \u201ctags\u201d designating countries. Raw events Raw events, as sent by your systems, are now available directly on the page describing an \"Observed Data\". Full raw event is available by clicking on icon '<>'.","title":"07/07/2020"},{"location":"releases/2020-07-07/#07072020","text":"","title":"07/07/2020"},{"location":"releases/2020-07-07/#improvement-of-the-display-of-observed-data-on-alert-page","text":"Significant work has been done on the display of the detail elements of an alert. The work mainly focused on \u201cObserved Data\u201d, which corresponds to the SEKOIA.IO internal representation of all the events collected. Here is the new display of an Observed Data:","title":"Improvement of the display of  \"Observed Data\" on Alert page"},{"location":"releases/2020-07-07/#metadata-of-an-observed-data","text":"A new block has been added at the top of the screen to display the metadata associated with an \"Observed Data\". It is thus possible to distinguish at first glance the type and format of the observed data, its relative date, as well as the entity for which the observation was made. Several redundant or technical information has been removed from this display area, but it is still possible to access all of the raw \"Observed Data\" information by clicking on the icon '<>'.","title":"Metadata of an \"Observed Data\""},{"location":"releases/2020-07-07/#display-of-objects-associated-with-observed-data-sco","text":"Various changes have been made to the display of SCOs in an Observed Data. SCOs are the \u201cSTIX Cyber-observable Objects\u201d, corresponding to the observable details objects, such as IP addresses, domain names, ports, file names, e-mail addresses, etc. SCOs involved in raising the alert are now highlighted in blue and unrolled by default. We can therefore understand the alert more quickly and start analyzing it immediately. In addition, any \u201ctags\u201d associated with SCOs are displayed directly on the title of the SCO. These \u201ctags\u201d correspond to enrichments by SEKOIA.IO of the events received. A flag icon is displayed in place of the text for the \u201ctags\u201d designating countries.","title":"Display of objects associated with \"Observed Data\" (SCO)"},{"location":"releases/2020-07-07/#raw-events","text":"Raw events, as sent by your systems, are now available directly on the page describing an \"Observed Data\". Full raw event is available by clicking on icon '<>'.","title":"Raw events"},{"location":"releases/2020-07-22/","text":"22/07/2020 Improved display of \u201cObserved Data\u201d on alert page Work on the detail page of an alert continued, always with the aim of facilitating the analysis of an alert and minimizing the presence of \u00ab noise \u00bb on the page. Differentiated display according to the types of SCO (STIX Cyber-observable Objects) The objects (SCO) that make up an \u00ab Observed Data \u00bb now have a separate display according to their type. Thus, an object of type network-traffic is better laid out and some extensions, such as http-request-ext, are displayed in a more readable way. Display of raw events formatted in JSON It is now possible to display the raw events in a dedicated window from the display of an \u00abObserved Data\u00bb. If the raw event is in JSON format, then the latter is formatted to make it easier to read. Adding and modifying \u00ab Alert Filters \u00bb When developping detection rules, it is now possible to add and modify \u00ab Alert Filters \u00bb. These filters, written in STIX patterning, make it possible to prevent the raising of alerts when certain criteria are met by an \u00ab observed data \u00bb. In the example below, the rule is used to raise an alert as soon as network traffic is detected by sysmon and the \u00ab alert filters \u00bb are used to indicate which are the legitimate processes to carry network traffic, for which there must be no raised alert. Two-factor authentication You can now activate two-factor authentication to strengthen the security of your user account on SEKOIA.IO. All you have to do is go to the management page of your user account (accessible by clicking on the icon at the top right of the application, choose 'Settings'). As a second factor of authentication, you can use a TOTP (time-based one-time password) application such as Google Authenticator, Authy, LastPass Authenticator or 1Password.","title":"22/07/2020"},{"location":"releases/2020-07-22/#22072020","text":"","title":"22/07/2020"},{"location":"releases/2020-07-22/#improved-display-of-observed-data-on-alert-page","text":"Work on the detail page of an alert continued, always with the aim of facilitating the analysis of an alert and minimizing the presence of \u00ab noise \u00bb on the page.","title":"Improved display of \u201cObserved Data\u201d on alert page"},{"location":"releases/2020-07-22/#differentiated-display-according-to-the-types-of-sco-stix-cyber-observable-objects","text":"The objects (SCO) that make up an \u00ab Observed Data \u00bb now have a separate display according to their type. Thus, an object of type network-traffic is better laid out and some extensions, such as http-request-ext, are displayed in a more readable way.","title":"Differentiated display according to the types of SCO (STIX Cyber-observable Objects)"},{"location":"releases/2020-07-22/#display-of-raw-events-formatted-in-json","text":"It is now possible to display the raw events in a dedicated window from the display of an \u00abObserved Data\u00bb. If the raw event is in JSON format, then the latter is formatted to make it easier to read.","title":"Display of raw events formatted in JSON"},{"location":"releases/2020-07-22/#adding-and-modifying-alert-filters","text":"When developping detection rules, it is now possible to add and modify \u00ab Alert Filters \u00bb. These filters, written in STIX patterning, make it possible to prevent the raising of alerts when certain criteria are met by an \u00ab observed data \u00bb. In the example below, the rule is used to raise an alert as soon as network traffic is detected by sysmon and the \u00ab alert filters \u00bb are used to indicate which are the legitimate processes to carry network traffic, for which there must be no raised alert.","title":"Adding and modifying \u00ab Alert Filters \u00bb"},{"location":"releases/2020-07-22/#two-factor-authentication","text":"You can now activate two-factor authentication to strengthen the security of your user account on SEKOIA.IO. All you have to do is go to the management page of your user account (accessible by clicking on the icon at the top right of the application, choose 'Settings'). As a second factor of authentication, you can use a TOTP (time-based one-time password) application such as Google Authenticator, Authy, LastPass Authenticator or 1Password.","title":"Two-factor authentication"},{"location":"releases/2020-09-10/","text":"10/09/2020 Case Management: New case tracking system The Operation Center now has a new feature called \u201cCase Management\u201d, allowing information relating to security records to be shared. A \u201ccase\u201d consists of a title, description, severity, and may be associated with alerts from the Operation Center. A \u201ccase\u201d has a lifecycle (currently, open or closed) and can be assigned to one or more people. This feature allows, for example, a security supervision team to escalate alerts to another team for clarification or to group alerts that seem related to facilitate analysis. \u201cCase Management\u201d replaces the old \u201cincident\u201d management mechanism. Among the many changes, we can mention the possibility of defining tags, assigning a case to one or more members of its community, adding comments or even associating alerts with a \u201ccase\u201d. Finally, the syntax of the description of a \u201ccase\u201d has been changed to use the Markdown language (with a graphical editor in the Operation Center). Old \u201cincidents\u201d have been converted to \u201ccases\u201d. The switch to the use of \u201ccases\u201d is completely transparent, access to old \u201cincidents\u201d is automatically redirected to the new implementation. Consultation of events: redesign of the page The page for viewing community events sent to SEKOIA.IO has been completely redesigned. It becomes more adaptable and more functional. This is the first work here, other improvements to this page will come later (search in longer periods, complex searches, etc.). Events table The table displaying the list of events now provides the following possibilities: Adding or removing a column (except for the date of the event which is mandatory); Move a column by dragging and dropping the title; Extension of an event and thus display it in ECS, STIX or raw format; Adding a filter on events from a table cell. Search in events Search fields in events now follow the \"ECS\" standard (Elastic Common Schema). Thus, to search for events with source IP address 127.0.0.1 , enter source.ip: \"127.0.0.1\" (and no longer source: \"127.0.0.1\" ). This change provides access to more fields of events stored in Elasticsearch. So to perform a search (admittedly useless) for DNS type events that requested the IPv6 address associated with google.com , we can use the following Dork query: 1 dns.question.name:\"google.com\" AND dns.question.type:\"AAAA\" A simple search creation wizard has also been added. It allows you to create rules even without knowing the Dork syntax, used on SEKOIA.IO. Saving searches The new form now offers the possibility of saving searches and finding them easily. The backup is currently performed within the web browser, so it will not be possible to access the saved searches from another machine. SEKOIA.IO documentation The code from the SEKOIA.IO documentation has been moved to a public space hosted on GitHub. Now it is possible for anyone to suggest changes to the documentation very easily, by clicking on the pen icon. Many help topics for using SEKOIA.IO have also been added to the documentation. You can of course always send us your comments and expectations with regard to this documentation, by emailing support .","title":"10/09/2020"},{"location":"releases/2020-09-10/#10092020","text":"","title":"10/09/2020"},{"location":"releases/2020-09-10/#case-management-new-case-tracking-system","text":"The Operation Center now has a new feature called \u201cCase Management\u201d, allowing information relating to security records to be shared. A \u201ccase\u201d consists of a title, description, severity, and may be associated with alerts from the Operation Center. A \u201ccase\u201d has a lifecycle (currently, open or closed) and can be assigned to one or more people. This feature allows, for example, a security supervision team to escalate alerts to another team for clarification or to group alerts that seem related to facilitate analysis. \u201cCase Management\u201d replaces the old \u201cincident\u201d management mechanism. Among the many changes, we can mention the possibility of defining tags, assigning a case to one or more members of its community, adding comments or even associating alerts with a \u201ccase\u201d. Finally, the syntax of the description of a \u201ccase\u201d has been changed to use the Markdown language (with a graphical editor in the Operation Center). Old \u201cincidents\u201d have been converted to \u201ccases\u201d. The switch to the use of \u201ccases\u201d is completely transparent, access to old \u201cincidents\u201d is automatically redirected to the new implementation.","title":"Case Management: New case tracking system"},{"location":"releases/2020-09-10/#consultation-of-events-redesign-of-the-page","text":"The page for viewing community events sent to SEKOIA.IO has been completely redesigned. It becomes more adaptable and more functional. This is the first work here, other improvements to this page will come later (search in longer periods, complex searches, etc.).","title":"Consultation of events: redesign of the page"},{"location":"releases/2020-09-10/#events-table","text":"The table displaying the list of events now provides the following possibilities: Adding or removing a column (except for the date of the event which is mandatory); Move a column by dragging and dropping the title; Extension of an event and thus display it in ECS, STIX or raw format; Adding a filter on events from a table cell.","title":"Events table"},{"location":"releases/2020-09-10/#search-in-events","text":"Search fields in events now follow the \"ECS\" standard (Elastic Common Schema). Thus, to search for events with source IP address 127.0.0.1 , enter source.ip: \"127.0.0.1\" (and no longer source: \"127.0.0.1\" ). This change provides access to more fields of events stored in Elasticsearch. So to perform a search (admittedly useless) for DNS type events that requested the IPv6 address associated with google.com , we can use the following Dork query: 1 dns.question.name:\"google.com\" AND dns.question.type:\"AAAA\" A simple search creation wizard has also been added. It allows you to create rules even without knowing the Dork syntax, used on SEKOIA.IO.","title":"Search in events"},{"location":"releases/2020-09-10/#saving-searches","text":"The new form now offers the possibility of saving searches and finding them easily. The backup is currently performed within the web browser, so it will not be possible to access the saved searches from another machine.","title":"Saving searches"},{"location":"releases/2020-09-10/#sekoiaio-documentation","text":"The code from the SEKOIA.IO documentation has been moved to a public space hosted on GitHub. Now it is possible for anyone to suggest changes to the documentation very easily, by clicking on the pen icon. Many help topics for using SEKOIA.IO have also been added to the documentation. You can of course always send us your comments and expectations with regard to this documentation, by emailing support .","title":"SEKOIA.IO documentation"},{"location":"releases/2021-01-06/","text":"2021-01-06: Operation Center\u2019s Configurable Dashboard System SEKOIA.IO\u2019s Operation Center now brings a new dashboard mechanism, that is fully configurable and adaptable to all needs. This new feature is now enabled per default for all SEKOIA.IO customers. Dashboards are composed of modular widgets that can be placed where you want. Widgets can be configured to specify the date range, applied filters, display, etc. SEKOIA.IO comes with a pre-configured dashboard that gives a synthetic view of the current community activity, either from an operational security perspective (risk level, number of alerts, etc.) or from an activity perspective (list of last posted comments, last created alerts, etc.). All SEKOIA.IO users are able to create new dashboards that fit their specific needs. It\u2019s also possible to clone an existing dashboard. Provided Widgets To Monitor SEKOIA.IO\u2019s Operation Center Activity SEKOIA.IO\u2019s Operation Center provides several widgets: Widget Name Description Screenshot Alerts List of alerts, optionally filtered by their status and sorted either by their urgency, their frequency, etc. Number of Alerts Count the number of alerts, optionally filtered by their status and by their associated entity Risk Level Global risk level (ARI) for the current community Cases List of cases, optionally filtered by their status and sorted either by their urgency or they last updated date. Number of Cases Count the number of cases, optionally filtered by their status Number of Events by Data Source Number of events collected by source of data displayed as a list, a doughnut or an histogram. Entities Overview List synthetic view of entities with for each one the risk level, number of alerts and the number of collected events. Last Comments List of comments posted on items such as alerts or cases. Top Observed Threats Show list threats (malware, tool or attack-pattern) observed in alerts. If Intelligence Center is accessible to the current user, then, CTI wdigets will be made available: last intelligence reports, number of known threats, etc.","title":"2021-01-06: Operation Center\u2019s Configurable Dashboard System"},{"location":"releases/2021-01-06/#2021-01-06-operation-centers-configurable-dashboard-system","text":"SEKOIA.IO\u2019s Operation Center now brings a new dashboard mechanism, that is fully configurable and adaptable to all needs. This new feature is now enabled per default for all SEKOIA.IO customers. Dashboards are composed of modular widgets that can be placed where you want. Widgets can be configured to specify the date range, applied filters, display, etc. SEKOIA.IO comes with a pre-configured dashboard that gives a synthetic view of the current community activity, either from an operational security perspective (risk level, number of alerts, etc.) or from an activity perspective (list of last posted comments, last created alerts, etc.). All SEKOIA.IO users are able to create new dashboards that fit their specific needs. It\u2019s also possible to clone an existing dashboard.","title":"2021-01-06: Operation Center\u2019s Configurable Dashboard System"},{"location":"releases/2021-01-06/#provided-widgets-to-monitor-sekoiaios-operation-center-activity","text":"SEKOIA.IO\u2019s Operation Center provides several widgets: Widget Name Description Screenshot Alerts List of alerts, optionally filtered by their status and sorted either by their urgency, their frequency, etc. Number of Alerts Count the number of alerts, optionally filtered by their status and by their associated entity Risk Level Global risk level (ARI) for the current community Cases List of cases, optionally filtered by their status and sorted either by their urgency or they last updated date. Number of Cases Count the number of cases, optionally filtered by their status Number of Events by Data Source Number of events collected by source of data displayed as a list, a doughnut or an histogram. Entities Overview List synthetic view of entities with for each one the risk level, number of alerts and the number of collected events. Last Comments List of comments posted on items such as alerts or cases. Top Observed Threats Show list threats (malware, tool or attack-pattern) observed in alerts. If Intelligence Center is accessible to the current user, then, CTI wdigets will be made available: last intelligence reports, number of known threats, etc.","title":"Provided Widgets To Monitor SEKOIA.IO\u2019s Operation Center Activity"},{"location":"searching/dork/","text":"Dork Dork is a domain-specific language to generate search queries that integrate advanced search operators. This language offers to exceed filters available on APIs. Example On the Operation Center, on the events page, the following query will match all not failed events received from the start of January 1st, 2020 to the end of January 2nd, 2020: NOT(error_code:\"Failed\") AND timestamp:>=2020-01-01T00:00:00Z AND timestamp:<2020-01-03T00:00:00Z Syntax A dork query contains one or more terms. Each terms hold a field, an operator and a literal. e.g: id:\"ALWyJiGeJSiw\" These terms can be combined though the use of logical operators. Literals Type Format Example String \"\\w+\" \"value\" Number \\d+[.,]\\d* 17.23 Boolean 0 (false) or 1 (true) 0 Date yyyy[-mm[-dd]] 2020-01-01 DateTime yyyy-mm-ddThh:mm:ss[.sss][+-hh:mm|Z] 2020-01-01T12:23:45.2342+02:00 Operators String operators Operator Description Example : The field must exactly match the literal type:\"malware\" :^ The field must start with the literal type:^\"Mal\" :$ The field must end with the literal type:$\"ware\" :~ The field must partially match the literal type:~\"dicat\" If the field represents a list: Operator Description Example : The field must match one item of the list tag:\"binary\" Number operators Operator Description Example : The field must equal the literal urgency:100 := The field must equal the literal urgency:=100 :> The field must be less than literal urgency:>10 :< The field must be greater than literal urgency:<50 Boolean operators Operator Description Example : The field must equal the literal deleted:1 Date operators Operator Description Example : The field must equal the literal timestamp:2020-01-01 := The field must equal the literal timestamp:=2020-01-01T12:13:45Z :> The field must be less than literal timestamp:>2020-01-01T00:00:00Z :< The field must be greater than literal timestamp:<2020-12-31T23:59:59+12:00 Logical operators Operator Description Example AND Match if both terms are verified timestamp:>2020-01-01T00:00:00Z AND type:$\"ware\" OR Match if any terms are verified timestamp:>2020-01-01T00:00:00Z OR type:^\"mal\" NOT Inverse the result of the term NOT type:^\"mal\" Grouping operators Operator Description Example () Groups operands (timestamp:>2020-01-01T00:00:00Z OR type:$\"ware\") AND NOT type:^\"mal\"","title":"Dork Language"},{"location":"searching/dork/#dork","text":"Dork is a domain-specific language to generate search queries that integrate advanced search operators. This language offers to exceed filters available on APIs.","title":"Dork"},{"location":"searching/dork/#example","text":"On the Operation Center, on the events page, the following query will match all not failed events received from the start of January 1st, 2020 to the end of January 2nd, 2020: NOT(error_code:\"Failed\") AND timestamp:>=2020-01-01T00:00:00Z AND timestamp:<2020-01-03T00:00:00Z","title":"Example"},{"location":"searching/dork/#syntax","text":"A dork query contains one or more terms. Each terms hold a field, an operator and a literal. e.g: id:\"ALWyJiGeJSiw\" These terms can be combined though the use of logical operators.","title":"Syntax"},{"location":"searching/dork/#literals","text":"Type Format Example String \"\\w+\" \"value\" Number \\d+[.,]\\d* 17.23 Boolean 0 (false) or 1 (true) 0 Date yyyy[-mm[-dd]] 2020-01-01 DateTime yyyy-mm-ddThh:mm:ss[.sss][+-hh:mm|Z] 2020-01-01T12:23:45.2342+02:00","title":"Literals"},{"location":"searching/dork/#operators","text":"","title":"Operators"},{"location":"searching/dork/#string-operators","text":"Operator Description Example : The field must exactly match the literal type:\"malware\" :^ The field must start with the literal type:^\"Mal\" :$ The field must end with the literal type:$\"ware\" :~ The field must partially match the literal type:~\"dicat\" If the field represents a list: Operator Description Example : The field must match one item of the list tag:\"binary\"","title":"String operators"},{"location":"searching/dork/#number-operators","text":"Operator Description Example : The field must equal the literal urgency:100 := The field must equal the literal urgency:=100 :> The field must be less than literal urgency:>10 :< The field must be greater than literal urgency:<50","title":"Number operators"},{"location":"searching/dork/#boolean-operators","text":"Operator Description Example : The field must equal the literal deleted:1","title":"Boolean operators"},{"location":"searching/dork/#date-operators","text":"Operator Description Example : The field must equal the literal timestamp:2020-01-01 := The field must equal the literal timestamp:=2020-01-01T12:13:45Z :> The field must be less than literal timestamp:>2020-01-01T00:00:00Z :< The field must be greater than literal timestamp:<2020-12-31T23:59:59+12:00","title":"Date operators"},{"location":"searching/dork/#logical-operators","text":"Operator Description Example AND Match if both terms are verified timestamp:>2020-01-01T00:00:00Z AND type:$\"ware\" OR Match if any terms are verified timestamp:>2020-01-01T00:00:00Z OR type:^\"mal\" NOT Inverse the result of the term NOT type:^\"mal\"","title":"Logical operators"},{"location":"searching/dork/#grouping-operators","text":"Operator Description Example () Groups operands (timestamp:>2020-01-01T00:00:00Z OR type:$\"ware\") AND NOT type:^\"mal\"","title":"Grouping operators"},{"location":"searching/search_events/","text":"Events Search The Events page exposes a search capability to investigate and hunt on your events. The search queries must follow the dork language . Type your search query in the box above the list of events to find expected events. Fields The Tables below detail all the fields that can be used to narrow down your search. In addition to them, one can filter the events based on their timestamps with the timestamp field. Action name type description action.id number Action unique identifier action.name string Name of the action action.outcome string Outcome status of the action Entity name type description entity.name string Name of the entity entity.uuid string Unique identifier of the entity Event name type description event.intake_key string The intake key event.original string The original message before normalization event.dialect string The intake format event.outcome string The parsing status (success or failure) Error name type description error.code string If ingestion failed, this field hosts the error Network name type description network.protocol string L7 Network protocol name. ex. http, lumberjack, transport protocol. network.transport string Protocol Name corresponding to the field iana_number . Destination name type description destination.ip string IP address of the destination. (IPv4 or IPv6) destination.port number Port of the destination destination.domain string Destination domain destination.packets number Packets sent from the destination to the source. Source name type description source.ip string IP address of the source. (IPv4 or IPv6) source.port number Port of the source source.domain string Source domain source.packets number Packets sent from the source to the destination. HTTP name type description http.request.method string HTTP request method http.response.status_code string HTTP response status code URL name type description url.original string Unmodified original url as seen in the event source. url.full string Full unparsed URL. DNS name type description dns.question.name string The name being queried. dns.question.type string The type of record being queried. dns.response_code string The DNS response code. User name type description user.id string Unique identifier of the user. user.name string Short name or login of the user. user.email string User email address. User Agent name type description user_agent.original string Unparsed user_agent string. Process name type description process.pid number Process Id process.name string Process name process.executable string Absolute path to the process executable. process.cmdline string Full command line that started the process. process.working_directory string he working directory of the process. process.ppid number Parent process' pid. process.parent.name string Parent process' name process.parent.executable string Parent process' executable Example Get valid event, from November 22nd to November 23rd 2019, that are neither apache nor nginx logs: timestamp:>=\"2019-11-22\" AND timestamp:<\"2019-11-23\" AND event.outcome:\"success\" AND NOT(event.dialect:\"apache\" OR event.dialect:\"nginx\")","title":"Querying Operation Center Events"},{"location":"searching/search_events/#events","text":"","title":"Events"},{"location":"searching/search_events/#search","text":"The Events page exposes a search capability to investigate and hunt on your events. The search queries must follow the dork language . Type your search query in the box above the list of events to find expected events.","title":"Search"},{"location":"searching/search_events/#fields","text":"The Tables below detail all the fields that can be used to narrow down your search. In addition to them, one can filter the events based on their timestamps with the timestamp field.","title":"Fields"},{"location":"searching/search_events/#action","text":"name type description action.id number Action unique identifier action.name string Name of the action action.outcome string Outcome status of the action","title":"Action"},{"location":"searching/search_events/#entity","text":"name type description entity.name string Name of the entity entity.uuid string Unique identifier of the entity","title":"Entity"},{"location":"searching/search_events/#event","text":"name type description event.intake_key string The intake key event.original string The original message before normalization event.dialect string The intake format event.outcome string The parsing status (success or failure)","title":"Event"},{"location":"searching/search_events/#error","text":"name type description error.code string If ingestion failed, this field hosts the error","title":"Error"},{"location":"searching/search_events/#network","text":"name type description network.protocol string L7 Network protocol name. ex. http, lumberjack, transport protocol. network.transport string Protocol Name corresponding to the field iana_number .","title":"Network"},{"location":"searching/search_events/#destination","text":"name type description destination.ip string IP address of the destination. (IPv4 or IPv6) destination.port number Port of the destination destination.domain string Destination domain destination.packets number Packets sent from the destination to the source.","title":"Destination"},{"location":"searching/search_events/#source","text":"name type description source.ip string IP address of the source. (IPv4 or IPv6) source.port number Port of the source source.domain string Source domain source.packets number Packets sent from the source to the destination.","title":"Source"},{"location":"searching/search_events/#http","text":"name type description http.request.method string HTTP request method http.response.status_code string HTTP response status code","title":"HTTP"},{"location":"searching/search_events/#url","text":"name type description url.original string Unmodified original url as seen in the event source. url.full string Full unparsed URL.","title":"URL"},{"location":"searching/search_events/#dns","text":"name type description dns.question.name string The name being queried. dns.question.type string The type of record being queried. dns.response_code string The DNS response code.","title":"DNS"},{"location":"searching/search_events/#user","text":"name type description user.id string Unique identifier of the user. user.name string Short name or login of the user. user.email string User email address.","title":"User"},{"location":"searching/search_events/#user-agent","text":"name type description user_agent.original string Unparsed user_agent string.","title":"User Agent"},{"location":"searching/search_events/#process","text":"name type description process.pid number Process Id process.name string Process name process.executable string Absolute path to the process executable. process.cmdline string Full command line that started the process. process.working_directory string he working directory of the process. process.ppid number Parent process' pid. process.parent.name string Parent process' name process.parent.executable string Parent process' executable","title":"Process"},{"location":"searching/search_events/#example","text":"Get valid event, from November 22nd to November 23rd 2019, that are neither apache nor nginx logs: timestamp:>=\"2019-11-22\" AND timestamp:<\"2019-11-23\" AND event.outcome:\"success\" AND NOT(event.dialect:\"apache\" OR event.dialect:\"nginx\")","title":"Example"}]}